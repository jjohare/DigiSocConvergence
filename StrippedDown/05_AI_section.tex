The swift rise of digital walled gardens, moving towards a less transparent internet, reveals both a need for user data protection and a corporate push for greater control and profit. Tech giants like Google, Reddit, and Twitter are increasingly controlling their platforms, adjusting data flows for revenue growth. Google's new privacy policy, which allows data collection for AI model training, increases public concerns over user consent and privacy rights. The wide-ranging language of the policy gives Google considerable power in using user-generated content, fueling debates on data usage ethics. Simultaneously, the social web's shift towards an entertainment-focused business model prioritizes revenue over human connection. Platforms target ad revenue through vertically scrolling videos, risking reduced content diversity and creating echo chambers.\par 
Entertainment unions like the International Alliance of Theatrical Stage Employees (IATSE) are grappling with AI's impact on employment. Their approach includes research, collaboration, education, political advocacy, organizing, and collective bargaining to protect members' interests, including upskilling initiatives. Upskilling is gaining industry attention. Companies like Tata Consultancy highlight the need to equip engineers with AI skills. Recognizing AI technologies' potential, they invest in reskilling programs to stay competitive and effectively use AI tools.\par
The rise of generative AI and the declining open web raises concerns about maintaining digital commons and encouraging diverse perspectives. AI-generated content could overshadow human contributions, making meaningful information harder to find and increasing misinformation risks. This situation highlights the need for balance between AI-generated and human-generated content.\par

Data control battles between platforms and users fuel debates on data ownership and profit sharing. Users demand more control over their data use and potentially a share in the resulting profits. This issue emphasizes the need for transparent data policies and fair user compensation models.\par

The influence of AI on the job market and the future of work is a significant concern. As AI technology progresses, the need for upskilling and reskilling programs grows to ensure workers can adapt to changing job requirements. Collaboration between industries, governments, and educational institutions is essential to address AI-induced disruptions and ensure a smooth workforce transition.\par

Finally, the importance of AI ethics and governance grows as AI technologies become more prevalent. The development and deployment of AI systems require ethical frameworks, transparency, and accountability. Collaboration between AI researchers, policymakers, and ethicists is critical to address potential risks and societal implications of AI technology.

\section{Artificial Intelligence in a global context}

This currently borrows heavily from \href{https://www.youtube.com/watch?v=5clOHBo8HP8}{the AI breakdown podcast}, is an AI generated placeholder, and needs considerably more more.

\subsection{Perception of AI and Society}
The examination of AI's implications on societal structures should undoubtedly receive the necessary attention. Soros's language and perception of reality seem particularly interesting, especially in the era of AI. He emphasizes his belief in reality and its importance in providing moral guidance, a concept that seems increasingly challenged in the age of AI.

\subsection{AI, Propaganda, and Authoritarianism}
In an opinion piece for The Hill by Bill Drexel and Caleb Withers, titled "Generative AI could be an authoritarian breakthrough in brainwashing," the authors argue that the concern isn't just external attempts to influence U.S. elections, but the impact on the populations within authoritarian countries. They posit that foreign disinformation efforts by Chinese and Russian entities are only the tip of the iceberg, with Beijing and Moscow disseminating massive amounts of propaganda to their own populations. The authors also cite instances of AI-enabled propaganda and misinformation campaigns, both in the context of undermining democracies and consolidating control within authoritarian states.

\subsection{Increased Surveillance Through AI}
Another critical concern around AI and authoritarianism is the potential for increased surveillance. With the integration of AI and data scraping techniques, governments can employ extensive teams to facilitate unprecedented levels of surveillance, compromising privacy. Such concerns are raised in the works of authors like Daniel Oberhaus, who posits that authoritarian regimes may have an advantage in AI due to their willingness to exploit data, such as advanced facial recognition data, in ways that open societies might not.

\subsection{Worker Surveillance and Remote Work}
Furthermore, the issue of worker surveillance, especially with the rise of remote work regimes, has garnered the attention of various entities, including the White House. This is due to concerns over automated systems that employers are using to monitor their remote workers, highlighting a less benign context of surveillance.

\subsection{AI and Ideology}
One way AI might foster authoritarianism is by supporting the ideology of closed societies or authoritarian regimes, such as China. These societies may leverage their global influence to disseminate their particular AI model, aligning it with their motivations and goals. The Carnegie Endowment for International Peace points out that for most countries, AI technology is viewed as an economic development factor that determines their standing in the global technology race, rather than as an ideological preference.

\subsection{AI and Central Planning}
Another concern is the fear that AI will make centrally planned economies seem viable, where past attempts failed due to the lack of data. This idea was discussed in a conversation between Peter Thiel and Reed Hoffman hosted by Neil Ferguson at Stanford in 2018. Thiel posited that AI appears to favor centralization, an aspect that supports the principles of central planning.

\subsection{Uncontrolled AGI Creation}
On the other hand, some suggest that capitalist competition could result in the creation of AGI that cannot be controlled. Dr. Jeffrey Hinton, a vocal advocate of this view, argues that AI's potential to disrupt business models could drive companies to recklessly pursue advancements in AI to stay competitive. This could lead to increased state power as people become more reliant on the state in an AI-dominated economy, potentially resulting in increased authoritarianism.

\subsection{AI Promoting Freedom}
However, AI could also promote freedom in several ways. For instance, AI tools like Altana have been used to identify goods made using forced labor, helping companies make informed supply chain decisions. AI could also serve as a new interface for disseminating information, such as a chatbot that aids detainees in requesting legal assistance.

\subsection{AI, Integrity, and Accessibility}
Yet, for AI to achieve its full potential in promoting freedom, the integrity of the information it disseminates must be uncompromised, and its accessibility must be ensured despite potential firewalls.

\subsection{AI's Impact on Societal Organization}
Given these diverse viewpoints, it seems that the potential of AI to either aid authoritarianism or promote freedom is yet to be fully explored. However, the inherent ability of democracies to encourage disagreement and diverse perspectives may serve as a counterbalance to the potential of AI for authoritarian control. Moreover, AI's capacity as a catalytic force in societal organization should not be underestimated. The increasing discourse around AI and its implications for labor and technology usage suggests that AI technology is reshaping the world in ways that were unimaginable just a few years ago. Its capabilities in data analysis, decision making, and automation are transforming industries and redefining the scope of what's possible.

\subsection{Democratization of AI Technology}
An argument often made in favor of democratization of AI technology is that it should be made open-source and freely available, thus creating a challenging framework for global political incumbents. This perspective is grounded on the belief that technology - and its underlying power - must be accessible to everyone to mitigate the risks of misuse and ensure fair benefits distribution.

\subsection{Open-source AI and Innovation}
Open-source AI can be a vehicle for widespread innovation. It can spur creativity, leading to breakthroughs in various sectors, from healthcare and education to energy and transportation. Open-source technologies facilitate collaboration, accelerate the pace of research, and democratize access, enabling researchers and developers across the globe to contribute to the expansion of AI's capabilities. It opens the possibility for rapid iteration and innovation, reducing the likelihood that a few powerful entities monopolize control over these transformative technologies.

\subsection{Open-source AI and Global Politics}
However, as beneficial as open-source AI may appear, the complexity of global politics can make the transition challenging. A landscape where AI technologies are open-source and freely available brings about potential dilemmas in various areas including national security, economic competitiveness, intellectual property rights, and data privacy.

\subsection{National Security and Open-source AI}
To start, national security is a primary concern. AI has a myriad of applications in defense and security sectors, many of which could potentially be exploited by adversarial entities. As such, unrestricted access to AI technologies could pose a risk to nations' security. Nevertheless, it is crucial to note that security risks also stem from concentrated AI power. A handful of nations or corporations owning the majority of AI developments may lead to destabilization, power imbalance, and heightened global tensions.

\subsection{Economic Competitiveness and Open-source AI}
Economic competitiveness is another intricate aspect. Countries and corporations are engaged in a fiercely competitive race to advance in AI technologies, recognizing the economic gains and strategic advantages tied to AI leadership. Open-source AI might challenge this dynamic, disrupting traditional models of competition. However, it could also create an environment of shared growth, leading to a more balanced global AI landscape.

\subsection{Intellectual Property Rights and Open-source AI}
Intellectual property rights form another complex dimension in the discussion. Open-source AI challenges traditional notions of ownership and patents, potentially undermining the incentives for companies and individuals to invest in AI research and development. Balancing the need for innovation with the necessity to protect inventors' rights becomes critical in an open-source framework.

\subsection{Data Privacy and Open-source AI}
Data privacy is a further point of contention. Open-source AI, coupled with increasingly ubiquitous data collection methods, raises concerns about individuals' privacy. However, it also provides an opportunity to develop robust, decentralized, and transparent AI systems that respect user privacy.

\subsection{A New Social Contract for AI}
Thus, navigating the intersection of AI and global politics necessitates careful consideration. It requires establishing a new social contract for AI—one that respects human rights, promotes equitable economic growth, and protects national security.

\subsection{Conclusion}
In conclusion, making AI open-source and freely available represents a shift from the status quo, with both promising potentials and daunting challenges. A global AI framework that upholds democratic principles and values, promotes shared prosperity, and safeguards security and privacy is the aspiration. To achieve this, an inclusive and multidimensional discourse is essential, involving governments, corporations, civil society, academia, and individual citizens. It is through this collective effort that AI's true potential can be harnessed for the global good.

There is skepticism the idea of artificial general intelligence (AGI) leading to superintelligent machines that threaten humanity in the near future. This supposed risk of AGI is described as a "red herring" - an unfounded fear. The reasons given are:

\begin{itemize}
\item We do not have a clear understanding or definition of general intelligence or consciousness.
\item Current AI like large language models are limited in scope. They are good at statistical pattern matching in language, not generally intelligent.
\item The hypothesis that intelligence and consciousness emerge simply from increasing computational power is unproven. There are likely other components we don't understand.
\end{itemize}

The real risk is perhaps government control and regulation of AI development and applications, justified by arguing it is needed for safety and responsible AI. This could impose limits on acceptable speech and thought. Centralised entities could become gatekeepers for how people access and interpret information about the world. Mandating allowable language could narrow ideas and speech to fit an official narrative. Fears of AGI, even if exaggerated, open the door for regulators and bureaucrats to intervene in the name of safety. The risk is not AGI itself but the government control that hype about it enables.

There is speculation that AI will automate many white collar cognitive jobs, similar to how industrial machinery automated manual labor. This may "chase humans up the value stack" as lower value work is handled by AI, freeing people to focus on higher value creative activities.