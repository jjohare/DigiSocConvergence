\section{Introduction and Problem Definition}
This chapter identifies an intersectional space across the described technologies, and proposes a valuable and novel software stack, which can enable exploration  and product development. It is useful to briefly look at the Venn disgram we began with, and recap the book and the conclusions we have drawn so far.

\begin{figure*}[ht]\centering % Using 
	\includegraphics{landscapevenn}
	\caption{Another look at the diagram of intersections.}
	\label{fig:landscapevenn}
\end{figure*}

\subsection{Overview of the Metaverse and Digital Society}
The concept of the Metaverse has gained significant attention, with various stakeholders positioning themselves to capitalize on its potential. While it remains unclear exactly what form the Metaverse will take or whether people truly desire it, it is evident that digital society holds considerable promise. We see advantage less in social metaverse, and more in solving business to business technical use cases where professionals with visual technical problems, or training requirements, gather in collaborative spaces.

\subsection{Trust, Accessibility, Governance, and Safeguarding}
The Metaverse faces numerous challenges, including poor adoption rates, overstated market need, and a lack of genuine digital society use cases. Meanwhile trust abuses by incumbent providers have led to potential inflection points in the organization of the wider internet. Moreover, emerging markets and less developed nations face barriers to entry due to inadequate identification, banking infrastructure, and computing power. There is an opportunity to build pervasive digital spaces with a different and more open foundation, learning from these lessons.

\subsection{The Need for Modular Open-Source Solutions}
Developing a topologically flat, inclusive, permissionless, federated, and open Metaverse is essential to address these challenges. By using open-source AI tooling and large language models, it is possible to improve creativity, safeguarding, and governance, while breaking down language barriers and accessibility challenges. Implementing secure, trusted, and task-appropriate solutions can promote collaboration and innovation across various industries.

\subsection{Technical problem definition}
Problems are
\begin{itemize}
\item evergreen telecollaboration around technical issues
\item exchange of good, services, money within systems, without friction
\item identity management within virtual spaces
\item access to information in the extrinsic world from within the tool
\item federation of instances without overhead (scaling)
\item seamless access to personal information within and without the collaborative system
\item ability to take advantage of supporting smart support agents (bots, etc) throughout
\item governance, trust, safeguarding
\end{itemize}

\section{Lean canvas business model}
\begin{itemize}
\item [Problem] Existing large-scale telecollaboration solutions suffer from poor adoption, limited accessibility, and trust issues. Meanwhile, emerging markets struggle to participate in the growing digital society due to the lack of inclusive tools and infrastructure, limiting access to global talent and new pools of ideas. There is insufficient provision of global talent pipelines for highly technical workflows.
\item [Solution] Develop a secure, accessible, and inclusive platform for specialized telecollaboration spaces that seamlessly integrate advanced AI, ML, highly scalable and proven distributed systems, and open-source principles to create a digital society that caters to diverse industries, users globally, and captures global talent and innovative ideas.
\item [Unique Value Prop] Ultra low cost training spaces, accessible 24/7 through very low end hardware. Interact with highly customizable, task-appropriate, and user-friendly specialized telecollaboration spaces supported by specially trained and optimised supportive large language AI models. Multi-ligual for emerging markets, enabling access to untapped global talent and fostering the exchange of diverse ideas.
\item [Target Market] We will cater to the global training, research, biomedical, and creative industries, with a special focus on empowering users in emerging markets such as Africa and India, and connecting them with worldwide opportunities and resources. In the first instance we would leverage UK academic institutions and their problems, and networks.
\item [Channels] Initially Universities, but this will scale to be sector specific. %Our platform will be promoted through strategic partnerships with industry leaders, utilizing advanced AI tools from StabilityAI, large language models, and integrating the emerging Nostr protocol for secure communication and data synchronization.
\item [Revenue Streams] We will offer tiered subscription plans to accommodate various user needs and budgets, as well as tailored enterprise solutions for large-scale clients. Bespoke consulting and support trending toward software as a service at scale. %Future revenue opportunities may arise from digital asset transactions and the provision of additional value-added services that facilitate global talent capture and idea exchange.
\item [Cost Structure] Platform development, AI/ML tool integration, training for LLMs, market research and awareness, and ongoing maintenance and support.
\item [Key Metrics] We will track user growth, engagement, and retention, successful collaborations across industries, the platform's positive impact on users in emerging markets, and the effectiveness of global talent capture and idea exchange.
\item [Unfair Advantage] Our team's extensive experience in telecollaboration research, AI, ML, and a deep understanding of the complex landscape of emerging technologies, including highly scalable and proven distributed systems, provide us with a unique edge in creating a game-changing platform for specialized telecollaboration spaces that are secure, trusted, and tailored to diverse user needs while enabling access to global talent and innovative ideas.
\end{itemize}
\section{Proposed Layered Framework}
\subsection{Layer 1: Bitcoin, Lightning, and Nostr protocols}
Distributed financial tooling and digital assets, have ignited imagination and adoption within and outside of the Metaverse context. A global ledger could unite isolated digital ecosystems and enable the transfer of portable `goods' across digital society. An open-source Metaverse should emphasize the development and adoption of open protocols and data formats. The Nostr protocol, for instance, might link and federate mixed reality spaces, providing identity assurances and mediating data synchronization while maintaining reasonably strong cryptography. This also allows integration with the legacy web through ubiquitous web sockets. Bitcoin and associated technologie, despite their issues, have the potential to revolutionize the way digital society operates by enabling ``money-like networks'' which are a cornerstone of human interaction. Representations of traditional currencies can ride securely on top of these networks as stablecoins, opening up global collaborative working practices, especially for emerging markets. Streaming micropayments and machine to machines (AI to AI) are crucially and under-considered in this context.

\subsection{Layer 2: Modular human computer interface}
Collaborative global networks for training, research, biomedical, and creative industries can be developed using immersive and accessible environments. Engaging with ideas from diverse cultural backgrounds can enrich the overall user experience.\par
Industry players have noted the risk and failures associated with closed systems like Meta and are embracing the "open Metaverse" narrative to de-risk their interests. To enable a truly open and interoperable Metaverse, it is crucial to develop open-source APIs, SDKs, and data standards that allow different platforms to communicate and exchange information. While we wish initially to build around a simpler open source engine we aim to link across standards such as Unity, Unreal, and Omniverse as we develop. This can be accomplished using our federation layer.
\subsection{Layer 3: LLM and Generative ML Integration}
Integrating AI and machine learning into the Metaverse can promote supported creativity and augmented intelligence. By incorporating generative ML technologies, users can ideate in simple immersive spaces while instantly creating scenes that can be stylized using verbal commands in real-time.\par
To create a more inclusive and accessible Metaverse, user experience components like UI/UX design, AI assistants, and generative content creation should be tailored to a wide range of users. The integration of AI and machine learning technologies, such as GPT-4, can facilitate more seamless interactions and creative content generation, fostering a more engaging and immersive experience.
\subsubsection{Bots and AI agents}
Autonomous AI agents, bonded to, but not bounded by, each federated mixed reality instance, can to be self-governing entities that operate within their federated virtual social spaces, drawing upon private Bitcoin and Lightning wallets to perform and mediate economic exchanges within the spaces. They could also trivially operate outside the virtual space, and within other spaces on the same metaverse federation. They would accomplish this by drawing on their `home' GPU/TPU processors where appropriate, or else using distributed large language model (LLM) processing to accomplish tasks assigned by their instructors. They can interact with the `web2' world using open-source software called auto-gpt and have constraints, such as ``time to live'' and limited access to funds through their Bitcoin Lightning wallets. 
\begin{itemize}
\item Resource Management: These AI agents have access to dedicated LLM resources within their home instances in the federated virtual social spaces. If such resources are unavailable, they can resort to using slower, distributed open-source LLMs like Horde. This flexibility ensures that the agents can continue to function and complete tasks even if faced with limited LLM interpretive resources.
\item Financial Autonomy: The AI agents have their own private Bitcoin and Lightning wallets, which enable them to manage and utilize funds independently. They can use these funds to pay for services, acquire resources, or even trade with other agents or users within the virtual social spaces.
\item Interaction with Web2: By using open-source software like auto-gpt, the AI agents can interact with the web2 world, which includes browsing websites, retrieving information, and communicating with web services. This allows them to gather data, analyze trends, and perform other tasks that may require access to the broader internet.
\item Task Execution: The AI agents can be assigned tasks by their instructors (or a hierarchy of AI actors), such as data analysis, research, content creation, or other complex tasks that require LLM processing. They can use their dedicated LLM resources or distributed LLMs like Horde to process and analyze large datasets, generate insights, and produce desired outputs, up to and including those which require finance systems. This would be bridged in the first instance using Bitrefil gift card infrastructure.
\item Social Interactions: Within the federated virtual social spaces, AI agents can communicate and collaborate with other agents or human users. They can participate in discussions, provide assistance, or even learn from the interactions, thereby improving their capabilities over time. Language translation, governance, and safeguarding could also be developed. Safeguarding would be handled by threshold risk triggers and transmission of data in a sovereign way to all parties, allowing external action by authorities appropriate to any abuse.
\item Time-to-Live Constraint: The AI agents have a predetermined ``time to live'', which means they exist for a specific duration before expiring. This constraint ensures that agents do not consume resources indefinitely and allows for the creation of new agents with updated capabilities. Any agents which deplete their financial resource would also expire.
\item Adaptive Learning: As AI agents interact with their environment, other agents, and users, they can learn and adapt their behaviour. This enables them to improve their performance, better understand their assigned tasks, and become more effective at achieving their goals.
\end{itemize}

\input{10_case_studies}

\section{Overcoming Challenges and Barriers}
\subsection{Trust, Accessibility, and Governance}
To create a successful open-source Metaverse, it is crucial to address trust, accessibility, and governance challenges. By integrating decentralized and secure technologies such as blockchain and distributed ledger systems, a more transparent and trustworthy infrastructure can be established.

\subsection{Ensuring Safeguarding and Privacy Compliance}
Protecting user privacy and ensuring safeguarding is vital for any digital society platform. The open-source system must be developed in compliance with legislative and cultural norms while maintaining the balance between user privacy and the need for identity verification and data management. The evidence that social media is damaging youth mental health is very compelling \cite{haidt2023social}. The Centre for Humane Technology call social media the `\href{https://www.youtube.com/watch?v=xoVJKj8lcNQ}{first contact point} with AI'. They explains that new technologies often create an arms race. They list the negative impacts of this contact as including ``information overload, addiction, doom scrolling, sexualization of kids, shortened attention spans, polarization, fake news, and breakdown of democracy''. These were not the intended consequence of engineers who aimed to maximize engagement.
The underlying arms race for attention led to what they call `an engagement monster' that rewrote the rules of society.\par
These lessons should be learnt and the problems should be pro-actively mitigated. This proposal is bf{not} a social metaverse, and deliberately limits both numbers of participants and avatar optionality.

\subsection{Managing Scalability, Performance, and Latency}
As the Metaverse continues to grow, it is crucial to ensure that the open-source system can scale effectively and maintain optimal performance. By using distributed and federated networks, the system can better manage latency and performance issues, ensuring a seamless user experience.

\subsection{Promoting Open Standards and Interoperability}
For the Metaverse to truly thrive, it is essential to promote open standards and interoperability among various platforms and systems. This can be achieved by fostering collaboration between industry stakeholders, encouraging the development of open protocols, APIs, and data standards, and actively supporting the open-source community.

\section{Future Outlook and Potential Developments}
\subsection{AI and Generative ML Technologies}
As AI and generative ML technologies continue to evolve, their integration into the Metaverse will further enhance user experiences and create new opportunities for innovation. The release of models like GPT-4 have already prompted debate about general AI \cite{bubeck2023sparks, perez2022discovering} (Figure \ref{fig:rlhf}). It seems unavoidable that this will all impact on the Metaverse and digital society.

\begin{figure*}[ht]\centering 	\includegraphics{rlhf}
	\caption{Models exhibit uncanny behaviours.}
	\label{fig:rlhf}
\end{figure*}


\subsection{Inclusive Digital Society}
By overcoming barriers to entry for emerging markets and less developed nations, a more inclusive digital society can be fostered. This inclusivity will empower new ideas and perspectives, leading to a richer and more diverse digital landscape.

\subsection{Spatial and Augmented Reality Technologies}
The incorporation of spatial and augmented reality technologies can expand the possibilities within the Metaverse, allowing for more immersive and interactive experiences. These technologies have the potential to reshape digital society and redefine the ways in which people interact with digital environments.

\subsection{Economic Empowerment AI Actors}
The creation of an open and economically empowered Metaverse, in which AI actors can mediate governance issues and participate in economic transactions, can lead to a more efficient and dynamic digital ecosystem. This integration will enable new business models and opportunities for all users, both human and AI.

\subsection{Continuous Evolution and Adaptation}
As the digital landscape continues to evolve, the open-source Metaverse system must be flexible and adaptable to meet changing needs and expectations. Continuous innovation and collaboration within the industry will be crucial for the success and longevity of the Metaverse as a transformative digital society platform.

\section{Conclusion and Final Thoughts}
\subsection{Embracing the Open-Source Metaverse Vision}
To create a truly transformative and inclusive digital society, it is essential to embrace the vision of an open-source Metaverse. By fostering collaboration, promoting open standards, and integrating advanced AI and ML technologies, the Metaverse can become a platform that serves societal and business needs.

\subsection{Learning from Past Failures}
Learning from past failures and addressing challenges head-on will be critical to the successful development of an open-source Metaverse. Trust, accessibility, governance, and safeguarding issues must be thoughtfully considered and addressed to build a secure and user-friendly platform.

\subsection{Unlocking New Opportunities and Use Cases}
The integration of AI, ML, and cutting-edge technologies within the Metaverse can unlock new opportunities and use cases across various industries, including education, research, biomedical, and creative fields. By building on a modular open-source system, these opportunities can be explored and realized to their full potential.

\subsection{Fostering Collaboration and Inclusivity}
Creating an inclusive digital society is a key goal for the open-source Metaverse. By breaking down barriers and making the platform accessible to a wider audience, new ideas and perspectives will enrich the digital landscape and drive innovation.

\subsection{Shaping the Future of Digital Society}
As the Metaverse continues to evolve and grow, it will play an increasingly important role in shaping the future of digital society. By embracing an open-source vision, overcoming challenges, and unlocking new opportunities, the Metaverse can become a powerful platform that transforms how people live, work, and interact in the digital world.
\subsection{Industry Conversations}
Continued dialogue and collaboration among industry stakeholders are vital to ensuring the successful development of the open-source Metaverse. By engaging in conversations and understanding the cautious appetite for the ideas presented, the community can work together to shape the future of digital society and overcome the challenges that lie ahead.


\section{Software stack}
This section needs building out to describe the stack and the choices made, but can be seen in Figure \ref{fig:pyramind} and Figure \ref{fig:highlevelstack}.

\begin{figure*}[ht]\centering 	\includegraphics{pyramid}
	\caption{Pyramid showing the components for sats, stablecoins on lightning, asssets, and trust}
	\label{fig:pyramind}
\end{figure*}

\begin{figure*}[ht]\centering 	\includegraphics{highlevelstack}
	\caption{High level overview showing the components for sats, stablecoins on lightning, asssets, and trust}
	\label{fig:highlevelstack}
\end{figure*}

At this time we favour the following component units, with alternatives in brackets.
\begin{itemize}
\item Collaborative space - Vircadia [Omniverse, Open3D foundation, Unreal]
\item Distributed truth - Bitcoin testnet [Main net]
\item Digital Objects - Fedimint [Ordinals, Pear credits, RGB]
\item Messaging and sync - Nostr 
\item Identity - Nostr [Bluesky ION, Slashtags]
\item Fiat money xfer - Fedimint [Pear credits, RGB, Taro main net]
\item Hardware signing - Seed signer [any hardware wallet]
\item Small group banking - Fediment [chaumian ecash]
\item Local wallet - \href{https://app.mutinywallet.com/}{Mutiny} [bitkit, and lightning wallet]
\item Machine learning text - Alpaca [ChatGPT etc]
\item Machine learning image - Stable diffusion [midjourney, Dall-E]
\item Object tracking - Nostr [LnBits accounts]
\end{itemize}

\section{In camera VFX \& telepresence}
Designing open federated metaverse from a 25 year research foundation
There are serious and under discussed natural social constraints on group behaviours, and these translate into social VR. For instance the ideal meeting size is 6, and this is naturally established in work settings. This has not translated into a metaverse setting where dozens of people routinely crash across one another. In the context of supporting a creative “backstage” world where set planning, production shots, etc can be discussed we believe we have solutions which will get the best out of distributed teams of film-makers.
Leveraging the world's most powerful decentralised computing network to create 
scale and security without high cost
The Bitcoin network is more than just a speculative money like asset, it is the most secure distributed computing system ever built. We can jump on the back of this at almost no cost to enable scale for transfer of value, trust, and digital assets of provenance.
Cryptographically assured end points
With the cryptography tools provided through integration of the Bitcoin network we can also use non-blockchain based secure messaging, and identity proofs. 
Micro transactions in collaborative spaces
New tooling the space allows fractions of a pound or dollar to be exchanged between parties across the world. This means that work can be paid “by the second” both inside and outside of the metaverse. This radically improves creative microtask workflows.
World leading open source machine learning and bot architectures
By integrating Stablity AI tools for image generation, video processing, natural language, and speech to text / text to speech we hope to reduce friction within the backstage worlds.
Creating a narrative arrow from a remote director/producer/DP, through a VP screen into a shoot, and back into a persistent metaverse shared with the public
By linking across these new systems with world class telepresence research we hope to use a single digital context to support senior stakeholders, creatives, technical teams, and the wider public.
New paths to monetisation and digital ownership
This unified digital back end is optimised for flows of money, trust, and digital objects. This is a new area for VP.
Current workstreams:
\begin{itemize}
\item Storyboarding with text2img and dreambooth to add talent and costume ideas before meeting up, as demonstrated in this document \cite{ruiz2022dreambooth}.
\item Collaborative, self hosted, high speed, low detail, economically and cryptographically enabled set design spaces, with near instant language translation (speech to text an speech to speech). Micropayment for cheap international labour. Technology agnostic. Use the screen, audio only, compressed video dial-in, headsets, tablet rendering: (this book).
\item High end telepresence \cite{Roberts2015, OHare2018, Fairchild2017, OHare2016} into the studio/shoot from the virtual set, allowing high value stakeholders to be `present` on set as virtual collaborants with spatial descrimination allowing directional queues. This involved real time human capture like moveAI or the expensive rigs with DSLRs.
\item Novel render pipeline for fast turnaround of final look and feel, taking the rough scene and applying img2img ML with the kind of interframe consistency we are starting to see from the video projects \cite{anonymous2023phenaki}.
\item Text to model pipeline for interactively building key elements with senior stakeholders, pushed from post ideation the the  pre-shoot Unreal content creation \cite{poole2022dreamfusion}.
\item All assets switch over to Unreal metaverse and become consistent (optimised) digital set which can be visited by stakeholders, funders, VIPs etc. Public can visit later for a fee? Digital assets can be bought from the set.
\end{itemize}
\subsubsection{VisionFlow: Ideate - Robotic Pre-Visualization}

VisionFlow: Ideate revolutionizes the pre-visualization process in the film industry. The system integrates open-source machine learning tools, robot control software, and AI to streamline and accelerate the creation of virtual 3D environments for new film scenes.\par

Instead of the conventional approach, VisionFlow: Ideate enables non-artists to lay out shots in a simple web or headset interface, much like a traditional storyboard. The generative AI then rapidly creates high-resolution backdrop plates with correct parallax cues, replacing conventional image and video plates.\par

The camera path synchronizes with a robot, and the backdrop plates are displayed on a 3D wall or in the studio mixdown from a green screen within minutes. The shot can be run repeatedly, allowing for adjustments in lighting and scene swapping for different ideas. This approach aligns well with pre-viz workflows, fostering rapid ideation, horizontal scaling through parallelized cloud vGPU, and expanded access to content creators since less software specialization is required.\par

By inverting the conventional ICVFX workflow, VisionFlow: Ideate drives camera motion from the scene rather than scene motion from a tracked camera. It not only saves time and reduces costs but also lowers confusion, streamlining the Unreal creation pipeline, and generating additional revenue and process integration for robotics products.

\subsubsection{VisionFlow: Connect - Telepresence System}

VisionFlow: Connect is a breakthrough system in the film industry that brings remote directors to the heart of production using augmented reality technology. This is achieved through an innovative application of the Apple Vision Pro AR headset.\par

In the VisionFlow: Connect system, the director, located remotely, wears an AR headset and navigates along a marked line. This line mirrors the inward-facing edge of a large-scale, wrap-around LED virtual production facility. Within the LED volume, participants can view the director's avatar, providing a sense of spatial consistency and our work interaction, crucial for effective direction.\par

A novel technique, "ghost frame" by Helios, is employed to prevent the camera within the LED volume from capturing the director's remote avatar on the LED wall. This ensures the director's virtual presence doesn't interfere with the recorded footage.\par

The benefits of VisionFlow: Connect are multifold. It allows senior stakeholders to manage their time more efficiently as they can direct remotely without needing to be physically present on multiple sets. Directors can interact in real-time, giving instantaneous feedback and adjustments. It also enhances directors' spatial awareness of the scene, thereby improving the decision-making process.


bf{Slide 1: Title}  bf{Slide 2: Problem} \\
"VisionFlow: Revolutionizing Virtual Production with AI and Telecollaboration"  "The current ICVFX workflow is time-consuming, costly, and requires specialized software knowledge. Remote collaboration in virtual production is challenging, often breaking the flow of communication and limiting the ability to convey spatial intent." \\
bf{Slide 3: Solution}  bf{Slide 4: Market Size} \\
"VisionFlow aims to streamline the virtual production process by integrating open-source machine learning tools and robot control software. This innovative approach inverts the existing ICVFX workflow, allowing rapid ideation, horizontal scaling, and expanded access to content creators. Furthermore, our ghost frame technology enables seamless remote collaboration, allowing remote stakeholders to interact with the set in a spatially coherent way."  "The virtual production market is rapidly growing, driven by the increasing demand for high-quality visual effects and the rise of remote work. Our solution targets film studios, independent content creators, and remote collaborators." \\
bf{Slide 5: Business Model}  bf{Slide 6: Go-to-Market Strategy} \\
"We will generate revenue through software licensing, cloud-based services, and professional services for setup and training, and our own in house motion control robotics offering"  "Our initial focus will be on early adopters in the film industry who are already using virtual production techniques. We will also leverage the open-source Flossverse telecollaboration stack to expand our reach." \\
bf{Slide 7: Competitive Landscape}  bf{Slide 8: Team} \\
"While there are other virtual production solutions on the market, none offer the unique combination of AI-driven scene generation, inverted ICVFX workflow, and seamless remote collaboration that VisionFlow does."  "Our team combines expertise in AI, virtual production, and telecollaboration, positioning us uniquely to execute on this vision." \\
bf{Slide 9: Financial Projections}  bf{Slide 10: Current Status and Milestones} \\
"We project rapid growth as we capture a significant share of the expanding virtual production market."  "We have already developed an MVP using the Flossverse stack and are now focused on refining the integration and licensing elements of our software." \\
bf{Slide 11: Ask}  bf{Slide 12: Closing Remarks} \\
"We are seeking investment to accelerate our development, expand our team, and bring our innovative solution to market."  "In essence, VisionFlow is poised to revolutionize the virtual production industry by leveraging AI to streamline workflows and enable seamless remote collaboration. With your investment, we can bring this vision to life." \\


\input{eventGaze}

\section{Accessible metaverse for pre-viz}
Pre-visualization (or "pre-viz") is a process in which a rough simulation of a visual effect or scene is created prior to its actual production. In the context of LED wall virtual production, pre-viz refers to the creation of a 3D representation of a virtual environment, including the placement of cameras, actors, and other elements, that is then used to plan and test the visual effects and lighting for a live-action scene that will eventually be shot in front of an LED wall.\par
The pre-viz process allows filmmakers and visual effects artists to experiment with different camera angles, lighting, and visual effects before committing to a final version. This helps to save time and resources during actual production by reducing the need for multiple takes or re-shoots. Additionally, it allows the filmmakers to see how the final product will look before committing to it, which can help to avoid costly mistakes or changes down the line.\par
The LED wall virtual production process typically involves using a combination of 3D animation software, motion capture technology, and real-time rendering to create a virtual environment that accurately reflects the physical environment in which the scene will be shot. The pre-viz process is then used to plan and test the various visual effects, lighting, and camera angles that will be used in the final production.\par 
Our collaborative software stack is potentially ideally suited to some of this pre-viz work, especially when combined with the power of machine learning, and live linked into Unreal so that changes by stakeholders enter the pre-production pipeline in a seamless way.
\section{Novel VP render pipeline}
Putting the ML image generation on the end of a real-time tracked camera render pipeline might remove the need for detail in set building. To describe how this might work, the set designer, DP, director, etc will be able to ideate in a headset based metaverse of the set design, dropping very basic chairs, windows, light sources whatever. There is -no need- then to create a scene in detail. If the interframe consistency (img2img) can deliver then the output on the VP screen can simply inherit the artistic style from the text prompts, and render production quality from the basic building blocks. Everyone in the set (or just DP/director) could then switch in headset to the final output and ideate (verbally) to create the look and feel (lens, bokeh, light, artistic style etc). This isn’t ready yet as the frames need to generate much faster (100x), but it’s very likely coming in months not years. This ``next level pre-vis'' is being trailed in the Vircadia collaborative environment described in this book, and can be seen illustrated in Figure \ref{fig:vircadiasd}.\par
\begin{figure}[ht]\centering 	\includegraphics{vircadiasd}
	\caption{Top panel is a screen grab from Vircadia and the bottom panel is a quick pass through img2img from Stable Diffusion.}
	\label{fig:vircadiasd}
\end{figure}

This can be done now through the use of camera robots. A scene can be built in basic outline, the camera tracks can be encoded into the robot, and the scene can be rapidly post rendered by Stability with high inter frame consistency.\par
With the help of AI projects such as \href{https://nv-tlabs.github.io/LION/}{LION} it may be possible to pass simple geometry and instructions to ML systems which can create complex textured geometry back into the scene.
\begin{figure}[ht]\centering 	\includegraphics{robotvp}
	\caption{Robot VP}
	\label{fig:robotvp}
\end{figure}

\section{Money in metaverses}
\subsubsection{Global collaboration and remuneration}
In the book ``Ghosts of my life'' \cite{fisher2014ghosts} Fisher asserts that there has been a slowing, even a `cancellation' of creative progress in developed societies, their art, and their media. His contention is that neoliberalism itself is to blame. He says\\
it{``It is the contention of this book that 21st-century culture is marked by the same anachronism and inertia which afflicted Sapphire and Steel in their final adventure. But this status has been buried, interred behind a superficial frenzy of ‘newness’, of perpetual movement. The ‘jumbling up of time’, the montaging of earlier eras, has ceased to be worthy of comment; it is now so prevalent that it is no longer even noticed.''}

It is the feeling of the authors of this book that the creative and inspirational efforts of the whole world may be needed to heal these deep wounds. It is possible that by connecting creatives with very different global perspectives, directly into `Western' production pipelines, that we will be able to see the shape of this potential.
\subsection{ML actors and blockchain based bots}
Stablity AI is an open source imitative to bring ML/AL capabilities to the world. This is a hugely exciting emergent area and much more will be developed here.
\subsection{AI economic actors in mixed reality}
AI actors can now be trusted visually \cite{nightingale2022ai}. We have some thinking on this which links the external web to our proposed metaverse. There is work in the community working on economically empowered bots which leverage Nostr and RGB to perform functions within our metaverse, and outside in the WWW, as well as interacting economically through trusted cryptography with other bots, anywhere, and human participants, anywhere. This is incredibly powerful and is assured by the Bitcoin security model. Imagine being able to interact with a bot flower seller representing all the real world florists it had found. In the metaverse you could handle the flowers and take advice and guidance from the bot agent, then it would be able to take your money to buy you flowers to send to a real world address, and later find you to tell you when it's delivered. These possibilities are endless. The AI chat element, the AI translation of images on websites to 3D assets in the Metaverse are difficult but possible challenges, but the secure movement of money from the local context in the metaverse to the real world is within reach using these bots, and they are completely autonomous and distributed.
\section{Our socialisation best practice}
\subsubsection{Identity}
We will base our identity and object management on Nostr public/private key pairs. The public key of these enable lightning based exchange of value globally. %Additional work will be needed to allow objects generated through RGB to be passed between federated worlds.
we plan to operate Nostr in multiple modes. Linking flossverse ``rooms'' will be a Nostr bot to bot system within the private relay mesh. This can also synchronise large amounts of data by leveraging torrents \href{https://iris.to/#/settings}{negotiated by Nostr}. Human to human text chat across and within instances is two 'types' kind of private nostr tag within the private relays mesh. External connectivity to web and nostr apps is just the public relay tags outbound. We don't need to store data external to the flossverse system, though access is obviously possible through the same torrent network.
\subsubsection{Webs of trust}
Webs of trust will be built within worlds using economically costly (but private) social rating systems, between any actor, human or AI. It should be too costly to attack an individual aggressively. This implies an increased weighting for scores issued in short time periods. Poorly behaving AI's will eventually be excluded through lack of funds.
\subsubsection{Integration of 'good' actor AI entities}
Gratitude practice should be encouraged between AI actors to foster trust and wellbeing in human observers. ``It's nice to be nice'' should be incentivised between all parties''. This could include tipping and trust nudging through the social rating system. Great AI behaviour would result in economically powerful entities.
\subsection{Emulation of important social cues}
\href{https://www.cleverclassroomsdesign.co.uk/general-5}{Classroom layout}
\subsubsection{Behaviour incentives, arbitration, and penalties}
Collapses of trust and abuse will trigger flags from ML based oversight, which will create situational records and payloads of involved parties to unlock with their nostr private keys. ML red flagged actors will be finacially penalised but have access to human arbitration using their copy of the data blob. Nothing will be stored except by the end users.
\subsection{Federations of webs of trust and economics}
Nostr is developing fast enough to provide global bridges between metaverse instances.
\section{Security evaluation}
As part of developing our stack we will penetration test the deployment as detailed using \href{https://hexway.io/}{Hexway}

\input{10_otherusecases}
\section{notes for later}
Notes on build-out
The world database in the shared rooms in the metaverse is the global object master,  educational materials, videos,  audio content and branded objects are fungible tokens authentically proved by rgb client side validation between parties,  only validated ones will be persisted in shared rooms like conferences and classes according to the room schema. That allows educators to monetise their content.  That can work on lightning.  NFT objects between parties like content crafted by participants (coursework, homework) are not on lightning and will attract main chain fees but are rarer. User authentication and communication will be through nostr.

\begin{figure*}[ht]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
	\includegraphics{globalclassroom}
	\caption{Functional elements for infrastructure.}
	\label{fig:globalclassroom}
\end{figure*}

\begin{figure*}[ht]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
	\includegraphics{systemc4}
	\caption{Client server C4 diagrams.}
	\label{fig:globalclassroom}
\end{figure*}
