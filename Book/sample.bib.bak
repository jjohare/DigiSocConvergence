@inproceedings{Adalgeirsson2010,
	title        = {{MeBot}: a robotic platform for socially embodied presence},
	author       = {Adalgeirsson, Sigurdur O and Breazeal, Cynthia},
	year         = 2010,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the 5th {ACM/IEEE} international conference on Human-robot interaction},
	location     = {Osaka, Japan},
	publisher    = {IEEE Press},
	series       = {HRI '10},
	pages        = {15--22},
	institution  = {IEEE Press},
	keywords     = {embodied videoconferencing, robot-mediated communication, telepresence, human robot interaction;litsurvey.bib}
}

@inproceedings{Adamczyk2007,
	title        = {Supporting multidisciplinary collaboration: requirements from novel {HCI} education},
	author       = {Adamczyk, Piotr D and Twidale, Michael B},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1073--1076},
	institution  = {ACM},
	keywords     = {low fidelity prototyping, design tools, social bookmarking, design education, multidisciplinary collaboration;litsurvey.bib}
}

@article{aiken2020zooming,
	title        = {Zooming in on privacy concerns: Video app Zoom is surging in popularity. In our rush to stay connected, we need to make security checks and not reveal more than we think},
	author       = {Aiken, Adam},
	year         = 2020,
	journal      = {Index on Censorship},
	publisher    = {SAGE Publications Sage UK: London, England},
	volume       = 49,
	number       = 2,
	pages        = {24--27}
}

@inproceedings{Al_Moubayed2012,
	title        = {Taming Mona Lisa: Communicating Gaze Faithfully In 2d And 3d Facial Projections},
	author       = {Al Moubayed, Samer and Edlund, Jens and Beskow, Jonas},
	year         = 2012,
	volume       = 1,
	pages        = 25,
	keywords     = {litsurvey.bib}
}

@article{Al-Hazaimeh2019,
	title        = {Geometrical-based approach for robust human image detection},
	author       = {Al-Hazaimeh, Obaida M and Al-Nawashi, Malek and Saraee, Mohamad},
	year         = 2019,
	journal      = {Multimedia Tools and Applications},
	publisher    = {Springer},
	volume       = 78,
	number       = 6,
	pages        = {7029--7053},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Al-Hazaimeh2019_Article_Geometrical-basedApproachForRo.pdf:PDF}
}

@inproceedings{Al-Saidi2009,
	title        = {Distributed Collaborative Visualization Using Light Field Rendering},
	author       = {Al-Saidi, A and Avis, N J and Grimstead, I J and Rana, O F},
	year         = 2009,
	month        = {\#may\#},
	booktitle    = {2009 9th {IEEE/ACM} International Symposium on Cluster Computing and the Grid},
	pages        = {609--614},
	abstract     = {Interactive distributed visualization is an emerging technology with numerous applications. However, many of the present approaches of interactive distributed visualization are based on the traditional polygonal processing graphics pipeline. Our research is centred on investigating an alternative method using image-based rendering (IBR) which uses (multiple) images of the scene instead of a 3D geometrical representation. A key advantage to the use of IBR techniques is that the bandwidth required is independent of scene complexity and is therefore predictable given knowledge of the desired final image resolution. In this paper, we describe our IBR based interactive distributed visualization platform involving light field rendering and present results which indicate the scalability of our approach to accommodate multiple collaborative users. To our knowledge this is the first system to demonstrate deployment of interactive light field rendering to large numbers of distributed users.},
	institution  = {IEEE},
	keywords     = {computational geometry;data visualisation;groupware;image representation;image resolution;interactive systems;rendering (computer graphics);distributed collaborative visualization;light field rendering;interactive distributed visualization;polygonal processing graphics pipeline;image-based rendering;3D geometrical representation;scene complexity;image resolution;Collaboration;Visualization;Rendering (computer graphics);Layout;Geometry;Distributed computing;Application software;Pipelines;Bandwidth;Image resolution;Visualization;Distributed Collaborative Environment;Distributed Systems;Client/Server;Distributed Applications.;litsurvey.bib}
}

@inproceedings{Allard2006,
	title        = {The {GrImage} Platform: A Mixed Reality Environment for Interactions},
	author       = {Allard, J and Franco, J and Menier, C and Boyer, E and Raffin, B},
	year         = 2006,
	month        = {\#jan\#},
	booktitle    = {Fourth {IEEE} International Conference on Computer Vision Systems ({ICVS'06})},
	pages        = {46--46},
	abstract     = {In this paper, we present a scalable architecture to compute, visualize and interact with 3D dynamic models of real scenes. This architecture is designed for mixed reality applications requiring such dynamic models, tele-immersion for instance. Our system consists in 3 main parts: the acquisition, based on standard firewire cameras; the computation, based on a distribution scheme over a cluster of PC and using a recent shape-from-silhouette algorithm which leads to optimally precise 3D models; the visualization, which is achieved on a multiple display wall. The proposed distribution scheme ensures scalability of the system and hereby allows control over the number of cameras used for acquisition, the frame-rate, or the number of projectors used for high resolution visualization. To our knowledge this is the first completely scalable vision architecture for real time 3D modeling, from acquisition to visualization through computation. Experimental results show that this framework is very promising for real time 3D interactions.},
	institution  = {IEEE},
	keywords     = {Virtual reality;Visualization;Computer architecture;Firewire;Cameras;Layout;Computer displays;Distributed computing;Clustering algorithms;Three dimensional displays;litsurvey.bib}
}

@article{bastian2021hedging,
	title        = {Hedging renewable energy investments with Bitcoin mining},
	author       = {Bastian-Pinto, Carlos L and Araujo, Felipe V de S and Brand{\~a}o, Luiz E and Gomes, Leonardo L},
	year         = 2021,
	journal      = {Renewable and Sustainable Energy Reviews},
	publisher    = {Elsevier},
	volume       = 138,
	pages        = 110520
}

@article{Allen_Joseph2014,
	title        = {Understanding workplace meetings: A qualitative taxonomy of meeting purposes},
	author       = {Allen Joseph, A and Beck, Tammy and Scott Cliff, W and Rogelberg Steven, G},
	year         = 2014,
	month        = {\#jan\#},
	journal      = {Management Research Review},
	publisher    = {Emerald Group Publishing Limited},
	volume       = 37,
	number       = 9,
	pages        = {791--814},
	abstract     = {Purpose-- The purpose of this study is to propose a taxonomy of meeting purpose. Meetings are a workplace activity that deserves increased attention from researchers and practitioners. Previous researchers attempted to develop typologies of meeting purpose with limited success. Through a comparison of classification methodologies, the authors consider a taxonomy as the appropriate classification scheme for meeting purpose. The authors then utilize the developed taxonomy to investigate the frequency with which a representative sample of working adults engaged in meetings of these varying purposes. Their proposed taxonomy provides relevant classifications for future research on meetings as well and serves as a useful tool for managers seeking to use and evaluate the effectiveness of meetings within their organizations. Design/methodology/approach-- This study employs an inductive methodology using discourse analysis of qualitative meeting descriptions to develop a taxonomy of meeting purpose. The authors discourse analysis utilizes open-ended survey responses from a sample of working adults (n = 491). Findings-- The authors categorical analysis of open-ended questions resulted in a 16-category taxonomy of meeting purpose. The two most prevalent meeting purpose categories in this sample were ``to discuss ongoing projects'' at 11.6 per cent and ``to routinely discuss the state of the business'' at 10.8 per cent. The two least common meeting purpose categories in this sample were ``to brainstorm for ideas or solutions'' at 3.3 per cent and ``to discuss productivity and efficiencies'' at 3.7 per cent. The taxonomy was analyzed across organizational type and employee job level to identify differences between those important organizational and employee characteristics. Research limitations/implications-- The data suggested that meetings were institutionalized in organizations, making them useful at identifying differences between organizations as well as differences in employees in terms of scope of responsibility. Researchers and managers should consider the purposes for which they call meetings and how that manifests their overarching organizational focus, structure and goals. Originality/value-- This is the first study to overtly attempt to categorize the various purposes for which meetings are held. Further, this study develops a taxonomy of meeting purposes that will prove useful for investigating the different types of meeting purposes in a broad range of organizational types and structures.},
	keywords     = {litsurvey.bib}
}

@article{Alspaugh2018,
	title        = {Futzing and moseying: Interviews with professional data analysts on exploration practices},
	author       = {Alspaugh, Sara and Zokaei, Nava and Liu, Andrea and Jin, Cindy and Hearst, Marti A},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {22--31},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440815.pdf:PDF}
}

@book{ammous2018bitcoin,
	title        = {The bitcoin standard: the decentralized alternative to central banking},
	author       = {Ammous, Saifedean},
	year         = 2018,
	publisher    = {John Wiley \& Sons},
	file         = {:../../../literature_repository/bitcoin/The Bitcoin Standard.pdf:PDF}
}

@article{oxford2021salvador,
	title        = {El Salvador bitcoin experiment comes with risks},
	author       = {Oxford Analytica},
	year         = 2021,
	journal      = {Emerald Expert Briefings},
	publisher    = {Oxford Analytica},
	number       = {oxan-db}
}

@inproceedings{Andersen2019,
	title        = {Immersion or Diversion: Does Virtual Reality Make Data Visualisation More Effective?},
	author       = {Andersen, Benjamin JH and Davis, Arran TA and Weber, Gerald and W{\"u}nsche, Burkhard C},
	year         = 2019,
	booktitle    = {2019 International Conference on Electronics, Information, and Communication (ICEIC)},
	pages        = {1--7},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08706403.pdf:PDF}
}

@inproceedings{Anstis1969,
	title        = {The Perception of Where a Face or Television Portrait is Looking},
	author       = {Anstis, Stuart M and Mayhew, John W and Morley, Tania},
	year         = 1969,
	publisher    = {JSTOR},
	volume       = 82,
	pages        = {474--489},
	keywords     = {litsurvey.bib}
}

@phdthesis{Antley2014-en,
	title        = {Human Balance Behaviour in Immersive Virtual Environments},
	author       = {Antley, Angus},
	year         = 2014,
	school       = {UCL (University College London)},
	keywords     = {litsurvey.bib}
}

@book{antonopoulos2017mastering,
	title        = {Mastering Bitcoin: Programming the open blockchain},
	author       = {Antonopoulos, Andreas M},
	year         = 2017,
	publisher    = {" O'Reilly Media, Inc."},
	file         = {:../../../literature_repository/bitcoin/Mastering-bitcoin-2nd.pdf:PDF}
}

@inproceedings{Aoki2003,
	title        = {The mad hatter's cocktail party: a social mobile audio space supporting multiple simultaneous conversations},
	author       = {Aoki, Paul M and Romaine, Matthew and Szymanski, Margaret H and Thornton, James D and Wilson, Daniel and Woodruff, Allison},
	year         = 2003,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Ft. Lauderdale, Florida, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '03},
	pages        = {425--432},
	institution  = {ACM},
	keywords     = {floor management, audio space, conversation analysis;litsurvey.bib}
}

@book{Bhatia2021,
	title        = {Layered Money},
	author       = {Bhatia, Nikhil},
	year         = 1988,
	publisher    = {Self Quoted},
	keywords     = {sample.bib}
}

@book{Argyle1976,
	title        = {Gaze and Mutual Gaze},
	author       = {Argyle, Michael and Cook, Mark},
	year         = 1976,
	month        = {\#jan\#},
	publisher    = {Cambridge University Press},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Argyle1965,
	title        = {Eye-contact, Distance And Affiliation},
	author       = {Argyle, Michael and Dean, Janet},
	year         = 1965,
	publisher    = {JSTOR},
	pages        = {289--304},
	keywords     = {litsurvey.bib}
}

@inproceedings{Argyle1976,
	title        = {The Central Europe Experiment: Looking at Persons and Looking at Objects},
	author       = {Argyle, Michael and Graham, Jean Ann},
	year         = 1976,
	volume       = 1,
	pages        = {6--16},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@book{Argyle1969,
	title        = {Gaze, Mutual Gaze, and Proximity},
	author       = {Argyle, Michael and Ingham, Roger},
	year         = 1969,
	keywords     = {litsurvey.bib}
}

@article{Arvey2009,
	title        = {Why face-to-face business meetings matter},
	author       = {Arvey, Richard D},
	year         = 2009,
	journal      = {White Paper for the Hilton Group},
	keywords     = {litsurvey.bib}
}

@inproceedings{Atzpadin2004,
	title        = {Stereo Analysis By Hybrid Recursive Matching For Real-time Immersive Video Conferencing},
	author       = {Atzpadin, Nicole and Kauff, Peter and Schreer, Oliver},
	year         = 2004,
	publisher    = {IEEE},
	volume       = 14,
	pages        = {321--334},
	keywords     = {litsurvey.bib}
}

@inproceedings{Avrahami2007,
	title        = {Biases in human estimation of interruptibility: effects and implications for practice},
	author       = {Avrahami, Daniel and Fogarty, James and Hudson, Scott E},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {50--60},
	institution  = {ACM},
	keywords     = {interruptibility, ubiquitous computing, availability, awareness, computer mediated communication, context aware computing;litsurvey.bib}
}

@article{Axon2019,
	title        = {Hearing attacks in network data: An effectiveness study},
	author       = {Axon, Louise and Happa, Jassim and Goldsmith, Michael and Creese, Sadie},
	year         = 2019,
	journal      = {Computers \& Security},
	publisher    = {Elsevier},
	volume       = 83,
	pages        = {367--388},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0167404818303377-main.pdf:PDF}
}

@article{Back2014,
	title        = {Enabling blockchain innovations with pegged sidechains},
	author       = {Back, Adam and Corallo, Matt and Dashjr, Luke and Friedenbach, Mark and Maxwell, Gregory and Miller, Andrew and Poelstra, Andrew and Tim{\'o}n, Jorge and Wuille, Pieter},
	year         = 2014,
	journal      = {URL: http://www. opensciencereview. com/papers/123/enablingblockchain-innovations-with-pegged-sidechains},
	volume       = 72,
	file         = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\sidechains.pdf:PDF}
}

@article{back2002hashcash,
	title        = {Hashcash-a denial of service counter-measure},
	author       = {Back, Adam and others},
	year         = 2002
}

@inproceedings{Bailenson2002,
	title        = {Gaze And Task Performance In Shared Virtual Environments},
	author       = {Bailenson, Jeremy N and Beall, Andrew C and Blascovich, Jim},
	year         = 2002,
	volume       = 13,
	pages        = {313--320},
	keywords     = {copresence, mutual gaze, organizational behaviour, presence, video conferencing;litsurvey.bib}
}

@article{Bailenson2003,
	title        = {Interpersonal distance in immersive virtual environments},
	author       = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis, Jack M},
	year         = 2003,
	month        = {\#jul\#},
	journal      = {Pers. Soc. Psychol. Bull.},
	publisher    = {Sage Publications},
	volume       = 29,
	number       = 7,
	pages        = {819--833},
	abstract     = {Digital immersive virtual environment technology (IVET) enables behavioral scientists to conduct ecologically realistic experiments with near-perfect experimental control. The authors employed IVET to study the interpersonal distance maintained between participants and virtual humans. In Study 1, participants traversed a three-dimensional virtual room in which a virtual human stood. In Study 2, a virtual human approached participants. In both studies, participant gender, virtual human gender, virtual human gaze behavior, and whether virtual humans were allegedly controlled by humans (i.e., avatars) or computers (i.e., agents) were varied. Results indicated that participants maintained greater distance from virtual humans when approaching their fronts compared to their backs. In addition, participants gave more personal space to virtual agents who engaged them in mutual gaze. Moreover, when virtual humans invaded their personal space, participants moved farthest from virtual human agents. The advantages and disadvantages of IVET for the study of human behavior are discussed.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Bailenson2003,
	title        = {Interpersonal Distance In Immersive Virtual Environments},
	author       = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis, Jack M},
	year         = 2003,
	publisher    = {Sage Publications},
	volume       = 29,
	pages        = {819--833},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bailenson2001,
	title        = {Equilibrium theory revisited: Mutual gaze and personal space in virtual environments},
	author       = {Bailenson, Jeremy N and Blascovich, Jim and Beall, Andrew C and Loomis, Jack M},
	year         = 2001,
	publisher    = {MIT Press},
	volume       = 10,
	pages        = {583--598},
	keywords     = {litsurvey.bib}
}

@article{Bailenson2006,
	title        = {The Effect of Behavioral Realism and Form Realism of {Real-Time} Avatar Faces on Verbal Disclosure, Nonverbal Disclosure, Emotion Recognition, and Copresence in Dyadic Interaction},
	author       = {Bailenson, Jeremy N and Yee, Nick and Merget, Dan and Schroeder, Ralph},
	year         = 2006,
	month        = {\#aug\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 15,
	number       = 4,
	pages        = {359--372},
	abstract     = {Abstract The realism of avatars in terms of behavior and form is critical to the development of collaborative virtual environments. In the study we utilized state of the art, real-time face tracking technology to track and render facial expressions unobtrusively in a desktop CVE. Participants in dyads interacted with each other via either a video-conference (high behavioral realism and high form realism), voice only (low behavioral realism and low form realism), or an ?emotibox? that rendered the dimensions of facial expressions abstractly in terms of color, shape, and orientation on a rectangular polygon (high behavioral realism and low form realism). Verbal and non-verbal self-disclosure were lowest in the videoconference condition while self-reported copresence and success of transmission and identification of emotions were lowest in the emotibox condition. Previous work demonstrates that avatar realism increases copresence while decreasing self-disclosure. We discuss the possibility of a hybrid realism solution that maintains high copresence without lowering self-disclosure, and the benefits of such an avatar on applications such as distance learning and therapy.},
	keywords     = {litsurvey.bib}
}

@article{Baker1977,
	title        = {{Three-Dimensional} Modeling},
	author       = {Baker, Harlyn},
	year         = 1977,
	volume       = 2,
	pages        = 649,
	keywords     = {litsurvey.bib}
}

@inproceedings{Balogh2010,
	title        = {Real-time {3D} light field transmission},
	author       = {Balogh, Tibor and Kov{\'a}cs, P{\'e}ter Tam{\'a}s},
	year         = 2010,
	month        = {\#may\#},
	booktitle    = {{Real-Time} Image and Video Processing 2010},
	publisher    = {International Society for Optics and Photonics},
	volume       = 7724,
	pages        = 772406,
	abstract     = {Although capturing and displaying stereo 3D content is now commonplace, information-rich light-field video content capture, transmission and display are much more challenging, resulting in at least one order of magnitude increase in complexity even in the simplest cases. We present an end-to-end system capable of capturing and real-time displaying of high-quality light-field video content on various HoloVizio light-field displays, providing very high 3D image quality and continuous motion parallax. The system is compact in terms of number of computers, and provides superior image quality, resolution and frame rate compared to other published systems. To generate light-field content, we have built a camera system with a large number of cameras and connected them to PC computers. The cameras were in an evenly spaced linear arrangement. The capture PC was directly connected through a single gigabit Ethernet connection to the demonstration 3D display, supported by a PC computation cluster. For the task of dense light field displaying massively parallel reordering and filtering of the original camera images is required. We were utilizing both CPU and GPU threads for this task. On the GPU we do the light-field conversion and reordering, filtering and the YUV-RGB conversion. We use OpenGL 3.0 shaders and 2D texture arrays to have easy access to individual camera images. A network-based synchronization scheme is used to present the final rendered images.},
	conference   = {Real-Time Image and Video Processing 2010},
	keywords     = {Lightfield; Light-field; 3D video; HoloVizio; 3D capture; Rendering; Camera array; 3D display; ; ; ; ; ; ; ; ;litsurvey.bib}
}

@inproceedings{Bandyopadhyay2001,
	title        = {Dynamic shader lamps : painting on movable objects},
	author       = {Bandyopadhyay, D and Raskar, R and Fuchs, H},
	year         = 2001,
	month        = {\#oct\#},
	booktitle    = {Proceedings {IEEE} and {ACM} International Symposium on Augmented Reality},
	publisher    = {IEEE Comput. Soc},
	pages        = {207--216},
	abstract     = {The authors present a Dynamic Spatially Augmented Reality system for augmenting movable 3D objects in an indoor environment using multiple projectors. We describe a real-time system for applying virtual paint and textures to real objects simply by direct physical manipulation of the object and a ``paint brush'' stylus. We track the objects and the ``paint brush'', and illuminate the objects with images that remain registered as they move, to create the illusion of material properties. The system is simple to use and we hope it may herald new applications in diverse fields such as visualization, tele-immersion, art and architecture. The system currently works with tracked objects whose geometry was pre-acquired and models created manually, but it is possible to extend it by adding cameras to the environment, to acquire object geometry automatically and use vision-based tracking for the object and paintbrush. Plus colour plates.},
	keywords     = {augmented reality;real-time systems;image registration;computer graphics;dynamic shader lamps;Dynamic Spatially Augmented Reality system;movable 3D objects;indoor environment;multiple projectors;real-time system;virtual paint;virtual textures;real objects;direct physical manipulation;paint brush stylus;material properties;visualization;tele-immersion;art;tracked objects;cameras;object geometry;vision-based tracking;Lamps;Painting;Paints;Brushes;Geometry;Augmented reality;Indoor environments;Real time systems;Material properties;Visualization;litsurvey.bib}
}

@inproceedings{Bardram2012,
	title        = {{ReticularSpaces}: activity-based computing support for physically distributed and collaborative smart spaces},
	author       = {Bardram, Jakob and Gueddana, Sofiane and Houben, Steven and Nielsen, S{\o}ren},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {2845--2854},
	institution  = {ACM},
	keywords     = {smart spaces, nomadic computing, multiple display environments, distributed user interfaces, collaboration;litsurvey.bib}
}

@inproceedings{Bartneck2009,
	title        = {My robotic doppelg{\"a}nger-A critical look at the uncanny valley},
	author       = {Bartneck, Christoph and Kanda, Takayuki and Ishiguro, Hiroshi and Hagita, Norihiro},
	year         = 2009,
	booktitle    = {Robot and Human Interactive Communication, 2009.},
	pages        = {269--276},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bartneck2007,
	title        = {Is The Uncanny Valley An Uncanny Cliff?},
	author       = {Bartneck, C and Kanda, T and Ishiguro, H and Hagita, N},
	year         = 2007,
	month        = {\#aug\#},
	booktitle    = {{RO-MAN} 2007 - The 16th {IEEE} International Symposium on Robot and Human Interactive Communication},
	pages        = {368--373},
	abstract     = {The uncanny valley theory proposed by Mori in 1970 has been a hot topic in human robot interaction research, in particular since the development of increasingly human-like androids and computer graphics. In this paper we describe an empirical study that attempts to plot Mori's hypothesized curve. In addition, the influence of framing on the users' perception of the stimuli was investigated. Framing had no significant influence on the measurements. The pictures of robots and humans were rated independently of whether the participants knew a particular picture showed a robot or human. Anthropomorphism had a significant influence on the measurements, but not even pictures of real humans were rated as likeable as the pictures of humanoids or toy robots. As a result we suggest the existence of an uncanny cliff model as an alternative to the uncanny valley model. However, this study focused on the perception of pictures of robots and the results, including the suggested model, may be different for the perception of movies of moving robots or the perception of standing right in front of a moving robot.},
	institution  = {IEEE},
	keywords     = {humanoid robots;man-machine systems;uncanny valley theory;human robot interaction research;human-like android;computer graphics;anthropomorphism;toy robots;Human robot interaction;Humanoid robots;Motion pictures;Service robots;Intelligent robots;Anthropomorphism;Communication industry;Computer industry;Computer graphics;Animation;litsurvey.bib}
}

@article{Bartneck2009,
	title        = {Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots},
	author       = {Bartneck, Christoph and Kuli{\'c}, Dana and Croft, Elizabeth and Zoghbi, Susana},
	year         = 2009,
	journal      = {International journal of social robotics},
	publisher    = {Springer},
	volume       = 1,
	number       = 1,
	pages        = {71--81},
	keywords     = {litsurvey.bib}
}

@article{Batch2017,
	title        = {The interactive visualization gap in initial exploratory data analysis},
	author       = {Batch, Andrea and Elmqvist, Niklas},
	year         = 2017,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 24,
	number       = 1,
	pages        = {278--287},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08017577.pdf:PDF}
}

@inproceedings{Baumgart1975,
	title        = {A polyhedron representation for computer vision},
	author       = {Baumgart, Bruce G},
	year         = 1975,
	month        = {\#may\#},
	booktitle    = {Proceedings of the May 19-22, 1975, national computer conference and exposition},
	location     = {Anaheim, California},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {AFIPS '75},
	pages        = {589--596},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bautista2008,
	title        = {An empirical evaluation of interactive visualizations for preferential choice},
	author       = {Bautista, Jeanette and Carenini, Giuseppe},
	year         = 2008,
	booktitle    = {Proceedings of the working conference on Advanced visual interfaces},
	pages        = {207--214},
	organization = {ACM},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p207-bautista.pdf:PDF}
}

@inproceedings{Beck2011,
	title        = {Synthesizing presence: A multidisciplinary review of the literature},
	author       = {Beck, Dennis and Fishwick, Paul and Kamhawi, Rasha and Coffey, Amy Jo and Henderson, Julie},
	year         = 2011,
	volume       = 3,
	keywords     = {litsurvey.bib}
}

@inproceedings{Beck2013,
	title        = {Immersive group-to-group telepresence},
	author       = {Beck, Stephan and Kunert, Andre and Kulik, Alexander and Froehlich, Bernd},
	year         = 2013,
	publisher    = {IEEE},
	volume       = 19,
	pages        = {616--625},
	keywords     = {litsurvey.bib}
}

@unpublished{Bekkering2006,
	title        = {Trust in videoconferencing},
	author       = {Bekkering, Ernst and Shim, J P},
	year         = 2006,
	month        = {\#jul\#},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bekkering2006,
	title        = {Trust In Videoconferencing},
	author       = {Bekkering, Ernst and Shim, J P},
	year         = 2006,
	publisher    = {ACM},
	volume       = 49,
	pages        = {103--107},
	keywords     = {litsurvey.bib}
}

@inproceedings{Belhumeur1993,
	title        = {A binocular stereo algorithm for reconstructing sloping, creased, and broken surfaces in the presence of half-occlusion},
	author       = {Belhumeur, Peter N},
	year         = 1993,
	booktitle    = {Computer Vision, 1993. Proceedings., Fourth International Conference on},
	pages        = {431--438},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@inproceedings{Benford1995-ln,
	title        = {{User embodiment in collaborative virtual environments}},
	author       = {Benford, Steve and Bowers, John and Fahl{\'e}n, Lennart E and Greenhalgh, Chris and Snowdon, Dave},
	year         = 1995,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Denver, Colorado, USA},
	publisher    = {ACM Press/Addison-Wesley Publishing Co.},
	address      = {USA},
	series       = {CHI '95},
	pages        = {242--249},
	keywords     = {litsurvey.bib}
}

@unpublished{Benford1998,
	title        = {Understanding and constructing shared spaces with mixed-reality boundaries},
	author       = {Benford, Steve and Greenhalgh, Chris and Reynard, Gail and Brown, Chris and Koleva, Boriana},
	year         = 1998,
	month        = {\#sep\#},
	keywords     = {telepresence, shared spaces, media-spaces, CSCW, virtual reality, mixed reality, video, collaborative virtual environments, augmented reality;litsurvey.bib}
}

@incollection{Benford1995,
	title        = {Virtual environments for data sharing and visualisationâ€”populated information terrains},
	author       = {Benford, Steve and Mariani, John},
	year         = 1995,
	booktitle    = {Interfaces to Database Systems (IDS94)},
	publisher    = {Springer},
	pages        = {168--182},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Virtual Environments for Data Sharing and Visu.pdf:PDF}
}

@article{Benjamin2012,
	title        = {Shader lamps virtual patients: the physical manifestation of virtual patients},
	author       = {Benjamin, L O K},
	year         = 2012,
	journal      = {Medicine Meets Virtual Reality 19: NextMed},
	publisher    = {IOS Press},
	volume       = 173,
	pages        = 372,
	keywords     = {litsurvey.bib}
}

@inproceedings{Benko2012,
	title        = {{MirageTable}: freehand interaction on a projected augmented reality tabletop},
	author       = {Benko, Hrvoje and Jota, Ricardo and Wilson, Andrew},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {199--208},
	institution  = {ACM},
	keywords     = {projector-camera system, spatial augmented reality, shared task space, 3d interaction, 3d teleconferencing, depth camera, projective textures, 3d digitization;litsurvey.bib}
}

@inproceedings{Benko2014,
	title        = {Dyadic projected spatial augmented reality},
	author       = {Benko, Hrvoje and Wilson, Andrew D and Zannier, Federico},
	year         = 2014,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 27th annual {ACM} symposium on User interface software and technology},
	location     = {Honolulu, Hawaii, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '14},
	pages        = {645--655},
	institution  = {ACM},
	keywords     = {depth cameras, augmented reality, projector camera system;litsurvey.bib}
}

@inproceedings{Bente1998,
	title        = {Sex Differences In Body Movement And Visual Attention: An Integrated Analysis Of Movement And Gaze In Mixed-sex Dyads},
	author       = {Bente, Gary and Donaghy, W C and Suwelack, Dorit},
	year         = 1998,
	volume       = 22,
	keywords     = {litsurvey.bib}
}

@article{Berger1975,
	title        = {Some Explorations in Initial Interaction and Beyond: Toward a Developmental Theory of Interpersonal Communication},
	author       = {Berger, Charles R and Calabrese, Richard J},
	year         = 1975,
	month        = {\#dec\#},
	journal      = {Hum. Commun. Res.},
	publisher    = {Oxford Academic},
	volume       = 1,
	number       = 2,
	pages        = {99--112},
	abstract     = {Abstract. This paper provides a theoretical perspective for dealing with the initial entry stage of interpersonal interaction. The seven axioms and 21 theorems},
	keywords     = {interpersonal relations;litsurvey.bib}
}

@misc{solidPages,
	title        = {Solid Project Web Page},
	author       = {Berners-Lee, Tim},
	year         = 2016,
	url          = {https://www.solidproject.org},
	owner        = {its352},
	timestamp    = {2021.12.02}
}

@misc{semanticWeb,
	title        = {Weaving the web},
	author       = {Berners-Lee, Tim; Fischetti, Mark},
	year         = 1999,
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://archive.org/details/isbn_9780062515872/mode/2up}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@inproceedings{Beyer2011,
	title        = {Audience behavior around large interactive cylindrical screens},
	author       = {Beyer, Gilbert and Alt, Florian and M{\"u}ller, J{\"o}rg and Schmidt, Albrecht and Isakovic, Karsten and Klose, Stefan and Schiewe, Manuel and Haulsen, Ivo},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {1021--1030},
	institution  = {ACM},
	keywords     = {public displays, cylindrical screens, interactive surfaces, digital columns, non-planar screens, display formats;litsurvey.bib}
}

@article{Bezrukova2009,
	title        = {Do Workgroup Faultlines Help or Hurt? A Moderated Model of Faultlines, Team Identification, and Group Performance},
	author       = {Bezrukova, Katerina and Jehn, Karen A and Zanutto, Elaine L and Thatcher, Sherry M B},
	year         = 2009,
	month        = {\#feb\#},
	journal      = {Organization Science},
	publisher    = {INFORMS},
	volume       = 20,
	number       = 1,
	pages        = {35--50},
	abstract     = {In this study we examine a moderated model of group faultlines, team identification, and group performance outcomes. We extend research on faultlines by showing how different faultline bases (social category and information-based faultlines) may have differential effects on the performance of groups. In addition to faultline strength (the extent of demographic alignment across members within a group), we examine the distance between faultline-based subgroups (e.g., two members of age 20 are closer in age to two members of an opposing subgroup of age 25 than of two members of age 50). We test our model using an archival field methodology and multiple-source data (qualitative and quantitative) from 76 workgroups in a Fortune 500 information-processing company. Our results revealed that groups with social category faultlines had low team discretionary awards. Faultline distance further exacerbated the negative effects of strength in groups with social category faultlines and produced similarly negative effects in groups with information-based faultlines. Team identification served as a moderator enhancing performance of groups with information-based faultlines.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bhardwaj2019,
	title        = {Hadoop based Analysis and Visualization of Diabetes Data through Tableau},
	author       = {Bhardwaj, Priti and Baliyan, Niyati},
	year         = 2019,
	booktitle    = {2019 Twelfth International Conference on Contemporary Computing (IC3)},
	pages        = {1--5},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08844873.pdf:PDF}
}

@inproceedings{Biocca1997,
	title        = {The Cyborg Dilemma : Embodiment in Virtual Environments},
	author       = {Biocca, Frank},
	year         = 1997,
	pages        = {12--26},
	keywords     = {be explosive, cyborgs, embodiment, human-computer interaction, it casts long, lighting the horizon as, note, part of keynote, presence, the following text was, virtual reality;litsurvey.bib}
}

@article{Biocca1997,
	title        = {The Cyborg's Dilemma: Progressive Embodiment in Virtual Environments},
	author       = {Biocca, Frank},
	year         = 1997,
	month        = {\#sep\#},
	journal      = {J. Comput. Mediat. Commun.},
	publisher    = {Oxford Academic},
	volume       = 3,
	number       = 2,
	pages        = {0--0},
	abstract     = {Abstract. How does the changing representation of the body in virtual environments affect the mind? This article considers how virtual reality interfaces are e},
	keywords     = {litsurvey.bib}
}

@inproceedings{Biocca2003,
	title        = {Toward a more robust theory and measure of social presence: Review and suggested criteria},
	author       = {Biocca, Frank and Harms, Chad and Burgoon, Judee},
	year         = 2003,
	publisher    = {MIT press},
	volume       = 12,
	pages        = {456--480},
	keywords     = {litsurvey.bib}
}

@article{Biocca2003,
	title        = {Toward a More Robust Theory and Measure of Social Presence: Review and Suggested Criteria},
	author       = {Biocca, Frank and Harms, Chad and Burgoon, Judee K},
	year         = 2003,
	month        = {\#oct\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 12,
	number       = 5,
	pages        = {456--480},
	abstract     = {At a time of increased social usage of net and collaborative applications, a robust and detailed theory of social presence could contribute to our understanding of social behavior in mediated environments, allow researchers to predict and measure differences among media interfaces, and guide the design of new social environments and interfaces. A broader theory of social presence can guide more valid and reliable measures. The article reviews, classifies, and critiques existing theories and measures of social presence. A set of criteria and scope conditions is proposed to help remedy limitations in past theories and measures and to provide a contribution to a more robust theory and measure of social presence.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Blanche2010,
	title        = {Holographic three-dimensional telepresence using large-area photorefractive polymer},
	author       = {Blanche, P-A and Bablumian, A and Voorakaranam, R and Christenson, C and Lin, W and Gu, T and Flores, D and Wang, P and Hsieh, W-Y and Kathaperumal, M and Rachwal, B and Siddiqui, O and Thomas, J and Norwood, R a and Yamamoto, M and Peyghambarian, N},
	year         = 2010,
	volume       = 468,
	pages        = {80--83},
	abstract     = {Holography is a technique that is used to display objects or scenes in three dimensions. Such three-dimensional (3D) images, or holograms, can be seen with the unassisted eye and are very similar to how humans see the actual environment surrounding them. The concept of 3D telepresence, a real-time dynamic hologram depicting a scene occurring in a different location, has attracted considerable public interest since it was depicted in the original Star Wars film in 1977. However, the lack of sufficient computational power to produce realistic computer-generated holograms and the absence of large-area and dynamically updatable holographic recording media have prevented realization of the concept. Here we use a holographic stereographic technique and a photorefractive polymer material as the recording medium to demonstrate a holographic display that can refresh images every two seconds. A 50\textbackslashquotesinglbase{\"A}{\^a}Hz nanosecond pulsed laser is used to write the holographic pixels. Multicoloured holographic 3D images are produced by using angular multiplexing, and the full parallax display employs spatial multiplexing. 3D telepresence is demonstrated by taking multiple images from one location and transmitting the information via Ethernet to another location where the hologram is printed with the quasi-real-time dynamic 3D display. Further improvements could bring applications in telemedicine, prototyping, advertising, updatable 3D maps and entertainment.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Blandford2008,
	title        = {Controlled Experiments},
	author       = {Blandford, Ann and Cox, Anna and Cairns, Paul},
	year         = 2008,
	keywords     = {litsurvey.bib}
}

@inproceedings{Blascovich2002,
	title        = {A theoretical model of social influence for increasing the utility of collaborative virtual environments},
	author       = {Blascovich, Jim},
	year         = 2002,
	month        = {\#sep\#},
	booktitle    = {Proceedings of the 4th international conference on Collaborative virtual environments},
	location     = {Bonn, Germany},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CVE '02},
	pages        = {25--30},
	keywords     = {agency, behavioral realism, self-relevance, social influence;litsurvey.bib}
}

@article{Bloom2015,
	title        = {Does working from home work? Evidence from a Chinese experiment},
	author       = {Bloom, Nicholas and Liang, James and Roberts, John and Ying, Zhichun Jenny},
	year         = 2015,
	journal      = {Q. J. Econ.},
	publisher    = {MIT Press},
	volume       = 130,
	number       = 1,
	pages        = {165--218},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bo_Shu2008,
	title        = {{Hardware-based camera calibration and {3D} modelling under circular motion}},
	author       = {{Bo Shu} and {Xianjie Qiu} and {Zhaoqi Wang}},
	year         = 2008,
	month        = {\#jun\#},
	booktitle    = {2008 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	pages        = {1--6},
	abstract     = {In this paper, we present a combined camera calibration and image based modeling method using an iterative optimization of shape from silhouette under circular motion. By minimizing the difference between the projections of reconstructed visual hull and the silhouette images using graphics hardware, the optimization can finally converge to accurate camera parameters and realistic visual hull efficiently and robustly. Using this method, we can automatically create photorealistic 3D models directly from images.},
	keywords     = {image motion analysis;image reconstruction;image sensors;optimisation;realistic images;solid modelling;hardware-based camera calibration;photorealistic 3D modelling;circular motion;image based modeling method;iterative optimization;reconstructed visual hull;silhouette image;graphics hardware;Cameras;Calibration;Iterative methods;Optimization methods;Shape;Image reconstruction;Graphics;Hardware;Image converters;Robustness;litsurvey.bib}
}

@article{Bock2008,
	title        = {How precise is gaze following in humans?},
	author       = {Bock, Simon W and Dicke, Peter and Thier, Peter},
	year         = 2008,
	month        = {\#mar\#},
	journal      = {Vision Res.},
	publisher    = {Elsevier},
	volume       = 48,
	number       = 7,
	pages        = {946--957},
	abstract     = {Gaze following is the basis of joint visual attention. We investigated the capability of human 'receivers' to single out one of many objects, defined by the gaze of a human or computer 'sender'. Deviations from the sender's target were normally distributed and judgements were highly accurate. Accuracy of gaze following under binocular and monocular vision of the receiver did not differ, but performance was poorer when only one of the sender's eyes was visible. Two types of systematic bias could be identified: upward bias and cardinal-axis bias. In summary, human gaze following is not only very precise but also surprisingly robust to manipulations of the sender cues available for guiding the receiver's eyes.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Bohannon2013,
	title        = {Eye contact and video-mediated communication: A review},
	author       = {Bohannon, Leanne S and Herbert, Andrew M and Pelz, Jeff B and Rantanen, Esa M},
	year         = 2013,
	month        = {\#apr\#},
	journal      = {Displays},
	publisher    = {Elsevier},
	volume       = 34,
	number       = 2,
	pages        = {177--185},
	abstract     = {A relatively new form of human communication, video-conferencing has become more popular as video technology improves and with increasing demands for real-time communication across greater distances. The full effects of video-conferencing on human communication are still being explored. Video-conferencing is presumed to be a somewhat richer form of communication than email and telephone, but not quite as informative as face-to-face communication. This review explores research into the influence of eye contact on communication and how video-conferencing mediates both verbal and non-verbal interactions. Facilitation of eye contact is a challenge that must be addressed so that video-conferencing can approach the rich interactions of face-to-face communication.},
	keywords     = {Video-conferencing; Eye contact; Communication; Eye-tracking; Display; Laptop;litsurvey.bib}
}

@article{Boker2011,
	title        = {Something in the way we move: Motion dynamics, not perceived sex, influence head movements in conversation},
	author       = {Boker, Steven M and Cohn, Jeffrey F and Theobald, Barry-John and Matthews, Iain and Mangini, Michael and Spies, Jeffrey R and Ambadar, Zara and Brick, Timothy R},
	year         = 2011,
	month        = {\#jun\#},
	journal      = {J. Exp. Psychol. Hum. Percept. Perform.},
	publisher    = {American Psychological Association},
	volume       = 37,
	number       = 3,
	pages        = {874--891},
	abstract     = {During conversation, women tend to nod their heads more frequently and more vigorously than men. An individual speaking with a woman tends to nod his or her head more than when speaking with a man. Is this due to social expectation or due to coupled motion dynamics between the speakers? We present a novel methodology that allows us to randomly assign apparent identity during free conversation in a video-conference, thereby dissociating apparent sex from motion dynamics. The method uses motion-tracked synthesized avatars that are accepted by naive participants as being live video. We find that 1) motion dynamics affect head movements but that apparent sex does not; 2) judgments of sex are driven almost entirely by appearance; and 3) ratings of masculinity and femininity rely on a combination of both appearance and dynamics. Together, these findings are consistent with the hypothesis of separate perceptual streams for appearance and biological motion. In addition, our results are consistent with a view that head movements in conversation form a low level perception and action system that can operate independently from top-down social expectations.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Bolton2012,
	title        = {A comparison of competitive and cooperative task performance using spherical and flat displays},
	author       = {Bolton, John and Kim, Kibum and Vertegaal, Roel},
	year         = 2012,
	month        = {\#feb\#},
	booktitle    = {Proceedings of the {ACM} 2012 conference on Computer Supported Cooperative Work},
	location     = {Seattle, Washington, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '12},
	pages        = {529--538},
	institution  = {ACM},
	keywords     = {shared space, organic user interfaces, collaboration, spherical displays;litsurvey.bib}
}

@inproceedings{Bondareva2004,
	title        = {Determinants of social presence in videoconferencing},
	author       = {Bondareva, Yevgenia and Bouwhuis, Don},
	year         = 2004,
	booktitle    = {{AVI2004} Workshop on Environments for Personalized Information Access},
	pages        = {1--9},
	institution  = {Citeseer},
	keywords     = {litsurvey.bib}
}

@inproceedings{Boote2005,
	title        = {Scholars Before Researchers: On The Centrality Of The Dissertation Literature Review In Research Preparation},
	author       = {Boote, David N and Beile, Penny},
	year         = 2005,
	publisher    = {Sage Publications},
	volume       = 34,
	pages        = {3--15},
	keywords     = {litsurvey.bib}
}

@article{Boote2005,
	title        = {Scholars Before Researchers: On the Centrality of the Dissertation Literature Review in Research Preparation},
	author       = {Boote, David N and Beile, Penny},
	year         = 2005,
	month        = {\#aug\#},
	journal      = {Educ. Res.},
	publisher    = {American Educational Research Association},
	volume       = 34,
	number       = 6,
	pages        = {3--15},
	abstract     = {A thorough, sophisticated literature review is the foundation and inspiration for substantial, useful research. The complex nature of education research demands such thorough, sophisticated reviews. Although doctoral education is a key means for improving education research, the literature has given short shrift to the dissertation literature review. This article suggests criteria to evaluate the quality of dissertation literature reviews and reports a study that examined dissertations at three universities. Acquiring the skills and knowledge required to be education scholars, able to analyze and synthesize the research in a field of specialization, should be the focal, integrative activity of predissertation doctoral education. Such scholarship is a prerequisite for increased methodological sophistication and for improving the usefulness of education research.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Borovikov2000,
	title        = {A distributed system for real-time volume reconstruction},
	author       = {Borovikov, Eugene and Davis, Larry},
	year         = 2000,
	booktitle    = {Computer Architectures for Machine Perception, 2000. Proceedings. Fifth {IEEE} International Workshop on},
	pages        = {183--189},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@unpublished{Bowman2012,
	title        = {Questioning naturalism in {3D} user interfaces},
	author       = {Bowman, Doug A and McMahan, Ryan P and Ragan, Eric D},
	year         = 2012,
	month        = {\#sep\#},
	keywords     = {litsurvey.bib}
}

@inproceedings{Boyer2003,
	title        = {A hybrid approach for computing visual hulls of complex objects},
	author       = {Boyer, Edmond and Franco, Jean-S{\'e}bastien},
	year         = 2003,
	booktitle    = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages        = {695--701},
	institution  = {IEEE Computer Society Press},
	keywords     = {litsurvey.bib}
}

@book{Boyle2018,
	title        = {Advances in visual computing},
	author       = {Boyle, George Bebis Richard and Koracin, Bahram Parvin Darko and Nefian, Paolo Remagnino {\"A}ra and Pascucci, Gopi Meenakshisundaram Valerio and Molineros, Jiri Zara Jose and Malzbender, Holger Theisel Thomas},
	year         = 2018,
	publisher    = {Springer},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/2010_Book_AdvancesInVisualComputing.pdf:PDF}
}

@inproceedings{Bradner2002,
	title        = {Why distance matters: effects on cooperation, persuasion and deception},
	author       = {Bradner, Erin and Mark, Gloria},
	year         = 2002,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2002 {ACM} conference on Computer supported cooperative work},
	location     = {New Orleans, Louisiana, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '02},
	pages        = {226--235},
	keywords     = {CSCW, cooperation, deception, distance collaboration, empirical study, instant messaging, video;litsurvey.bib}
}

@inproceedings{Brooks1990,
	title        = {Project {GROPEHaptic} displays for scientific visualization},
	author       = {Brooks, Frederick P and Ouh-Young, Ming and Batter, James J and Jerome Kilpatrick, P},
	year         = 1990,
	month        = {\#sep\#},
	booktitle    = {Proceedings of the 17th annual conference on Computer graphics and interactive techniques},
	location     = {Dallas, TX, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGGRAPH '90},
	volume       = 24,
	pages        = {177--185},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@article{Brown1992,
	title        = {Managing the â€œS curves of innovation},
	author       = {Brown, Rick},
	year         = 1992,
	journal      = {Journal of Business \& Industrial Marketing},
	publisher    = {MCB UP Ltd},
	file         = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\10-1108_08858629210035418.pdf:PDF}
}

@inproceedings{Bruckner2010,
	title        = {Illustrative focus+ context approaches in interactive volume visualization},
	author       = {Bruckner, Stefan and Gr{\"o}ller, M Eduard and Mueller, Klaus and Preim, Bernhard and Silver, Deborah},
	year         = 2010,
	booktitle    = {Dagstuhl Follow-Ups},
	volume       = 1,
	organization = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Illustrative Focus + Context Approaches in Int.pdf:PDF}
}

@article{Bruno2013,
	title        = {Proxemics Revisited: Similar Effects of Arms Length on Men's and Women's Personal Distances},
	author       = {Bruno, Nicola and Muzzolini, Michela},
	year         = 2013,
	journal      = {Universal Journal of Psychology},
	publisher    = {Horizon Research Publishing},
	volume       = 1,
	number       = 2,
	pages        = {46--52},
	keywords     = {litsurvey.bib}
}

@book{brunton2019digital,
	title        = {Digital Cash: The Unknown History of the Anarchists, Utopians, and Technologists Who Created Cryptocurrency},
	author       = {Brunton, Finn},
	year         = 2019,
	publisher    = {Princeton University Press},
	file         = {:../../../literature_repository/bitcoin/Finn_Brunton_Digital_Cash__The_Unknown.pdf:PDF}
}

@article{Buczak2015,
	title        = {A survey of data mining and machine learning methods for cyber security intrusion detection},
	author       = {Buczak, Anna L and Guven, Erhan},
	year         = 2015,
	journal      = {IEEE Communications Surveys \& Tutorials},
	publisher    = {IEEE},
	volume       = 18,
	number       = 2,
	pages        = {1153--1176},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07307098.pdf:PDF}
}

@article{Budhiraja2015,
	title        = {Where's My Drink? Enabling Peripheral Real World Interactions While Using {HMDs}},
	author       = {Budhiraja, Pulkit and Sodhi, Rajinder and Jones, Brett and Karsch, Kevin and Bailey, Brian and Forsyth, David},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1502. 04744},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bulling2013,
	title        = {{EyeContext}: recognition of high-level contextual cues from human visual behaviour},
	author       = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {305--308},
	keywords     = {eye movement analysis, electrooculography (eog), visual behaviour, context recognition;litsurvey.bib}
}

@article{Bulu2012,
	title        = {Place presence, social presence, co-presence, and satisfaction in virtual worlds},
	author       = {Bulu, Saniye Tugba},
	year         = 2012,
	month        = {\#jan\#},
	journal      = {Comput. Educ.},
	publisher    = {Elsevier},
	volume       = 58,
	number       = 1,
	pages        = {154--161},
	abstract     = {This study investigated the relationship among three types of presences, including place presence, social presence, and co-presence in virtual worlds and their relationship with satisfaction and immersive tendencies of students. Students' scores on a subjective questionnaire were analyzed. The results indicated that there was a significant relationship among the place presence, social presence, and co-presence. While social presence seemed to affect the satisfaction most, place and co-presence also affected students' satisfaction in the virtual world. Moreover, immersive tendencies of the students were related to their place and co-presence but not to their social presence. Findings highlighted the important issues for the design of virtual world environments to increase presence and satisfaction of students.},
	keywords     = {Distance education and telelearning; Interactive learning environments; Media in education; Multimedia/hypermedia systems; Simulations;litsurvey.bib}
}

@book{burnham1983rise,
	title        = {The rise of the computer state},
	author       = {Burnham, David},
	year         = 1983,
	publisher    = {Random House Inc.}
}

@book{Butime2010,
	title        = {{Application of Computer Vision to {3D} Reconstruction: A Survey of Reconstruction Methods}},
	author       = {Butime, J and Galo, L and Gutierrez, I},
	year         = 2010,
	publisher    = {VDM Publishing},
	series       = {A Survey of Reconstruction Methods},
	keywords     = {litsurvey.bib}
}

@inproceedings{Butscher2018,
	title        = {Clusters, trends, and outliers: How immersive technologies can facilitate the collaborative analysis of multidimensional data},
	author       = {Butscher, Simon and Hubenschmid, Sebastian and M{\"u}ller, Jens and Fuchs, Johannes and Reiterer, Harald},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages        = 90,
	organization = {ACM},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/paper90.pdf:PDF}
}

@article{Buxton2009,
	title        = {Mediaspace--meaningspace--meetingspace},
	author       = {Buxton, Bill},
	year         = 2009,
	journal      = {Media space 20+ years of mediated life},
	publisher    = {Springer},
	pages        = {217--231},
	keywords     = {litsurvey.bib}
}

@inproceedings{Buxton1992,
	title        = {Telepresence: Integrating shared task and person spaces},
	author       = {Buxton, William},
	year         = 1992,
	booktitle    = {Proceedings of graphics interface},
	volume       = 92,
	pages        = {123--129},
	institution  = {Canadian Information Processing Society Toronto, Canada},
	keywords     = {litsurvey.bib}
}

@article{Buxton1992,
	title        = {Telepresence: integrating shared task and person spaces},
	author       = {Buxton, W},
	year         = 1992,
	journal      = {Proceedings of Graphics Interface},
	keywords     = {litsurvey.bib}
}

@article{Buxton1997,
	title        = {{Interfaces for multiparty videoconferences}},
	author       = {Buxton, W A S and Sellen, A J and Sheasby, M C},
	year         = 1997,
	journal      = {Video Mediated Communication.},
	pages        = {385--400},
	keywords     = {litsurvey.bib}
}

@inproceedings{Bocker1996,
	title        = {Anthropometric data on horizontal head movements in videocommunications},
	author       = {B{\"o}cker, Martin and Blohm, Werner and M{\"u}hlbach, Lothar},
	year         = 1996,
	month        = {\#apr\#},
	booktitle    = {Conference Companion on Human Factors in Computing Systems},
	location     = {Vancouver, British Columbia, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '96},
	pages        = {95--96},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@article{Caldwell1995,
	title        = {Appropriateness of communications media use in organizations: situation requirements and media characteristics},
	author       = {Caldwell, Barrett S and Uang, Shiaw-Tsyr and Taha, Lilas H},
	year         = 1995,
	month        = {\#jul\#},
	journal      = {Behav. Inf. Technol.},
	publisher    = {Taylor \& Francis},
	volume       = 14,
	number       = 4,
	pages        = {199--207},
	abstract     = {Abstract The purpose of this paper is to examine media use in organizations as affected by situation requirements and media characteristics. This paper discusses the strength of four existing models describing communications media use in individuals and organizations. The paper also presents research which evaluated interactions of multiple situation variables affecting communications media appropriateness in a survey population. Participants rated die acceptability of each of twelve communications media in each of eight hypothetical organizational situations. Situations varied based on high or low levels of three factors: message urgency, amount of message content, and distance between communicators. Results indicated (1) situations have unique and significant contributions to media appropriateness; (2) appropriateness of media usage depends on the match between situation requirements and media characteristics, and (3) situation effects are more salient in some ?situation-dependent? media. Another survey of 1072 voice mail users confirmed die validity and reliability of these results.},
	keywords     = {litsurvey.bib}
}

@techreport{callas1998openpgp,
	title        = {OpenPGP message format},
	author       = {Callas, Jon and Donnerhacke, Lutz and Finney, Hal and Thayer, Rodney},
	year         = 1998,
	institution  = {RFC 2440, November}
}

@inproceedings{Canny2011,
	title        = {{Triple-View}: Improving Persuasion in Group Video Conferencing through spatial Faithfulness},
	author       = {Canny, Apoorva Sachdev John},
	year         = 2011,
	keywords     = {litsurvey.bib}
}

@inproceedings{Card2002,
	title        = {Degree-of-interest trees: a component of an attention-reactive user interface.},
	author       = {Card, Stuart K and Nation, David},
	year         = 2002,
	booktitle    = {AVI},
	volume       = 2,
	pages        = {231--245},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Degree-of-Interest Trees A Component of an Att.pdf:PDF}
}

@book{Carlston2013,
	title        = {The Oxford Handbook of Social Cognition},
	author       = {Carlston, Donal E},
	year         = 2013,
	month        = {\#sep\#},
	publisher    = {OUP USA},
	series       = {Oxford Library of Psychology},
	abstract     = {Social cognition, as a field, can be characterized as a distinct subarea of social psychology that examines all of the countless cognitive complexities, mental representations, and processes implicated in interaction, as well as an approach to studying interactions in the context of the groups, cultures, and societies to which they belong. Together these two facets of social cognition create one of the most influential and important social sciences to come along in some time. Providing a comprehensive review of major topics in the field of social cognition, The Oxford Handbook of Social Cognition expresses that excitement and fascination in describing the content and approach that constitute the field today. The 43 chapters included in this handbook cover: - central aspects of the field of social cognition, including its history and historically important foundational research areas (attribution, attitudes, impression formation, and prejudice/stereotyping), along with methodology - core issues relating to social cognitive representations and processes (including those that are visual, implicit, or automatic) and the stages of information processing (attention, perception, memory, and judgment, along with simulation and thought suppression) - applications of the social cognition approach to areas of social psychology, general psychology, and other disciplines, such as marketing, law, health and politics After more than 30 years, the vibrant field of social cognition continues to reign as one of psychology's most dominant approaches. The impressive chapters collected in this volume define the field and contribute enormously to our understanding of what social cognition is today.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Carranza2003,
	title        = {Free-viewpoint video of human actors},
	author       = {Carranza, Joel and Theobalt, Christian and Magnor, Marcus A and Seidel, Hans-Peter},
	year         = 2003,
	booktitle    = {{ACM} transactions on graphics ({TOG})},
	volume       = 22,
	pages        = {569--577},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@article{casino2019systematic,
	title        = {A systematic literature review of blockchain-based applications: Current status, classification and open issues},
	author       = {Casino, Fran and Dasaklis, Thomas K and Patsakis, Constantinos},
	year         = 2019,
	journal      = {Telematics and informatics},
	publisher    = {Elsevier},
	volume       = 36,
	pages        = {55--81}
}

@article{Chartrand1999,
	title        = {The chameleon effect: the perception-behavior link and social interaction},
	author       = {Chartrand, T L and Bargh, J A},
	year         = 1999,
	month        = {\#jun\#},
	journal      = {J. Pers. Soc. Psychol.},
	publisher    = {American Psychological Association},
	volume       = 76,
	number       = 6,
	pages        = {893--910},
	abstract     = {The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception-behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, \& L. Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{chaum1985security,
	title        = {Security without identification: Transaction systems to make big brother obsolete},
	author       = {Chaum, David},
	year         = 1985,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 28,
	number       = 10,
	pages        = {1030--1044}
}

@inproceedings{Chen2002,
	title        = {Leveraging the asymmetric sensitivity of eye contact for videoconference},
	author       = {Chen, Milton},
	year         = 2002,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Minneapolis, Minnesota, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '02},
	pages        = {49--56},
	institution  = {ACM},
	keywords     = {eye contact, gaze perception, videoconferencing;litsurvey.bib}
}

@article{Chen2018,
	title        = {Structure-based suggestive exploration: a new approach for effective exploration of large networks},
	author       = {Chen, Wei and Guo, Fangzhou and Han, Dongming and Pan, Jacheng and Nie, Xiaotao and Xia, Jiazhi and Zhang, Xiaolong},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {555--565},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440813.pdf:PDF}
}

@article{hafid2020scaling,
	title        = {Scaling blockchains: A comprehensive survey},
	author       = {Hafid, Abdelatif and Hafid, Abdelhakim Senhaji and Samih, Mustapha},
	year         = 2020,
	journal      = {IEEE Access},
	publisher    = {IEEE},
	volume       = 8,
	pages        = {125244--125262}
}

@article{Cheng2011,
	title        = {Clustering large attributed graphs: A balance between structural and attribute similarities},
	author       = {Cheng, Hong and Zhou, Yang and Yu, Jeffrey Xu},
	year         = 2011,
	journal      = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
	publisher    = {ACM},
	volume       = 5,
	number       = 2,
	pages        = 12,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/1921632.1921638.pdf:PDF}
}

@inproceedings{Cheung2003,
	title        = {{Visual hull alignment and refinement across time: a {3D} reconstruction algorithm combining shape-from-silhouette with stereo}},
	author       = {Cheung, G K M and Baker, S and Kanade, T},
	year         = 2003,
	booktitle    = {Proceedings of the {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR} '03)},
	address      = {Madison},
	keywords     = {litsurvey.bib}
}

@inproceedings{Cheung2000,
	title        = {A real time system for robust {3D} voxel reconstruction of human motions},
	author       = {Cheung, German K M and Kanade, Takeo and Bouguet, J-Y and Holler, Mark},
	year         = 2000,
	booktitle    = {Computer Vision and Pattern Recognition, 2000. Proceedings. {IEEE} Conference on},
	volume       = 2,
	pages        = {714--720},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Chien1986,
	title        = {{Volume/surface octrees for the representation of three-dimensional objects}},
	author       = {Chien, C H and Aggarwal, J K},
	year         = 1986,
	month        = {\#oct\#},
	journal      = {Computer Vision, Graphics, and Image Processing},
	volume       = 36,
	number       = 1,
	pages        = {100--113},
	abstract     = {The octree structure for the representation of 3D objects is an extension of the quadtree representation of 2D (binary) images. It is generated from the 3D binary array of the object it represents. However, the acquisition of a 3D array is not a trivial problem. In this study, we propose a scheme to generate an octree of an object from its three orthogonal views (silhouettes) exploiting a volume intersection technique. A multi-level boundary search algorithm is developed to incorporate surface information into the octree representation. This makes the octree representation compact, informative, and especially useful for graphic displays and object recognition tasks. An algorithm is also designed for computing the moment of inertia matrix, which is useful for object recognition. All the algorithms developed in this study are essentially tree traversal procedures and therefore are suitable for implementation on parallel processors.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Cho1994,
	title        = {{Obtaining 3-d shape from silhouette informations interpolated by photometric stereo}},
	author       = {Cho, Changsuk and Minamitani, Haruyuki},
	year         = 1994,
	booktitle    = {Workshop on Machine Vision Applications ({MVA} '94)},
	publisher    = {Citeseer},
	address      = {Kanagawa},
	pages        = {147--150},
	keywords     = {litsurvey.bib}
}

@article{Chovil1991,
	title        = {Discourse ?oriented facial displays in conversation},
	author       = {Chovil, Nicole},
	year         = 1991,
	month        = {\#jan\#},
	journal      = {Research on Language and Social Interaction},
	publisher    = {Routledge},
	volume       = 25,
	number       = {1-4},
	pages        = {163--194},
	keywords     = {litsurvey.bib}
}

@inproceedings{Chu2010,
	title        = {{{OpenCL}: Make Ubiquitous Supercomputing Possible}},
	author       = {Chu, S and Hsiao, C},
	year         = 2010,
	month        = {\#sep\#},
	booktitle    = {2010 {IEEE} 12th International Conference on High Performance Computing and Communications ({HPCC})},
	publisher    = {IEEE},
	address      = {Melbourne},
	pages        = {556--561},
	abstract     = {Due to the dramatic requirements of 3D games and applications, graphics processing unit (GPU) or general-purpose graphics processing unit (GPGPU) have become required components in the modern computer systems. While these devices enable high parallelism with huge amount of processing elements, the utilization of their capabilities in general scientific applications are still low due to their difficult programming paradigms. Therefore an open standard, OpenCL, is proposed to provide universal APIs and programming paradigms for various GPUs and accelerators. In this study, it adopts several benchmarks, with various computation characteristics, to demonstrate the capabilities of OpenCL with several platforms. These programs are parallelized by OpenMP and OpenCL, and then targeted on several GPUs and conventional servers. This paper also provides an example to illustrate the migration of the given program, from OpenMP to OpenCL. The presented experimental results show that these inexpensive GPUs will lead better performance than servers if adopt OpenCL paradigms. It will be the preliminary milestone of cheap supercomputing by the acceleration of GPUs that can be obtained ubiquitously.},
	keywords     = {coprocessors;message passing;multiprocessing systems;parallel machines;parallel programming;ubiquitous computing;OpenCL;ubiquitous supercomputing;3D games;general-purpose graphics processing unit;programming paradigms;open standard;universal API;OpenMP;Computer architecture;Graphics processing unit;Instruction sets;Kernel;Microprocessors;Sun;Parallel Programming;OpenCL;OpenMP;GPU;GPGPU;Supercomputing;litsurvey.bib}
}

@inproceedings{Ciger2004,
	title        = {Evaluation of gaze tracking technology for social interaction in virtual environments},
	author       = {Ciger, Jan and Herbelin, Bruno and Thalmann, Daniel},
	year         = 2004,
	booktitle    = {Proc. of the 2\textbackslashtextsuperscript{nd} Workshop on Modeling and Motion Capture Techniques for Virtual Environments ({CAPTECH'04})},
	institution  = {Citeseer},
	keywords     = {litsurvey.bib}
}

@article{Clark2013,
	title        = {Bitcoin Internals: A Technical Guide to Bitcoin},
	author       = {Clark, Chris},
	year         = 2013,
	journal      = {Amazon Digital Services},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Bitcoin Internals - Clark, Chris.pdf:PDF}
}

@inproceedings{Colburn2000,
	title        = {The Role Of Eye Gaze In Avatar Mediated Conversational Interfaces},
	author       = {Colburn, Alex and Cohen, Michael F and Drucker, Steven},
	year         = 2000,
	keywords     = {litsurvey.bib}
}

@inproceedings{Conati2014,
	title        = {Evaluating the impact of user characteristics and different layouts on an interactive visualization for decision making},
	author       = {Conati, Cristina and Carenini, Giuseppe and Hoque, Enamul and Steichen, Ben and Toker, Dereck},
	year         = 2014,
	booktitle    = {Computer Graphics Forum},
	volume       = 33,
	number       = 3,
	pages        = {371--380},
	organization = {Wiley Online Library},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/EuroVis14-CameraReady.pdf:PDF}
}

@article{Cook1977,
	title        = {Gaze and mutual gaze in social encounters},
	author       = {Cook, Mark},
	year         = 1977,
	journal      = {Am. Sci.},
	publisher    = {Society of the Sigma Xi},
	volume       = 65,
	number       = 3,
	pages        = {328--333},
	abstract     = {Reviews research on gaze and mutual gaze in social interaction and discusses techniques of measurement. The perception of different patterns is described, as well as the linkage between gaze and speech, deviant problems of gaze in psychiatric cases, and cross-cultural differences. Data are drawn principally from experimental research, but literary and anthropological sources are included where appropriate. It is concluded that gaze is one of the main nonverbal signals and that knowledge of its uses has important practical implications for treatment and training in social skills and for the design of communications equipment. (33 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
	keywords     = {eye contact, gaze \& mutual gaze social interaction, interpersonal interaction, literature review, nonverbal communication, research;litsurvey.bib}
}

@misc{Cooke_undated,
	title        = {{IMAGE-BASED} {RENDERING} {FOR} {TELECONFERENCE} {SYSTEMS}},
	author       = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
	keywords     = {litsurvey.bib}
}

@article{Cooke2002a,
	title        = {Image-based rendering for teleconference systems},
	author       = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
	year         = 2002,
	publisher    = {V{\'a}clav Skala-UNION Agency},
	keywords     = {litsurvey.bib}
}

@inproceedings{Cooke2000,
	title        = {Extension of incomplete 3d for arbitrary multi-view-synthesis},
	author       = {Cooke, Eddie and Schreer, Oliver and Pasewaldt, Bernhard and Kauff, Peter},
	year         = 2000,
	booktitle    = {{VMV}},
	pages        = {205--212},
	keywords     = {litsurvey.bib}
}

@article{Cordeil2016,
	title        = {Immersive collaborative analysis of network connectivity: Cave-style or head-mounted display?},
	author       = {Cordeil, Maxime and Dwyer, Tim and Klein, Karsten and Laha, Bireswar and Marriott, Kim and Thomas, Bruce H},
	year         = 2016,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 23,
	number       = 1,
	pages        = {441--450},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07539620.pdf:PDF}
}

@misc{costigan2018world,
	title        = {World Without Mind: The Existential Threat of Big Tech (Franklin Foer)},
	author       = {Costigan, Sean S},
	year         = 2018,
	publisher    = {Springer}
}

@inproceedings{Coughlan2006,
	title        = {Interaction in creative tasks: Ideation, Representation and Evaluation in Composition', paper presented to the},
	author       = {Coughlan, T and Johnson, P},
	year         = 2006,
	booktitle    = {Proceedings of the {SIGCHI} conference on Human Factors in computing systems},
	keywords     = {litsurvey.bib}
}

@article{Criminisi2007,
	title        = {Efficient dense stereo with occlusions for new view-synthesis by four-state dynamic programming},
	author       = {Criminisi, Antonio and Blake, Andrew and Rother, Carsten and Shotton, Jamie and Torr, Philip H S},
	year         = 2007,
	journal      = {Int. J. Comput. Vis.},
	publisher    = {Springer},
	volume       = 71,
	number       = 1,
	pages        = {89--110},
	keywords     = {litsurvey.bib}
}

@inproceedings{Criminisi2003,
	title        = {{Gaze manipulation for one-to-one teleconferencing}},
	author       = {{Criminisi} and {Shotton} and {Blake} and {Torr}},
	year         = 2003,
	month        = {\#oct\#},
	booktitle    = {Proceedings Ninth {IEEE} International Conference on Computer Vision},
	address      = {Nice},
	pages        = {191--198 vol.1},
	abstract     = {A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications. Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesizes images from a virtual camera in arbitrary position (typically located within the monitor) to facilitate eye contact. Our technique is based on an improved, dynamic-programming, stereo algorithm for efficient novel-view generation. The two main contributions are: i) a new type of three-plane graph for dense-stereo dynamic-programming, that encourages correct occlusion labeling; ii) a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface. Furthermore, we present a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts (flicker); and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space. Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams. These include demonstrations of synthesis of cyclopean views of extended conversational sequences. We further demonstrate synthesis from a freely translating virtual camera.},
	keywords     = {teleconferencing;video coding;video cameras;dynamic programming;rendering (computer graphics);image sequences;image matching;hidden feature removal;computational geometry;gaze manipulation;one-to-one teleconferencing;video stream;virtual camera;novel-view generation;three-plane graph;dense-stereo dynamic-programming;occlusion labeling;minimum-cost surface;background model temporal maintenance;cost aggregation algorithm;three-dimensional matching cost space;spatial artefact;temporal artefact;cyclopean view synthesis;conversational sequence;Teleconferencing;Cameras;Streaming media;Costs;Application software;Computer displays;Computerized monitoring;Heuristic algorithms;Labeling;Robustness;litsurvey.bib}
}

@phdthesis{Cruz-Neira1995,
	title        = {{Virtual reality based on multiple projection screens: the cave and its applications to computational science and engineering}},
	author       = {Cruz-Neira, Carolina},
	year         = 1995,
	school       = {University of Illinois, Chicago},
	keywords     = {litsurvey.bib}
}

@inproceedings{Cuddihy2000,
	title        = {Embodied interaction in social virtual environments},
	author       = {Cuddihy, Elisabeth and Walters, Deborah},
	year         = 2000,
	month        = {\#sep\#},
	booktitle    = {Proceedings of the third international conference on Collaborative virtual environments},
	location     = {San Francisco, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CVE '00},
	pages        = {181--188},
	institution  = {ACM},
	keywords     = {interactivity models, user interface, presence, embodiment;litsurvey.bib}
}

@article{Daas2015,
	title        = {Big data as a source for official statistics},
	author       = {Daas, Piet JH and Puts, Marco J and Buelens, Bart and van den Hurk, Paul AM},
	year         = 2015,
	journal      = {Journal of Official Statistics},
	publisher    = {De Gruyter Open},
	volume       = 31,
	number       = 2,
	pages        = {249--262},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/[Journal of Official Statistics] Big Data as a.pdf:PDF}
}

@article{dai1998b,
	title        = {b-money, 1998},
	author       = {Dai, Wei},
	year         = 1998,
	journal      = {URL http://www. weidai. com/bmoney. txt.(Last access: 08.04. 2019)}
}

@inproceedings{Dalsgaard2011,
	title        = {3d projection on physical objects: design insights from five real life cases},
	author       = {Dalsgaard, Peter and Halskov, Kim},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {1041--1050},
	institution  = {ACM},
	keywords     = {visual effects, exhibitions, architecture, design, augmented reality, projection, cultural heritage, 3d;litsurvey.bib}
}

@article{Darken2003,
	title        = {A chromakey augmented virtual environment for deployable training},
	author       = {Darken, Rudolph P and Sullivan, Joseph A and Lennerton, Mark},
	year         = 2003,
	keywords     = {litsurvey.bib}
}

@book{Davies2004,
	title        = {{Machine vision: theory, algorithms, practicalities}},
	author       = {Davies, E R},
	year         = 2004,
	publisher    = {Elsevier},
	keywords     = {litsurvey.bib}
}

@inproceedings{Debevec1996,
	title        = {{Modeling and rendering architecture from photographs: a hybrid geometry- and image-based approach}},
	author       = {Debevec, Paul E and Taylor, Camillo J and Malik, Jitendra},
	year         = 1996,
	month        = {\#aug\#},
	booktitle    = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGGRAPH '96},
	pages        = {11--20},
	keywords     = {litsurvey.bib}
}

@inproceedings{Deckers2011,
	title        = {Designing for perceptual crossing to improve user involvement},
	author       = {Deckers, Eva and Wensveen, Stephan and Ahn, Rene and Overbeeke, Kees},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {1929--1938},
	institution  = {ACM},
	keywords     = {research through design, designing for perceptual crossing, phenomenology;litsurvey.bib}
}

@inproceedings{Deckers2013,
	title        = {Designing for perceptual crossing: designing and comparing three behaviors},
	author       = {Deckers, Eva and Wensveen, Stephan and Levy, Pierre and Ahn, Rene},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {1901--1910},
	institution  = {ACM},
	keywords     = {perceptual crossing, perceptive qualities, product behavior, research through design, design theory, phenomenology;litsurvey.bib}
}

@article{Delaunay1934,
	title        = {{Sur la sphere vide}},
	author       = {Delaunay, B},
	year         = 1934,
	journal      = {Biol. Bull. Acad. Sci. USSR},
	volume       = 6,
	pages        = {793--800},
	keywords     = {litsurvey.bib}
}

@inproceedings{Dennis1990,
	title        = {Ad hoc versus established groups in an electronic meeting system environment},
	author       = {Dennis, Alan R and Easton, Annette C and Easton, George K and George, Joey F and Nunamaker, J F},
	year         = 1990,
	booktitle    = {System Sciences, 1990., Proceedings of the {Twenty-Third} Annual Hawaii International Conference on},
	volume       = 3,
	pages        = {23--29},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Denstadli2012,
	title        = {Videoconferencing as a mode of communication: A comparative study of the use of videoconferencing and face-to-face meetings},
	author       = {Denstadli, Jon Martin and Julsrud, Tom Erik and Hjorthol, Randi Johanne},
	year         = 2012,
	journal      = {Journal of Business and Technical Communication},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 26,
	number       = 1,
	pages        = {65--91},
	keywords     = {litsurvey.bib}
}

@inproceedings{Desai2011,
	title        = {Essential features of telepresence robots},
	author       = {Desai, M and Tsui, K M and Yanco, H A and Uhlik, C},
	year         = 2011,
	month        = {\#apr\#},
	booktitle    = {2011 {IEEE} Conference on Technologies for Practical Robot Applications},
	pages        = {15--20},
	abstract     = {Telepresence robots are mobile robot platforms capable of providing two way audio and video communication. Recently there has been a surge in companies designing telepresence robots. We conducted a series of user studies at Google in Mountain View with two different commercially available telepresence robots. Based on the data collected from these user studies, we present a set of guidelines for designing telepresence robots. These essential guidelines pertain to video, audio, user interface, physical features, and autonomous behaviors.},
	institution  = {IEEE},
	keywords     = {mobile robots;teleconferencing;telerobotics;user interfaces;video communication;virtual reality;telepresence robots;mobile robot;audio communication;video communication;Google;Mountain View;user interface;physical features;autonomous behaviors;Legged locomotion;Driver circuits;Cameras;Navigation;Robot vision systems;litsurvey.bib}
}

@article{diffie1976new,
	title        = {New directions in cryptography},
	author       = {Diffie, Whitfield and Hellman, Martin},
	year         = 1976,
	journal      = {IEEE transactions on Information Theory},
	publisher    = {IEEE},
	volume       = 22,
	number       = 6,
	pages        = {644--654}
}

@article{dimara2017conceptual,
	title        = {Conceptual and methodological issues in evaluating multidimensional visualizations for decision support},
	author       = {Dimara, Evanthia and Bezerianos, Anastasia and Dragicevic, Pierre},
	year         = 2017,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	publisher    = {IEEE},
	volume       = 24,
	number       = 1,
	pages        = {749--759},
	file         = {:../../../literature_repository/Data Visualisation/08019855.pdf:PDF}
}

@inproceedings{Ding2007,
	title        = {An empirical study of the use of visually enhanced voip audio conferencing: the case of {IEAC}},
	author       = {Ding, Xianghua and Erickson, Thomas and Kellogg, Wendy A and Levy, Stephen and Christensen, James E and Sussman, Jeremy and Wolf, Tracee Vetting and Bennett, William E},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1019--1028},
	institution  = {ACM},
	keywords     = {social proxy, conference call, social visualization, voice, social translucence, VoIP, telephony, audio conferencing;litsurvey.bib}
}

@article{Dinov2016,
	title        = {Predictive big data analytics: a study of Parkinsonâ€™s disease using large, complex, heterogeneous, incongruent, multi-source and incomplete observations},
	author       = {Dinov, Ivo D and Heavner, Ben and Tang, Ming and Glusman, Gustavo and Chard, Kyle and Darcy, Mike and Madduri, Ravi and Pa, Judy and Spino, Cathie and Kesselman, Carl and others},
	year         = 2016,
	journal      = {PloS one},
	publisher    = {Public Library of Science},
	volume       = 11,
	number       = 8,
	pages        = {e0157077},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Study of parkinsions disease.pdf:PDF}
}

@inproceedings{Divorra2010,
	title        = {Towards 3D-aware telepresence: Working on technologies behind the scene},
	author       = {Divorra, O and Civit, Jaume and Zuo, F and Belt, H and Feldmann, I and Chreer, O and Yellin, E and Ijsselsteijn, W and van Eijk, R and Espinola, D and {Others}},
	year         = 2010,
	keywords     = {litsurvey.bib}
}

@inproceedings{Dodds2008,
	title        = {Mobile Group Dynamics in {Large-Scale} Collaborative Virtual Environments},
	author       = {Dodds, T J and Ruddle, R A},
	year         = 2008,
	month        = {\#mar\#},
	booktitle    = {2008 {IEEE} Virtual Reality Conference},
	pages        = {59--66},
	abstract     = {We have developed techniques called mobile group dynamics (MGDs), which help groups of people to work together while they travel around large-scale virtual environments. MGDs explicitly showed the groups that people had formed themselves into, and helped people move around together and communicate over extended distances. The techniques were evaluated in the context of an urban planning application, by providing one batch of participants with MGDs and another with an interface based on conventional collaborative virtual environments (CVEs). Participants with MGDs spent nearly twice as much time in close proximity (within 10m of their nearest neighbor), communicated seven times more than participants with a conventional interface, and exhibited real-world patterns of behavior such as staying together over an extended period of time and regrouping after periods of separation. The study has implications for CVE designers, because it shows how MGDs improves groupwork in CVEs.},
	institution  = {IEEE},
	keywords     = {groupware;mobile computing;virtual reality;mobile group dynamics;large-scale collaborative virtual environments;urban planning;collaborative interaction;Large-scale systems;Collaboration;Virtual environment;Collaborative work;Virtual reality;Collaborative software;Computer interfaces;Computer networks;Distributed computing;Mobile computing;Collaborative interaction;experimental methods;distributed VR;usability;C.2.4 [Computer-Computer Communication Networks]: Distributed Systems\?\`Distributed applications;H.1.2 [Models and Principles]: User/Machine Systems\?\`Human factors;Software psychology;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems\?\`Artificial, augmented and virtual realities;H.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces\?\`Collaborative computing;Computer-supported cooperative work;Synchronous interaction;I.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism\?\`Virtual Reality;litsurvey.bib}
}

@inproceedings{Doleisch2003,
	title        = {Interactive feature specification for focus+ context visualization of complex simulation data},
	author       = {Doleisch, Helmut and Gasser, Martin and Hauser, Helwig},
	year         = 2003,
	booktitle    = {VisSym},
	volume       = 3,
	pages        = {239--248},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Interactive Feature Specication for Focus+Cont.pdf:PDF}
}

@article{Doleisch2002,
	title        = {Smooth brushing for focus+ context visualization of simulkation data in 3D},
	author       = {Doleisch, Helmut and Hauser, Helwig},
	year         = 2002,
	publisher    = {UNION Agency},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/SMOOTH BRUSHING FOR FOCUS + CONTEXT VISUALIZAT.pdf:PDF}
}

@article{Dolling2019,
	title        = {Visualizing US Animal Shelter Outcomes},
	author       = {Dolling, Carmen},
	year         = 2019,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/carmendolling.pdf:PDF}
}

@unpublished{Dou2016,
	title        = {{Fusion4D}: real-time performance capture of challenging scenes},
	author       = {Dou, Mingsong and Khamis, Sameh and Degtyarev, Yury and Davidson, Philip and Fanello, Sean Ryan and Kowdle, Adarsh and Escolano, Sergio Orts and Rhemann, Christoph and Kim, David and Taylor, Jonathan and Kohli, Pushmeet and Tankovich, Vladimir and Izadi, Shahram},
	year         = 2016,
	month        = {\#jul\#},
	number       = {Article 114},
	keywords     = {4D reconstruction, real-time, nonrigid, multi-view;litsurvey.bib}
}

@article{Dourish1996,
	title        = {Your place or mine? Learning from long-term use of {Audio-Video} communication},
	author       = {Dourish, Paul and Adler, Annette and Bellotti, Victoria and Henderson, Austin},
	year         = 1996,
	month        = {\#mar\#},
	journal      = {Comput. Support. Coop. Work},
	volume       = 5,
	number       = 1,
	pages        = {33--62},
	abstract     = {Workstations and personal computers are increasingly being delivered with the ability to handle multimedia data; more and more of us are linked by high-speed digital networks. With multimedia communication environments becoming more commonplace, what have we learned from earlier experiences with prototype media environments? This paper reports on some of our experiences as developers, researchers and users of flexible, networked, multimedia computer environments, or ``media spaces''. It focusses on the lessons we can learn from extended, long-term use of media spaces, with connections that last not hours or days, but months or years. We take as our starting point a set of assumptions which differ from traditional analytical perspectives. In particular, we begin from the position that that real-world baseline is not always an appropriate point of comparison for new media technologies; that a set of complex and intricate communicative behaviours arise over time; and that media spaces connect not only individuals, but the wider social groups of which they form part. We outline a framework based on four perspectives --- individual, interactional, communal and societal --- from which to view the behaviour of individuals and groups linked by multimedia environments. On the basis of our long-term findings, we argue for a view of media spaces which, first, focuses on a wider interpretation of media space interaction than the traditional view of person-to-person connections, and, second, emphasises emergent communicative practices, rather than looking for the transfer of face-to-face behaviours.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Du2017,
	title        = {Representativeness of latent dirichlet allocation topics estimated from data samples with application to common crawl},
	author       = {Du, Yuheng and Herzog, Alexander and Luckow, Andre and Nerella, Ramu and Gropp, Christopher and Apon, Amy},
	year         = 2017,
	booktitle    = {2017 IEEE International Conference on Big Data (Big Data)},
	pages        = {1418--1427},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Representativeness of Latent Dirichlet Allocat.pdf:PDF}
}

@article{Duckworth2014,
	title        = {Parallel processing for real-time {3D} reconstruction from video streams},
	author       = {Duckworth, Tobias and Roberts, David J},
	year         = 2014,
	journal      = {Journal of real-time image processing},
	publisher    = {Springer},
	volume       = 9,
	number       = 3,
	pages        = {427--445},
	keywords     = {litsurvey.bib}
}

@article{Duckworth2012,
	title        = {{3DRecon}, a utility for {3D} reconstruction from video},
	author       = {Duckworth, Tobias and Roberts, David J},
	year         = 2012,
	journal      = {Joint Virtual Conference of ICAT - EGVE - EuroVR (JVRC '12)},
	keywords     = {litsurvey.bib}
}

@inproceedings{Duckworth2011,
	title        = {Accelerated polyhedral visual hulls using {OpenCL}},
	author       = {Duckworth, T and Roberts, D J},
	year         = 2011,
	month        = {\#mar\#},
	booktitle    = {2011 {IEEE} Virtual Reality Conference},
	address      = {Singapore},
	pages        = {203--204},
	abstract     = {We present a method for reconstruction of the visual hull (VH) of an object in real-time from multiple video streams. A state of the art polyhedral reconstruction algorithm is accelerated by implementing it for parallel execution on a multi-core graphics processor (GPU). The time taken to reconstruct the VH is measured for both the accelerated and non-accelerated implementations of the algorithm, over a range of image resolutions and number of cameras. The results presented are of relevance to researchers in the field of 3D reconstruction at interactive frame rates (real-time), for applications such as telepresence.},
	keywords     = {computer graphic equipment;coprocessors;image reconstruction;video signal processing;virtual reality;polyhedral visual hull;visual hull reconstruction;video streams;polyhedral reconstruction algorithm;multicore graphics processor;graphics processing unit;image resolution;3D reconstruction;telepresence application;Cameras;Three dimensional displays;Image edge detection;Graphics processing unit;Solid modeling;Visualization;Image resolution;Reconstruction algorithms;Parallel processing;Virtual reality;litsurvey.bib}
}

@inproceedings{Duckworth2011,
	title        = {Camera Image Synchronisation in Multiple Camera {Real-Time} {3D} Reconstruction of Moving Humans},
	author       = {Duckworth, T and Roberts, D J},
	year         = 2011,
	month        = {\#sep\#},
	booktitle    = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation and Real Time Applications},
	publisher    = {IEEE Computer Society},
	address      = {Salford},
	pages        = {138--144},
	abstract     = {We present an analysis of the requirement for input synchronisation in a multi-camera 3D reconstruction system for real-time applications such as telepresence.{\^A} Synchronisation of the cameras at the acquisition stage is universally used to ensure the images feeding the reconstruction algorithm were taken at the same time.{\^A} However, this requirement adds delays to the reconstruction pipeline, therefore increasing the end to end latency of the system.{\^A} While this has not been a significant problem for many of the applications of 3D reconstruction, it is for its application to tele-presence. Furthermore, synchronising the firing of cameras adds much financial cost to the system. Using real camera images of moving humans, we study the effect removing synchronisation has on the output reconstructed model over a range of camera configurations and relative frame delays.{\^A} From this we determine the synchronisation requirements for a 3D reconstruction telepresence system in terms of the maximum time between camera frames that gives rise to acceptable results.},
	keywords     = {image reconstruction;image sensors;telecontrol;virtual reality;camera image synchronisation;multiple camera real-time 3D reconstruction system;3D reconstruction telepresence system;input synchronisation;reconstruction pipeline;camera frames;Cameras;Synchronization;Image reconstruction;Three dimensional displays;Delay;Visualization;Shape;Tele-immersion;telepresence;3D reconstruction;synchronization;litsurvey.bib}
}

@article{Duffy2010,
	title        = {The future of meetings: the case for face-to-face},
	author       = {Duffy, Christine and McEuen, Mary Beth},
	year         = 2010,
	keywords     = {litsurvey.bib}
}

@article{Dyck2008,
	title        = {Recognition profile of emotions in natural and virtual faces},
	author       = {Dyck, Miriam and Winbeck, Maren and Leiberg, Susanne and Chen, Yuhan and Gur, Ruben C and Mathiak, Klaus},
	year         = 2008,
	month        = {\#nov\#},
	journal      = {PLoS One},
	publisher    = {Public Library of Science},
	volume       = 3,
	number       = 11,
	pages        = {e3628},
	abstract     = {BACKGROUND: Computer-generated virtual faces become increasingly realistic including the simulation of emotional expressions. These faces can be used as well-controlled, realistic and dynamic stimuli in emotion research. However, the validity of virtual facial expressions in comparison to natural emotion displays still needs to be shown for the different emotions and different age groups. METHODOLOGY/PRINCIPAL FINDINGS: Thirty-two healthy volunteers between the age of 20 and 60 rated pictures of natural human faces and faces of virtual characters (avatars) with respect to the expressed emotions: happiness, sadness, anger, fear, disgust, and neutral. Results indicate that virtual emotions were recognized comparable to natural ones. Recognition differences in virtual and natural faces depended on specific emotions: whereas disgust was difficult to convey with the current avatar technology, virtual sadness and fear achieved better recognition results than natural faces. Furthermore, emotion recognition rates decreased for virtual but not natural faces in participants over the age of 40. This specific age effect suggests that media exposure has an influence on emotion recognition. CONCLUSIONS/SIGNIFICANCE: Virtual and natural facial displays of emotion may be equally effective. Improved technology (e.g. better modelling of the naso-labial area) may lead to even better results as compared to trained actors. Due to the ease with which virtual human faces can be animated and manipulated, validated artificial emotional expressions will be of major relevance in future research and therapeutic applications.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Edigo1988,
	title        = {Videoconferencing as a technology to support group work: A review of its failure},
	author       = {Edigo, C},
	year         = 1988,
	booktitle    = {Proceedings of the {ACM} conf. on {Computer-Supported} Cooperative Work},
	keywords     = {litsurvey.bib}
}

@article{egger2017htc,
	title        = {HTC Vive MeVisLab integration via OpenVR for medical applications},
	author       = {Egger, Jan and Gall, Markus and Wallner, J{\"u}rgen and Boechat, Pedro and Hann, Alexander and Li, Xing and Chen, Xiaojun and Schmalstieg, Dieter},
	year         = 2017,
	journal      = {PloS one},
	publisher    = {Public Library of Science},
	volume       = 12,
	number       = 3,
	pages        = {e0173972},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/volumeMedical/pone.0173972.pdf:PDF}
}

@article{Ehsan2017,
	title        = {Efficient recommendation of aggregate data visualizations},
	author       = {Ehsan, Humaira and Sharaf, Mohamed A and Chrysanthis, Panos K},
	year         = 2017,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	publisher    = {IEEE},
	volume       = 30,
	number       = 2,
	pages        = {263--277},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08081825.pdf:PDF}
}

@inproceedings{Van_Eijk2010,
	title        = {Human sensitivity to eye contact in {2D} and {3D} videoconferencing},
	author       = {van Eijk, R and Kuijsters, A and Dijkstra, K and IJsselsteijn, W A},
	year         = 2010,
	month        = {\#jun\#},
	booktitle    = {2010 Second International Workshop on Quality of Multimedia Experience ({QoMEX})},
	pages        = {76--81},
	abstract     = {Gaze awareness and eye contact serve important functions in social interaction. In order to maintain those functions in 2D and 3D videoconferencing systems, human sensitivity to eye contact and gaze direction needs to be taken into account in the design of such systems. Here we experimentally investigate human perception of eye contact and gaze direction in 2D and 3D, using a within-subjects design. Our results indicate that the disparity between the optical axis of the camera and the looking direction of a looker (a photographed face) should be at most 1.2Â° in horizontal direction, and 1.7Â° in vertical direction to support eye contact. Maximum tolerable offsets for the perception of eye contact are independent of (monoscopic or stereoscopic) display conditions. Asymmetric sensitivity to eye contact is explained by the underestimation of the vertical component of a looker's gaze direction.},
	institution  = {IEEE},
	keywords     = {teleconferencing;video communication;visual perception;human sensitivity;2D videoconferencing;3D videoconferencing;gaze awareness;eye contact perception;within-subject design;camera optical axis;looking direction;looker gaze direction;Humans;Teleconferencing;Cameras;Optical sensors;Eyes;Displays;Games;Industrial engineering;Technological innovation;Optical feedback;Eye contact;gaze direction;perception;3D;videoconferencing;litsurvey.bib}
}

@inproceedings{Eisemann2008,
	title        = {Floating textures},
	author       = {Eisemann, Martin and De Decker, Bert and Magnor, Marcus and Bekaert, Philippe and De Aguiar, Edilson and Ahmed, Naveed and Theobalt, Christian and Sellent, Anita},
	year         = 2008,
	booktitle    = {Computer Graphics Forum},
	volume       = 27,
	pages        = {409--418},
	institution  = {Wiley Online Library},
	keywords     = {litsurvey.bib}
}

@article{Eisenbart2016,
	title        = {Does scheduling matter? When unscheduled decision making results in more effective meetings},
	author       = {Eisenbart, Boris and Garbuio, Massimo and Mascia, Daniele and Morandi, Federica},
	year         = 2016,
	month        = {\#jan\#},
	journal      = {Journal of Strategy and Management},
	publisher    = {Emerald Group Publishing Limited},
	volume       = 9,
	number       = 1,
	pages        = {15--38},
	abstract     = {Purpose-- Managers spend a great deal of time in meetings making decisions critical to organisational success, yet the design aspects of meetings remain largely understudied. The purpose of this paper is to elaborate on the potential impact of one critical design aspect of meetings -- namely, whether a decision to be taken (or the meeting in general) was scheduled or not -- on the use of distributed information, information elaboration, conflict, speed of decision making, and, ultimately, decision-making effectiveness. Design/methodology/approach-- The research presented in this paper combines a literature review with empirical data obtained from questionnaires and direct observation of decision making meetings on organisational issues in a hospital. One meeting was scheduled, the other two were unscheduled. A second questionnaire was administered 12 months after the respective decision making meetings to explore and evaluate the efficiency of the decisions made and their implementation. Findings-- This paper suggests that a scheduled meeting with a shared agenda of all decisions to be taken may induce decision makers to form opinions upfront at the meeting, with these opinions eventually serving as sources of conflict during group discussion. Because of the nature of the conflict generated, these meetings are more likely to run long and to not deliver the expected outcomes. Originality/value-- The study contributes to the debate on group decision-making processes by examining the effect of meeting scheduling on information elaboration and conflict in real-world decision-making settings. Although robust evidence has supported the existence of relationships between information elaboration, conflict, and decision-making effectiveness, previous studies have mainly focused on the effects of these processes during scheduled meetings and experimental settings. The findings of the present study show the effect of meeting scheduling on decision-making effectiveness in real-world settings.},
	keywords     = {litsurvey.bib}
}

@article{Ekman1993,
	title        = {Facial expression and emotion},
	author       = {Ekman, P},
	year         = 1993,
	month        = {\#apr\#},
	journal      = {Am. Psychol.},
	publisher    = {American Psychological Association},
	volume       = 48,
	number       = 4,
	pages        = {384--392},
	abstract     = {Cross-cultural research on facial expression and the developments of methods to measure facial expression are briefly summarized. What has been learned about emotion from this work on the face is then elucidated. Four questions about facial expression and emotion are discussed: What information does an expression typically convey? Can there be emotion without facial expression? Can there be a facial expression of emotion without emotion? How do individuals differ in their facial expressions of emotion?},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Eldes2013,
	title        = {Multi-view autostereoscopic projection display using rotating screen},
	author       = {Eldes, Osman and Ak{\c s}it, Kaan and Urey, Hakan},
	year         = 2013,
	month        = {\#nov\#},
	journal      = {Opt. Express},
	publisher    = {Optical Society of America},
	volume       = 21,
	number       = 23,
	pages        = {29043--29054},
	abstract     = {A new technique for multi-view autostereoscopic projection display is proposed, and demonstrated. The technique uses two mobile projectors, a rotating retro-reflective diffuser screen, and a head-tracking camera. As two dynamic viewing slits are created at the viewer's position, the slits can track the position of the eyes by rotating the screen. The display allows a viewer to move approximately 700 mm along the horizontal axis, and 500 mm along the vertical axis with an average crosstalk below 5 \%. Two screen prototypes with different diffusers have been tried, and they provide luminance levels of 60 Cd/m2, and 160 Cd/m2 within the viewing field.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Engle1987,
	title        = {Co-integration and error correction: representation, estimation, and testing},
	author       = {Engle, Robert F and Granger, Clive WJ},
	year         = 1987,
	journal      = {Econometrica: journal of the Econometric Society},
	publisher    = {JSTOR},
	pages        = {251--276},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/1913236.pdf:PDF}
}

@inproceedings{Erickson2010,
	title        = {Telepresence in Virtual Conferences: An Empirical Comparison of Distance Collaboration Technologies},
	author       = {Erickson, Thomas and Kellogg, W A},
	year         = 2010,
	pages        = {1--6},
	keywords     = {litsurvey.bib}
}

@inproceedings{Erickson2011,
	title        = {Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment},
	author       = {Erickson, Thomas and Shami, N Sadat and Kellogg, Wendy A and Levine, David W},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {503--512},
	institution  = {ACM},
	keywords     = {collaborative virtual environment, synchronous interaction, virtual world, spatialized audio, CVE, virtual conference, CMC, second life;litsurvey.bib}
}

@inproceedings{Ess2008,
	title        = {A mobile vision system for robust multi-person tracking},
	author       = {Ess, A and Leibe, B and Schindler, K and Van Gool, L},
	year         = 2008,
	month        = {\#jun\#},
	booktitle    = {2008 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages        = {1--8},
	abstract     = {We present a mobile vision system for multi-person tracking in busy environments. Specifically, the system integrates continuous visual odometry computation with tracking-by-detection in order to track pedestrians in spite of frequent occlusions and egomotion of the camera rig. To achieve reliable performance under real-world conditions, it has long been advocated to extract and combine as much visual information as possible. We propose a way to closely integrate the vision modules for visual odometry, pedestrian detection, depth estimation, and tracking. The integration naturally leads to several cognitive feedback loops between the modules. Among others, we propose a novel feedback connection from the object detector to visual odometry which utilizes the semantic knowledge of detection to stabilize localization. Feedback loops always carry the danger that erroneous feedback from one module is amplified and causes the entire system to become instable. We therefore incorporate automatic failure detection and recovery, allowing the system to continue when a module becomes unreliable. The approach is experimentally evaluated on several long and difficult video sequences from busy inner-city locations. Our results show that the proposed integration makes it possible to deliver stable tracking performance in scenes of previously infeasible complexity.},
	keywords     = {computer vision;feedback;image sequences;tracking;video signal processing;mobile vision system;multiperson tracking;continuous visual odometry computation;tracking-by-detection;pedestrian tracking;egomotion;camera rig;pedestrian detection;depth estimation;cognitive feedback loops;automatic failure detection;video sequences;Machine vision;Layout;Feedback loop;Object detection;Mobile robots;Noise robustness;Cameras;Data mining;Detectors;Video sequences;litsurvey.bib}
}

@article{Esteban2002,
	title        = {{Multi-stereo 3d object reconstruction}},
	author       = {Esteban, C H and Schmitt, F},
	year         = 2002,
	journal      = {International Symposium on 3D Processing, Visualization, and Transmission (3DPVT '02)},
	pages        = {159--166},
	keywords     = {litsurvey.bib}
}

@article{faccia2019accounting,
	title        = {Accounting and blockchain technology: from double-entry to triple-entry},
	author       = {Faccia, Alessio and Mosteanu, Narcisa Roxana},
	year         = 2019,
	journal      = {The Business \& Management Review},
	publisher    = {Centre for Business \& Economic Research},
	volume       = 10,
	number       = 2,
	pages        = {108--116}
}

@inproceedings{Fagel2010,
	title        = {On the importance of eye gaze in a face-to-face collaborative task},
	author       = {Fagel, Sascha and Bailly, G{\'e}rard and Elisei, Fr{\'e}d{\'e}ric and Lelong, Am{\'e}lie},
	year         = 2010,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 3rd international workshop on Affective interaction in natural environments},
	location     = {Firenze, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {AFFINE '10},
	pages        = {81--86},
	institution  = {ACM},
	keywords     = {face-to-face interaction, head motion, eye gaze;litsurvey.bib}
}

@article{Fairchild2017,
	title        = {A Mixed Reality Telepresence System for Collaborative Space Operation},
	author       = {Fairchild, A J and Campion, S P and Garc{\'\i}a, A S and Wolff, R and Fernando, T and Roberts, D J},
	year         = 2017,
	month        = {\#apr\#},
	journal      = {IEEE Trans. Circuits Syst. Video Technol.},
	publisher    = {IEEE},
	volume       = 27,
	number       = 4,
	pages        = {814--827},
	abstract     = {This paper presents a mixed reality (MR) system that results from the integration of a telepresence system and an application to improve collaborative space exploration. The system combines free viewpoint video with immersive projection technology to support nonverbal communication (NVC), including eye gaze, interpersonal distance, and facial expression. Importantly, these features can be interpreted together as people move around the simulation, maintaining a natural social distance. The application is a simulation of Mars, within which the collaborators must come to agreement over; for example, where the Rover should land and go. The first contribution is the creation of an MR system supporting contextualization of NVC. Two technological contributions are prototyping a technique to subtract a person from a background that may contain physical objects and/or moving images and a lightweight texturing method for multiview rendering, which provides balance in terms of visual and temporal quality. A practical contribution is the demonstration of pragmatic approaches to sharing space between display systems of distinct levels of immersion. A research tool contribution is a system that allows comparison of conventional authored and video-based reconstructed avatars, within an environment that encourages exploration and social interaction. Aspects of system quality, including the communication of facial expression and end-to-end latency are reported.},
	keywords     = {aerospace computing;avatars;digital simulation;face recognition;feature extraction;gaze tracking;groupware;image texture;rendering (computer graphics);space research;video signal processing;mixed reality telepresence system;collaborative space exploration improvement;free viewpoint video;immersive projection technology;nonverbal communication;NVC;eye gaze;interpersonal distance;facial expression;Mars simulation;MR system;moving images;lightweight texturing method;multiview rendering;temporal quality;visual quality;display systems;video-based reconstructed avatars;social interaction;end-to-end latency;Three-dimensional displays;Virtual reality;Space exploration;Rendering (computer graphics);Space research;Collaborative work;3D video-based reconstruction;background-foreground segmentation;computer-supported collaborative work;mixed reality (MR);space science;telepresence;litsurvey.bib}
}

@other{Fan,
	title        = {A real-time network security visualization system based on incremental learning (ChinaVis 2018)},
	author       = {Xin Fan and Chenlu Li and Xiaoju Dong},
	doi          = {10.1007/s12650-018-0525-z},
	abstract     = {Journal of Visualization, https://doi.org/10.1007/s12650-018-0525-z},
	file         = {:C\:/Users/its352/Docear/projects/Big data/literature_repository/Data Visuaisation/s12650-018-0525-z.pdf:PDF},
	keywords     = {Real-time analysis, Network security visualization, Machine learning, Incremental learning, Pattern recognition},
	publishers   = {Springer Berlin Heidelberg}
}

@misc{Fastcompany2020,
	title        = {Why working from home might be here to stay},
	author       = {{Fastcompany}},
	year         = 2020,
	howpublished = {\url{https://www.fastcompany.com/90480501/the-incredibly-simple-reason-working-from-home-could-be-here-to-stay}},
	keywords     = {litsurvey.bib}
}

@book{Faugeras2001,
	title        = {{The Geometry of Multiple Images: The Laws That Govern The Formation of Images of A Scene and Some of Their Applications}},
	author       = {Faugeras, Olivier and Luong, Quang-Tuan and Papadopoulou, T},
	year         = 2001,
	publisher    = {MIT Press},
	keywords     = {litsurvey.bib}
}

@article{Faugeras1984,
	title        = {{Polyhedral approximation of {3-D} objects without holes}},
	author       = {Faugeras, O D and Hebert, M and Mussi, P and Boissonnat, J D},
	year         = 1984,
	month        = {\#feb\#},
	journal      = {Computer Vision, Graphics, and Image Processing},
	volume       = 25,
	number       = 2,
	pages        = {169--183},
	abstract     = {An efficient way of building a polyhedral approximation of a set of points in 3-D space is described. The points are the vertices of a planar graph embedded in a surface of genus 0 and are obtained by a laser range finder. The technique presented here is a generalization of an existing algorithm (R. Duda and P. Hart, Pattern Classification and Scene Analysis, Wiley-Interscience, New York 1973) for the polygonal approximation of a simple curve in 2-D space.},
	keywords     = {litsurvey.bib}
}

@article{Fayard2007,
	title        = {Photocopiers and Water-coolers: The Affordances of Informal Interaction},
	author       = {Fayard, Anne-Laure and Weeks, John},
	year         = 2007,
	month        = {\#may\#},
	journal      = {Organization Studies},
	publisher    = {SAGE Publications Ltd},
	volume       = 28,
	number       = 5,
	pages        = {605--634},
	abstract     = {There has been increasing recognition of the importance of informal interactions in organizations, but research examining the effects of the physical environment on informal interaction has produced contradictory results and practical attempts to control the level of informal interaction by design have been marked by unintended consequences. Drawing on a qualitative study of informal interactions observed in photocopier rooms in three organizations, this paper builds on the work of ecological psychologist James Gibson to develop a theory of the affordances of informal interaction. The affordances of an environment are the possibilities for action called forth by it to a perceiving subject. Research on affordances has typically focused on the affordances of individual behavior. We introduce the notion of social affordances and identify the social and physical characteristics that produce the propinquity, privacy, and social designation necessary for an environment to afford informal interactions. The theory of social affordances provides a lens through which to reinterpret the conflicting results of previous studies and to reexamine the seemingly simple water-cooler around which the organization gathers.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Feldmann2009,
	title        = {Multi-view depth estimation based on visual-hull enhanced Hybrid Recursive Matching for {3D} video conference systems},
	author       = {Feldmann, I and Atzpadin, N and Schreer, O and -. Pujol-Acolado, J and -. Landabaso, J and Escoda, O D},
	year         = 2009,
	month        = {\#nov\#},
	booktitle    = {2009 16th {IEEE} International Conference on Image Processing ({ICIP})},
	pages        = {745--748},
	abstract     = {This paper discusses the problem of high quality depth map estimation for real-time systems. Our work is based on the European FP7 project 3DPresence which aims to build a multi-view and multiuser 3D videoconferencing system. Based on new multi-view auto-stereoscopic display technology the remote conferees will be rendered as an integral part of a three dimensional virtual shared environment. In order to create the related views for the 3D displays as well as to virtually correct the eye contact problem robust depth maps are required. For this purpose, in this paper we will discuss the fusion of two competing approaches which have, from a camera configuration point of view, contrary to each other properties. Namely, we will combine the volumetric Visual Hull (VH) approach with the stereo matching based Hybrid Recursive Matching (HRM) to a new method which benefits from the advantages of both techniques and discards their weak points.},
	institution  = {IEEE},
	keywords     = {real-time systems;stereo image processing;video signal processing;multiview depth estimation;visual hull;hybrid recursive matching;3D video conference systems;depth map estimation;real time systems;auto stereoscopic display technology;three dimensional virtual shared environment;3D displays;eye contact problem;Recursive estimation;Videoconference;Cameras;Layout;Image reconstruction;Teleconferencing;Three dimensional displays;Human resource management;Real time systems;Robustness;Depth estimation;Visual-Hull;HRM;stereo-matching;real-time;litsurvey.bib}
}

@article{Fels2000,
	title        = {Toward determining an attention-getting device for improving interaction during video-mediated communication},
	author       = {Fels, D I and Weiss, P L},
	year         = 2000,
	month        = {\#mar\#},
	journal      = {Comput. Human Behav.},
	publisher    = {Elsevier},
	volume       = 16,
	number       = 2,
	pages        = {189--198},
	abstract     = {Video-mediated communication is becoming a more common and effective means of interpersonal communication including work-related activities, distance education, telemedicine, and access to public information. Although the issue of `attention getting' and its importance for interpersonal interaction is well recognized in the video-mediated communication literature there is very little empirical evidence as to the relative effectiveness of the various attributes of attention-getting signals. The objective of this study was to compare the response times and error rates of four attention-getting devices which were suitable for a particular application of video-mediated communication in the educational sector. Twelve subjects (eight female and four male), classroom instructors aged 35--55 years, participated in the study. Four attention-getting devices were tested in this experiment: a red light, a yellow rotating light, a wire hand, and a fan with ribbon streamers. Each device was tested three times in three different classrooms during an actual class with actual instructors (the subjects). A one-way analysis of variance demonstrated a significant difference in response time for the four devices with the yellow light and the metal hand being fastest. This preliminary study points out the importance of empirically testing the effectiveness of attention-getting devices of differing characteristics since, of the four devices tested here, two could be expected to elicit the most immediate response from a communication partner.},
	keywords     = {Video-mediated communication; Attention-getting device; Children and computing;litsurvey.bib}
}

@article{Feng2018,
	title        = {Patterns and pace: Quantifying diverse exploration behavior with visualizations on the web},
	author       = {Feng, Mi and Peck, Evan and Harrison, Lane},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {501--511},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08454489.pdf:PDF}
}

@inproceedings{Ferscha1999,
	title        = {Distributed interaction in virtual spaces},
	author       = {Ferscha, Alois and Johnson, James},
	year         = 1999,
	booktitle    = {Distributed Interactive Simulation and {Real-Time} Applications, 1999. Proceedings. 3rd IEEE International Workshop on},
	pages        = {5--13},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@unpublished{Fish1993,
	title        = {Video as a technology for informal communication},
	author       = {Fish, Robert S and Kraut, Robert E and Root, Robert W and Rice, Ronald E},
	year         = 1993,
	month        = {\#jan\#},
	keywords     = {groupware, collaboration, videoconferencing, informal communication, videophone;litsurvey.bib}
}

@inproceedings{Fish1992,
	title        = {Evaluating video as a technology for informal communication},
	author       = {Fish, Robert S and Kraut, Robert E and Root, Robert W and Rice, Ronald E},
	year         = 1992,
	month        = {\#jun\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Monterey, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '92},
	pages        = {37--48},
	institution  = {ACM},
	keywords     = {informal meetings, video, group work, collaboration, desktop videoconferencing;litsurvey.bib}
}

@article{Flood1958,
	title        = {Some Experimental Games},
	author       = {Flood, Merrill M},
	year         = 1958,
	month        = {\#oct\#},
	journal      = {Manage. Sci.},
	publisher    = {INFORMS},
	volume       = 5,
	number       = 1,
	pages        = {5--26},
	abstract     = {This paper reports the results of six experiments and analyses performed to explore the applicability of the non-constant-sum case of the theories of von Neumann-Morgenstern, and others, to the actual behavior of people playing games or involved in bargaining situations. The paper suggests directions in which the theory of games might be modified and extended to improve its applicability and usefulness. A ?split-the-difference principle? is suggested to augment the usual theory, so as to specify the exact amount of payments to be made in an ordinary two-person bargaining situation such as the sale of a used car. The application of this principle seems satisfactory in the experiments. One experiment suggests that, in a sequence of trials in the same game situation, people tend to start near an equilibrium point and then try to find a better equilibrium, if there is one. The experiments show examples of non-optimal behavior of the bargainers when the judgment necessary to estimate the relevant payoff is obscure. A fair division of five parcels of objects among five players when each player attaches different values to the parcels is outlined and computed, and the effect of coalitions is discussed.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Fonnet2018,
	title        = {Axes and Coordinate Systems Representations for Immersive Analytics of Multi-Dimensional Data},
	author       = {Fonnet, Adrien and Vigier, Toinon and Prie, Yannick and Cliquet, Gregoire and Picarougne, Fabien},
	year         = 2018,
	booktitle    = {2018 International Symposium on Big Data Visual and Immersive Analytics (BDVA)},
	pages        = {1--10},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08533892.pdf:PDF}
}

@misc{France242020,
	title        = {Zoom deemed insecure},
	author       = {{France24}},
	year         = 2020,
	howpublished = {\url{https://www.france24.com/en/20200416-not-a-safe-platform-india-bans-zoom-for-government-use}},
	keywords     = {litsurvey.bib}
}

@inproceedings{Franco2003,
	title        = {Exact polyhedral visual hulls},
	author       = {Franco, J-S and Boyer, E},
	year         = 2003,
	booktitle    = {Procedings of the British Machine Vision Conference 2003},
	location     = {Norwich},
	publisher    = {British Machine Vision Association},
	volume       = 1,
	pages        = {32.1--32.10},
	conference   = {British Machine Vision Conference 2003},
	keywords     = {litsurvey.bib}
}

@inproceedings{Franco2004,
	title        = {A distributed approach for real time {3D} modeling},
	author       = {Franco, J-S and M{\'e}nier, Cl{\'e}ment and Boyer, Edmond and Raffin, Bruno},
	year         = 2004,
	booktitle    = {Computer Vision and Pattern Recognition Workshop, 2004. {CVPRW'04}. Conference on},
	pages        = {31--31},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Franco2009,
	title        = {Efficient polyhedral modeling from silhouettes},
	author       = {Franco, Jean-S{\'e}bastien and Boyer, Edmond},
	year         = 2009,
	month        = {\#mar\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	publisher    = {IEEE},
	volume       = 31,
	number       = 3,
	pages        = {414--427},
	abstract     = {Modeling from silhouettes is a popular and useful topic in computer vision. Many methods exist to compute the surface of the visual hull from silhouettes, but few address the problem of ensuring sane topological properties of the surface, such as manifoldness. This article provides an efficient algorithm to compute such a surface in the form of a polyhedral mesh. It relies on a small number of geometric operations to compute a visual hull polyhedron in a single pass. Such simplicity enables the algorithm to combine the advantages of being fast, producing pixel-exact surfaces, and repeatably yield manifold and watertight polyhedra in general experimental conditions with real data, as verified with all datasets tested. The algorithm is fully described, its complexity analyzed and modeling results given.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@book{franco2014understanding,
	title        = {Understanding bitcoin},
	author       = {Franco, Pedro},
	year         = 2014,
	publisher    = {Wiley Online Library},
	file         = {:../../../literature_repository/bitcoin/Understanding Bitcoin Cryptography - Pedro Franco.pdf:PDF}
}

@article{Fu2018,
	title        = {Malware visualization for fine-grained classification},
	author       = {Fu, Jianwen and Xue, Jingfeng and Wang, Yong and Liu, Zhenyan and Shan, Chun},
	year         = 2018,
	journal      = {IEEE Access},
	publisher    = {IEEE},
	volume       = 6,
	pages        = {14510--14523},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08290767.pdf:PDF}
}

@inproceedings{Fuchs2002,
	title        = {{3D} {Tele-Collaboration} over internet 2},
	author       = {Fuchs, H and Kelshikar, N and Mulligan, J and Daniilidis, K},
	year         = 2002,
	booktitle    = {International Workshop on Immersive Telepresence ({ITP} '02)},
	address      = {Juan Les Pin},
	keywords     = {litsurvey.bib}
}

@article{Fulk1987,
	title        = {A Social Information Processing Model of Media Use in Organizations},
	author       = {Fulk, Janet and Steinfield, Charles W and Schmitz, Joseph and Power, J Gerard},
	year         = 1987,
	month        = {\#oct\#},
	journal      = {Communic. Res.},
	publisher    = {SAGE Publications Inc},
	volume       = 14,
	number       = 5,
	pages        = {529--552},
	abstract     = {This article presents a model of how social influence processes affect individuals' attitudes toward communication media and media use behavior. The model integrates two areas of research. One body of work posits that media use patterns are the outcome of objectively rational choices. These choices involve evaluating communication options and selecting an appropriate medium to match the communication requirements of the task. The second perspective is social information processing theory (Salancik \& Pfeffer, 1978). This approach proposes that attitudes and behaviors are partially determined by information embedded in the social context. The synthesis of these perspectives asserts that media characteristics and attitudes are in part socially constructed. Furthermore, attitudes are influenced by attributions based on observations of one's own past behavior. This model is shown to explain a wider range of existing empirical findings. Also, new propositions are derived to guide future research. This social construction model of media use has significant implications for the design, conduct, and reporting of future research in organizations.},
	keywords     = {litsurvey.bib}
}

@article{Fullwood2006,
	title        = {Effect of gazing at the camera during a video link on recall},
	author       = {Fullwood, Chris and Doherty-Sneddon, Gwyneth},
	year         = 2006,
	month        = {\#mar\#},
	journal      = {Appl. Ergon.},
	publisher    = {Elsevier},
	volume       = 37,
	number       = 2,
	pages        = {167--175},
	abstract     = {The impact of looking into the camera during a presentation over a video link (resulting in the perception of mutual gaze) on information recall was investigated. In a face-to-face context mutual gaze has been shown to facilitate the encoding and subsequent recall of information [Fry, R., Smith, G.F., 1975. The effects of feedback and eye contact on performance of a digit-coding task. J. Soc. Psychol. 96, 145-146; Otteson, J.D., Otteson, C.R., 1980. Effect of teacher's gaze on children's story recall. Percept. Motor Skill. 50, 35-42; Sherwood, J.V., 1988. Facilitative effects of gaze upon learning. Percept. Motor Skill. 64 (3 Part 2), 1275-1278]. One explanation for these findings is that gaze acts as an arousal stimulus, which increases attentional focus and therefore enhances memory [Kelley, D.H., Gorham, J., 1988. Effects of immediacy on recall of information. Commun. Edu. 37(3), 198-207]. Two studies were conducted in order to test whether gazing at the camera during video-mediated presentations resulted in similar benefits as mutual gaze in a face-to-face context. In study 1 a confederate presented information about two fictitious soap products. In one condition, the confederate gazed at the camera for 30\% of the presentation, therefore giving the participants the impression that he was gazing in their direction. In the other condition the confederate did not gaze at the camera. Participants viewed the sales presentations from both conditions. In the condition where gaze was directed at the camera, participants recalled significantly more information about the sales presentation. Study 2 employed the same pre-recorded sales presentations used in study 1, however they were delivered to the participants under audio-only conditions (therefore, the image was switched off). Results from study 2 indicated no recall differences between the two conditions. Findings from these studies would seem to indicate that the perception of gaze aversion over a video link (a consequence of the salesman not looking into the camera) has a negative impact on information recall. This has practical implications for video-mediated presentations. In a distance learning environment lecturers could be advised to look into the camera in order to promote more efficient learning in students.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Furche2016,
	title        = {Data Wrangling for Big Data: Challenges and Opportunities.},
	author       = {Furche, Tim and Gottlob, Georg and Libkin, Leonid and Orsi, Giorgio and Paton, Norman W},
	year         = 2016,
	booktitle    = {EDBT},
	volume       = 16,
	pages        = {473--478},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Data Wrangling for Big Data_ Challenges andOpp.pdf:PDF}
}

@book{Furneaux2018,
	title        = {Investigating Cryptocurrencies: Understanding, Extracting, and Analyzing Blockchain Evidence},
	author       = {Furneaux, Nick},
	year         = 2018,
	publisher    = {John Wiley \& Sons},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Nick_Furneaux_Investigating_Cryptocurrencies_.pdf:PDF}
}

@inproceedings{Garae2018,
	title        = {A Full-Scale Security Visualization Effectiveness Measurement and Presentation Approach},
	author       = {Garae, Jeffery and Ko, Ryan KL and Apperley, Mark},
	year         = 2018,
	booktitle    = {2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
	pages        = {639--650},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08455963.pdf:PDF}
}

@inproceedings{Garau2001,
	title        = {The impact of eye gaze on communication using humanoid avatars},
	author       = {Garau, Maia and Slater, Mel and Bee, Simon and Sasse, Martina Angela},
	year         = 2001,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Seattle, Washington, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '01},
	pages        = {309--316},
	keywords     = {avatars, cmc, collaborative virtual environments, communication, computer-mediated communication, cves, gaze, mediated, nonverbal behaviours; mediated communication; collaborative virtual enviroments (CVEs); computer-mediated communication (CMC);litsurvey.bib}
}

@article{Garau2005,
	title        = {The Responses of People to Virtual Humans in an Immersive Virtual Environment},
	author       = {Garau, Maia and Slater, Mel and Pertaub, David-Paul and Razzaque, Sharif},
	year         = 2005,
	month        = {\#feb\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 14,
	number       = 1,
	pages        = {104--116},
	abstract     = {This paper presents an experiment investigating the impact of behavior and responsiveness on social responses to virtual humans in an immersive virtual environment (IVE). A number of responses are investigated, including presence, copresence, and two physiological responses?heart rate and electrodermal activity (EDA). Our findings suggest that increasing agents' responsiveness even on a simple level can have a significant impact on certain aspects of people's social responses to human-oid agents. Despite being aware that the agents were computer-generated, participants with higher levels of social anxiety were significantly more likely to avoid ?disturbing? them. This suggests that on some level people can respond to virtual humans as social actors even in the absence of complex interaction. Responses appear to be shaped both by the agents' behaviors and by people's expectations of the technology. Participants experienced a significantly higher sense of personal contact when the agents were visually responsive to them, as opposed to static or simply moving. However, this effect diminished with experienced computer users. Our preliminary analysis of objective heart-rate data reveals an identical pattern of responses.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Garau2003,
	title        = {The impact of avatar realism and eye gaze control on perceived quality of communication in a shared immersive virtual environment},
	author       = {Garau, Maia and Slater, Mel and Vinayagamoorthy, Vinoba and Brogni, Andrea and Steed, Anthony and Sasse, M Angela},
	year         = 2003,
	booktitle    = {Proceedings of the {SIGCHI} conference on Human factors in computing systems},
	pages        = {529--536},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@incollection{Gargallo2007,
	title        = {An occupancy--depth generative model of multi-view images},
	author       = {Gargallo, Pau and Sturm, Peter and Pujades, Sergi},
	year         = 2007,
	booktitle    = {Computer {Vision--ACCV} 2007},
	publisher    = {Springer},
	pages        = {373--383},
	keywords     = {litsurvey.bib}
}

@inproceedings{Garrison1999,
	title        = {Critical Inquiry In A Text-based Environment: Computer Conferencing In Higher Education},
	author       = {Garrison, D Randy and Anderson, Terry and Archer, Walter},
	year         = 1999,
	publisher    = {Elsevier},
	volume       = 2,
	pages        = {87--105},
	keywords     = {litsurvey.bib}
}

@inproceedings{Gasparello2011,
	title        = {{{Real-Time} Network Streaming of Dynamic {3D} Content with In-frame and Inter-frame Compression}},
	author       = {Gasparello, P S and Marino, G and Bann{\`o}, F and Tecchia, F and Bergamasco, M},
	year         = 2011,
	month        = {\#sep\#},
	booktitle    = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation and Real Time Applications},
	publisher    = {IEEE},
	address      = {Salford},
	pages        = {81--87},
	abstract     = {Real-time 3D content distribution over a network (either LAN or WAN) has many possible applications, but requires facing several challenges, most notably the handling of the large amount of data usually associated with 3D meshes. The scope of the present paper falls within the well-established context of real-time capture and streaming of OpenGL command sequences, focusing in particular on data compression schemes. However, we advance beyond the state-of-the-art improving over previous attempts of ``in-frame'' geometric compression on 3D structures inferred from generic OpenGL command sequences and adding ``inter-frame'' redundancy exploitation of the traffic generated by the typical architecture of interactive applications. Measurements reveal for this combination of techniques a very effective reduction of network traffic and a CPU overhead compatible with the requirements of interactive applications, suggesting a significant application potential for Internet-based 3D content streaming.},
	keywords     = {computational geometry;content management;data compression;data handling;Internet;media streaming;mesh generation;telecommunication traffic;real-time network streaming;real-time 3D content distribution;in-frame compression;inter-frame compression;data handling;3D meshes;OpenGL command sequences;in-frame geometric compression;inter-frame redundancy exploitation;traffic generation;network traffic reduction;Internet-based 3D content streaming;Three dimensional displays;Real time systems;Data compression;Geometry;Solid modeling;Rendering (computer graphics);Cameras;Distributed Rendering;Distributed Applications;Remote Graphics;Delta Compression;Geometric Compression;litsurvey.bib}
}

@article{Gatica-Perez2009,
	title        = {Automatic nonverbal analysis of social interaction in small groups: A review},
	author       = {Gatica-Perez, Daniel},
	year         = 2009,
	month        = {\#nov\#},
	journal      = {Image Vis. Comput.},
	publisher    = {Elsevier},
	volume       = 27,
	number       = 12,
	pages        = {1775--1787},
	abstract     = {An increasing awareness of the scientific and technological value of the automatic understanding of face-to-face social interaction has motivated in the past few years a surge of interest in the devising of computational techniques for conversational analysis. As an alternative to existing linguistic approaches for the automatic analysis of conversations, a relatively recent domain is using findings in social cognition, social psychology, and communication that have established the key role that nonverbal communication plays in the formation, maintenance, and evolution of a number of fundamental social constructs, which emerge from face-to-face interactions in time scales that range from short glimpses all the way to long-term encounters. Small group conversations are a specific case on which much of this work has been conducted. This paper reviews the existing literature on automatic analysis of small group conversations using nonverbal communication, and aims at bridging the current fragmentation of the work in this domain, currently split among half a dozen technical communities. The review is organized around the main themes studied in the literature and discusses, in a comparative fashion, about 100 works addressing problems related to the computational modeling of interaction management, internal states, personality traits, and social relationships in small group conversations, along with pointers to the relevant literature in social science. Some of the many open challenges and opportunities in this domain are also discussed.},
	keywords     = {Social interaction analysis; Small group conversations; Nonverbal behavior;litsurvey.bib}
}

@article{Gaver1996,
	title        = {Situating Action {II}: Affordances for Interaction: The Social Is Material for Design},
	author       = {Gaver, William W},
	year         = 1996,
	month        = {\#jun\#},
	journal      = {Ecol. Psychol.},
	publisher    = {Routledge},
	volume       = 8,
	number       = 2,
	pages        = {111--129},
	keywords     = {litsurvey.bib}
}

@inproceedings{Gaver1992,
	title        = {The affordances of media spaces for collaboration},
	author       = {Gaver, William W},
	year         = 1992,
	month        = {\#dec\#},
	booktitle    = {Proceedings of the 1992 {ACM} conference on Computer-supported cooperative work},
	location     = {Toronto, Ontario, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '92},
	pages        = {17--24},
	institution  = {ACM},
	keywords     = {ecological approaches, mediaspaces, affordance, video;litsurvey.bib}
}

@inproceedings{Gaver1993,
	title        = {One is not enough: multiple views in a media space},
	author       = {Gaver, William W and Sellen, Abigail and Heath, Christian and Luff, Paul},
	year         = 1993,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {INTERACT} '93 and {CHI} '93 Conference on Human Factors in Computing Systems},
	location     = {Amsterdam, The Netherlands},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '93},
	pages        = {335--341},
	keywords     = {comparisons, experimental studies, not add, of collaboration, on the other hand, see one another does, significantly to the process, tend to suggest, that allowing people to; media spaces; CSCW; video; social interaction;litsurvey.bib}
}

@inproceedings{Gee2005,
	title        = {Uncanny valley revisited},
	author       = {Gee, F C and Browne, W N and Kawamura, K},
	year         = 2005,
	booktitle    = {Robot and Human Interactive Communication, 2005. {IEEE} International Workshop on},
	pages        = {151--157},
	institution  = {Ieee},
	keywords     = {litsurvey.bib}
}

@article{Gemmell2000,
	title        = {Gaze awareness for video-conferencing: a software approach},
	author       = {Gemmell, J and Toyama, K and Zitnick, C L and Kang, T and Seitz, S},
	year         = 2000,
	month        = {\#oct\#},
	journal      = {IEEE Multimedia},
	publisher    = {IEEE},
	volume       = 7,
	number       = 4,
	pages        = {26--35},
	abstract     = {Previous attempts at bringing gaze awareness to desktop videoconferencing have relied on hardware solutions. In this article, the authors describe their software approach, which tracks participants' head and eye movements using vision techniques, then uses this information to graphically place the head and eyes in a 3D environment.},
	keywords     = {teleconferencing;tracking;active vision;computer graphics;groupware;gaze awareness;desktop videoconferencing;software approach;head movements;eye movements;computer vision techniques;graphical placement;3D environment;CSCW;Videoconference;Eyes;Face detection;Humans;Psychology;Teleconferencing;Lips;Animation;Collaborative work;Mouth;litsurvey.bib}
}

@inproceedings{Gergle2006,
	title        = {The impact of delayed visual feedback on collaborative performance},
	author       = {Gergle, Darren and Kraut, Robert E and Fussell, Susan R},
	year         = 2006,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Montr{\'e}al, Qu{\'e}bec, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '06},
	pages        = {1303--1312},
	institution  = {ACM},
	keywords     = {shared visual space, visual delay, language, computer-supported cooperative work, empirical studies, communication;litsurvey.bib}
}

@book{Gibson2014,
	title        = {The ecological approach to visual perception: classic edition},
	author       = {Gibson, James J},
	year         = 2014,
	publisher    = {Psychology Press},
	keywords     = {litsurvey.bib}
}

@article{Gibson1963,
	title        = {Perception of another person's looking behavior},
	author       = {Gibson, J J and Pick, A D},
	year         = 1963,
	month        = {\#sep\#},
	journal      = {Am. J. Psychol.},
	publisher    = {JSTOR},
	volume       = 76,
	number       = 3,
	pages        = {386--394},
	keywords     = {EYE MOVEMENTS; VISUAL PERCEPTION;litsurvey.bib},
	language     = {en}
}

@article{Gillies2005,
	title        = {Non-verbal communication for correlational characters},
	author       = {Gillies, Marco and Slater, Mel and {Others}},
	year         = 2005,
	keywords     = {litsurvey.bib}
}

@article{Godfrey2016,
	title        = {Interactive visualization of large data sets},
	author       = {Godfrey, Parke and Gryz, Jarek and Lasek, Piotr},
	year         = 2016,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	publisher    = {IEEE},
	volume       = 28,
	number       = 8,
	pages        = {2142--2157},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07457691.pdf:PDF}
}

@inproceedings{Goebbels2003,
	title        = {Design and evaluation of team work in distributed collaborative virtual environments},
	author       = {Goebbels, Gernot and Lalioti, Vali and G{\"o}bel, Martin},
	year         = 2003,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the {ACM} symposium on Virtual reality software and technology},
	location     = {Osaka, Japan},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {VRST '03},
	pages        = {231--238},
	institution  = {ACM},
	keywords     = {guidelines, evaluation, CVE Design Model, tele-presence, collaborative virtual environments, awareness;litsurvey.bib}
}

@inproceedings{Goldin-Meadow1999,
	title        = {The role of gesture in communication and thinking},
	author       = {Goldin-Meadow, S},
	year         = 1999,
	volume       = 3,
	pages        = {419--429},
	abstract     = {People move their hands as they talk - they gesture. Gesturing is a robust phenomenon, found across cultures, ages, and tasks. Gesture is even found in individuals blind from birth. But what purpose, if any, does gesture serve? In this review, I begin by examining gesture when it stands on its own, substituting for speech and clearly serving a communicative function. When called upon to carry the full burden of communication, gesture assumes a language-like form, with structure at word and sentence levels. However, when produced along with speech, gesture assumes a different form - it becomes imagistic and analog. Despite its form, the gesture that accompanies speech also communicates. Trained coders can glean substantive information from gesture - information that is not always identical to that gleaned from speech. Gesture can thus serve as a research tool, shedding light on speakers' unspoken thoughts. The controversial question is whether gesture conveys information to listeners not trained to read them. Do spontaneous gestures communicate to ordinary listeners? Or might they be produced only for speakers themselves? I suggest these are not mutually exclusive functions - gesture serves as both a tool for communication for listeners, and a tool for thinking for speakers.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Golovchinsky2009,
	title        = {{DICE}: designing conference rooms for usability},
	author       = {Golovchinsky, Gene and Qvarfordt, Pernilla and van Melle, Bill and Carter, Scott and Dunnigan, Tony},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {1015--1024},
	institution  = {ACM},
	keywords     = {ubiquitous computing, smart environments, usability;litsurvey.bib}
}

@article{Goodwin2000,
	title        = {Action and embodiment within situated human interaction},
	author       = {Goodwin, Charles},
	year         = 2000,
	month        = {\#sep\#},
	journal      = {J. Pragmat.},
	publisher    = {Elsevier},
	volume       = 32,
	number       = 10,
	pages        = {1489--1522},
	abstract     = {A theory of action must come to terms with both the details of language use and the way in which the social, cultural, material and sequential structure of the environment where action occurs figure into its organization. In this paper it will be suggested that a primordial site for the analysis of human language, cognition, and action consists of a situation in which multiple participants are attempting to carry out courses of action in concert with each other through talk while attending to both the larger activities that their current actions are ambedded within, and relevant phenomena in their surround. Using as data video recordings of young girls playing hopscotch and archaeologists classifying color, it will be argued that human action is built throught the simultaneous deployment of a range of quite different kinds of semiotic resources. Talk itself contains multiple sign systems with alternative properties. Strips of talk gain their power as social action via their placement within larger sequential structures, encompassing activities, and participation frameworks constituted through displays of mutual orientation made by the actors' bodies. The body is used in a quite different way to perform gesture, again a class of phenomena that encompasses structurally different types of sign systems. Both talk and gesture can index, construe or treat as irrelevant, entities in the participants' surround. Moreover, material structure in the surround, such as graphic fields of various types, can provide semiotic structure without which the constitution of particular kinds of action being invoked through talk would be impossible. In brief it will be argued that the construction of action through talk within situated interaction is accomplished through the temporally unfolding juxtaposition of quite different kinds of semiotic resources, and that moreover through this process the human body is made publicly visible as the site for a range of structurally different kinds of displays implicated in the constitution of the actions of the moment.},
	keywords     = {Theory of action; Conversation analysis; Talk-in-interaction; Embodiment; Gestures; Semiotic fields;litsurvey.bib}
}

@article{Gorodnichy2004,
	title        = {Nouse `use your nose as a mouse' perceptual vision technology for hands-free games and interfaces},
	author       = {Gorodnichy, Dmitry O and Roth, Gerhard},
	year         = 2004,
	month        = {\#oct\#},
	journal      = {Image Vis. Comput.},
	volume       = 22,
	number       = 12,
	pages        = {931--942},
	abstract     = {Due to recent increase of computer power and decrease of camera cost, it became very common to see a camera on top of a computer monitor. This paper presents the vision-based technology which allows one in such a setup to significantly enhance the perceptual power of the computer. The described techniques for tracking a face using a convex-shape nose feature as well as for face-tracking with two off-the-shelf cameras allow one to track faces robustly and precisely in both 2D and 3D with low resolution cameras. Supplemented by the mechanism for detecting multiple eye blinks, this technology provides a complete solution for building intelligent hands-free input devices. The theory behind the technology is presented. The results from running several perceptual user interfaces built with this technology are shown.},
	keywords     = {computer human, face tracking, stereo tracking; Computer-human; Stereo-tracking; Face-tracking;litsurvey.bib}
}

@inproceedings{Gotsch2018,
	title        = {{TeleHuman2}: A Cylindrical Light Field Teleconferencing System for Life-size {3D} Human Telepresence},
	author       = {Gotsch, Daniel and Zhang, Xujing and Merritt, Timothy and Vertegaal, Roel},
	year         = 2018,
	booktitle    = {{CHI}},
	pages        = 522,
	keywords     = {litsurvey.bib}
}

@inproceedings{Grau2007,
	title        = {A Robust {Free-Viewpoint} Video System for Sport Scenes},
	author       = {Grau, O and Thomas, G A and Hilton, A and Kilner, J and Starck, J},
	year         = 2007,
	month        = {\#may\#},
	booktitle    = {2007 {3DTV} Conference},
	pages        = {1--4},
	abstract     = {This contribution describes robust methods to provide a free-viewpoint video visualisation of sport scenes using a multi-camera set-up. This allows generation of novel views of actions from any angle and is of interest for visualisation in TV productions. The system utilises 3D reconstruction techniques previously developed for studio use. This paper discusses some experiences found while applying these techniques for an uncontrolled outdoor environment and addresses robustness issues. This includes segmentation, camera calibration and 3D reconstruction. A number of different 3D representations, including billboards, visual hulls and view-dependent geometry are evaluated for the purpose.},
	institution  = {IEEE},
	keywords     = {image reconstruction;image representation;three-dimensional television;video signal processing;robust free-viewpoint video system;sport scenes;robust methods;free-viewpoint video visualisation;multi-camera set-up;TV productions;3D reconstruction techniques;uncontrolled outdoor environment;camera calibration;Robustness;Layout;Cameras;Robot vision systems;Visualization;Broadcasting;Calibration;TV;Production;Geometry;litsurvey.bib}
}

@article{De_Greef2001,
	title        = {Social presence in a home tele-application},
	author       = {de Greef, P and Ijsselsteijn, W A},
	year         = 2001,
	month        = {\#apr\#},
	journal      = {Cyberpsychol. Behav.},
	publisher    = {Mary Ann Liebert, Inc.},
	volume       = 4,
	number       = 2,
	pages        = {307--315},
	abstract     = {The current paper presents a study on the subjective evaluation of an advanced telecommunication platform aimed at informal home use, called the PhotoShare tele-application. This platform enables users to view photos (e.g., family or holiday snapshots) together, while the presenter and the viewer are at different, remote locations. The platform includes a common viewing space where the photos are displayed and selected, as well as an audio connection and a large-screen video connection for communication between the remote sites. The study investigated the effects of videocommunication on social presence. In addition, the ability to point at a picture with an electronic pointer was evaluated. In the context of presence research, the current study also provided information regarding the validity of the IPO Social Presence Questionnaire (IPO-SPQ), which was specifically designed to investigate social presence with telecommunication applications. The results indicated that adding broadband, life-size video communication significantly increased social presence. In addition, we found a significant effect of sex on social presence: women gave substantially higher social presence ratings than men. The absence of a significant effect of the pointing function indicated that extensive workspace functionality may be of minor importance to the user's feeling of social presence.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Greenberg1976,
	title        = {The Role of Seating Position in Group Interaction: A Review, with Applications for Group Trainers},
	author       = {Greenberg, Jerald},
	year         = 1976,
	month        = {\#sep\#},
	journal      = {Group \& Organization Studies},
	publisher    = {SAGE Publications},
	volume       = 1,
	number       = 3,
	pages        = {310--327},
	abstract     = {Experimental research relating seating position to group interaction was critically reviewed. Studies have found that persons in central seating positions were able to maintain eye contact with the most group mem bers, thereby enhancing their ability to interact with the group and emerge as the leader. Tasks requiring interpersonal communication were associated with the use of close seating arrangements, and tasks requir ing independent activities were associated with distant seating ar rangements. Research on affiliative relations found that physical close ness enhances friendship formation and is a reliable sociometric index of friendship choices within groups. Final discussion centered on the prac tical implications of these findings for the group training session. It was stressed that group trainers learn to alter the seating positions of mem bers in order to facilitate the attainment of group goals.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Greenhalgh1997,
	title        = {Boundaries, awareness and interaction in collaborative virtual environments},
	author       = {Greenhalgh, Chris and Benford, Steve},
	year         = 1997,
	booktitle    = {Enabling Technologies: Infrastructure for Collaborative Enterprises, 1997. Proceedings., Sixth {IEEE} Workshops on},
	pages        = {193--198},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@unpublished{Greenhalgh1995,
	title        = {{MASSIVE}: a collaborative virtual environment for teleconferencing},
	author       = {Greenhalgh, Chris and Benford, Steven},
	year         = 1995,
	month        = {\#sep\#},
	keywords     = {CSCW, scalability;litsurvey.bib}
}

@article{Greenhalgh2001,
	title        = {Making Networked Virtual Environments Work},
	author       = {Greenhalgh, Chris and Bullock, Adrian and Fr{\'e}con, Emmanuel and Lloyd, David and Steed, Anthony},
	year         = 2001,
	month        = {\#apr\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 10,
	number       = 2,
	pages        = {142--159},
	abstract     = {Collaborative virtual environments (CVEs) are a promising technology enabling remote participants to share a common place through three-dimensional graphical scenes. Within the COVEN project (Normand, 1999), we have run prolonged series of Internet trials that have allowed us to gather valuable data to formulate usability guidelines and networking requirements. However, running such trials in a real setting and making sure that the application and networking infrastructures will be stable enough is still a challenge. In this paper, we describe some of our experiences, together with the technical choices that have permitted many hours of successful Internet trials. We also make a thorough analysis of different correlated logging data. This analysis allows us to propose and confirm a model of a CVE application's network behavior, together with a number of interesting results that disprove some common assumptions. Furthermore, we use the model and the logging data to highlight the benefits of IP multicasting and for predicting traffic behaviors and bandwidth use on top of different logical network topologies.},
	keywords     = {litsurvey.bib}
}

@article{Gregor2006,
	title        = {The Nature of Theory in Information Systems},
	author       = {Gregor, Shirley},
	year         = 2006,
	journal      = {Miss. Q.},
	publisher    = {Management Information Systems Research Center, University of Minnesota},
	volume       = 30,
	number       = 3,
	pages        = {611--642},
	abstract     = {[The aim of this research essay is to examine the structural nature of theory in Information Systems. Despite the importance of theory, questions relating to its form and structure are neglected in comparison with questions relating to epistemology. The essay addresses issues of causality, explanation, prediction, and generalization that underlie an understanding of theory. A taxonomy is proposed that classifies information systems theories with respect to the manner in which four central goals are addressed: analysis, explanation, prediction, and prescription. Five interrelated types of theory are distinguished: (1) theory for analyzing, (2) theory for explaining, (3) theory for predicting, (4) theory for explaining and predicting, and (5) theory for design and action. Examples illustrate the nature of each theory type. The applicability of the taxonomy is demonstrated by classifying a sample of journal articles. The paper contributes by showing that multiple views of theory exist and by exposing the assumptions underlying different viewpoints. In addition, it is suggested that the type of theory under development can influence the choice of an epistemological approach. Support is given for the legitimacy and value of each theory type. The building of integrated bodies of theory that encompass all theory types is advocated.]},
	keywords     = {litsurvey.bib}
}

@inproceedings{Grimstead2005,
	title        = {Collaborative visualization: a review and taxonomy},
	author       = {Grimstead, I J and Walker, D W and Avis, N J},
	year         = 2005,
	month        = {\#oct\#},
	booktitle    = {Ninth {IEEE} International Symposium on Distributed Simulation and {Real-Time} Applications},
	publisher    = {Ieee},
	pages        = {61--69},
	abstract     = {We present a brief review of 42 collaborative visualization systems, grouped into four application areas: collaborative problem-solving environments, virtual reality environments, multi-player online games and multi-user enabling of single user applications. The systems are then compared by five attributes: number of simultaneous users, user access control, communication architecture, type of transmitted data and user synchronization. We review the characteristic properties of each application area, overall trends in characteristics and recommend improvements for future systems. The taxonomy of visualization and accompanying bibliography are available on-line via the RAVE project pages by Grimstead, I.J., (2005), with on-line references hyper-linked where available.},
	keywords     = {groupware;bibliographies;data visualisation;virtual reality;user interfaces;collaborative visualization taxonomy;collaborative problem-solving;virtual reality;multiplayer online games;user access control;communication architecture;data transmission;user synchronization;bibliography;online references;Taxonomy;Layout;Data visualization;Application software;Online Communities/Technical Collaboration;Virtual reality;Peer to peer computing;Problem-solving;Analytical models;Access control;litsurvey.bib}
}

@inproceedings{Gross2003,
	title        = {blue-c: a spatially immersive display and {3D} video portal for telepresence},
	author       = {Gross, Markus and W{\"u}rmlin, Stephan and Naef, Martin and Lamboray, Edouard and Spagno, Christian and Kunz, Andreas and Koller-Meier, Esther and Svoboda, Tomas and Van Gool, Luc and Lang, Silke and Strehlke, Kai and Moere, Andrew Vande and Staadt, Oliver},
	year         = 2003,
	month        = {\#jul\#},
	booktitle    = {{ACM} {SIGGRAPH} 2003 Papers},
	location     = {San Diego, California},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGGRAPH '03},
	volume       = 22,
	pages        = {819--827},
	institution  = {ACM},
	keywords     = {virtual environments, graphics hardware, spatially immersive displays, 3D Video, real-time graphics;litsurvey.bib}
}

@inproceedings{Grossman2008,
	title        = {Collaborative interaction with volumetric displays},
	author       = {Grossman, Tovi and Balakrishnan, Ravin},
	year         = 2008,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Florence, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '08},
	pages        = {383--392},
	institution  = {ACM},
	keywords     = {collaborative interaction, volumetric displays;litsurvey.bib}
}

@inproceedings{Gu2006,
	title        = {Visual Attention and Eye Gaze During Multiparty Conversations with Distractions},
	author       = {Gu, Erdan and Badler, Norman I},
	year         = 2006,
	booktitle    = {Intelligent Virtual Agents},
	publisher    = {Springer Berlin Heidelberg},
	pages        = {193--204},
	abstract     = {Our objective is to develop a computational model to predict visual attention behavior for an embodied conversational agent. During interpersonal interaction, gaze provides signal feedback and directs conversation flow. Simultaneously, in a dynamic environment, gaze also directs attention to peripheral movements. An embodied conversational agent should therefore employ social gaze not only for interpersonal interaction but also to possess human attention attributes so that its eyes and facial expression portray and convey appropriate distraction and engagement behaviors.},
	institution  = {Springer},
	keywords     = {litsurvey.bib}
}

@article{Gunawardena1997,
	title        = {Social presence as a predictor of satisfaction within a computer ?mediated conferencing environment},
	author       = {Gunawardena, Charlotte N and Zittle, Frank J},
	year         = 1997,
	month        = {\#jan\#},
	journal      = {Am. J. Distance Educ.},
	publisher    = {Routledge},
	volume       = 11,
	number       = 3,
	pages        = {8--26},
	abstract     = {Abstract Based on the GlobalEd inter?university computer conference, this study examined how effective ?social presence? is as a predictor of overall learner satisfaction in a text?based medium. The stepwise regression analysis converged on a three?predictor model revealing that social presence (the degree to which a person is perceived as ?real? in mediated communication), student perception of having equal opportunity to participate, and technical skills accounted for about 68\% of the explained variance. Social presence alone contributed about 60\% of this variance, suggesting that it may be a very strong predictor of satisfaction. Reliability data on the social presence scale is provided. The results also indicated that participants who felt a higher sense of social presence enhanced their socio?emotional experience by using emoticons to express missing nonverbal cues in written form. These findings have implications for designing academic computer conferences where equal attention must be paid to designing techniques that enhance social presence.},
	keywords     = {litsurvey.bib}
}

@article{Guye-Vuilleme1999,
	title        = {Nonverbal communication interface for collaborative virtual environments},
	author       = {Guye-Vuill{\`e}me, A and Capin, T K and Pandzic, S and Thalmann, N Magnenat and Thalmann, D},
	year         = 1999,
	month        = {\#mar\#},
	journal      = {Virtual Real.},
	publisher    = {Springer},
	volume       = 4,
	number       = 1,
	pages        = {49--59},
	abstract     = {Nonverbal communication is an important aspect of real-life face-to-face interaction and one of the most efficient ways to convey emotions, therefore users should be provided the means to replicate it in the virtual world. Because articulated embodiments are well suited to provide body communication in virtual environments, this paper first reviews some of the advantages and disadvantages of complex embodiments. After a brief introduction to nonverbal communication theories, we present our solution, taking into account the practical limitations of input devices and social science aspects. We introduce our sample of actions and implementation using our VLNET (Virtual Life Network) networked virtual environment and discuss the results of an informal evaluation experiment.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Hackathorn2016,
	title        = {Immersive analytics: Building virtual data worlds for collaborative decision support},
	author       = {Hackathorn, Richard and Margolis, Todd},
	year         = 2016,
	booktitle    = {2016 Workshop on Immersive Analytics (IA)},
	pages        = {44--47},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07932382.pdf:PDF}
}

@book{petzold2008annotated,
	title        = {The annotated Turing: a guided tour through Alan Turing's historic paper on computability and the Turing machine},
	author       = {Petzold, Charles},
	year         = 2008,
	publisher    = {Wiley Publishing}
}

@article{Hager1979,
	title        = {Long-distance of transmission of facial affect signals},
	author       = {Hager, Joseph C and Ekman, Paul},
	year         = 1979,
	month        = {\#oct\#},
	journal      = {Ethol. Sociobiol.},
	publisher    = {Elsevier},
	volume       = 1,
	number       = 1,
	pages        = {77--82},
	abstract     = {This study examined the distance at which certain facial expression can transmit affect messages. A man and a woman assumed---facial expressions that were selected carefully to represent six affects. These expressions were shown in still photographs and in live portrayals to 49 observers who composed four groups which were 30, 35, 40, and 45 meters away from the stimuli. Photographs and live portrayals produced comparable results. Every observer was able to label the expressions accurately although accuracy declined as distance increased. Extrapolation from the data suggested that some messages may be sent far beyond the distances used in this study. These results raise important issues about the transmission of facial signals over distance and suggest that the face is a long-distance transmitter of affect signals.},
	keywords     = {Facial expression;litsurvey.bib}
}

@book{Hall1969,
	title        = {The Hidden Dimension},
	author       = {Hall, Edward Twitchell and Hall, Edward T},
	year         = 1969,
	publisher    = {Anchor Books New York},
	volume       = 1990,
	keywords     = {litsurvey.bib}
}

@inproceedings{Hall-Holt2001,
	title        = {{Stripe boundary codes for real-time structured-light range scanning of moving objects}},
	author       = {Hall-Holt, O and Rusinkiewicz, S},
	year         = 2001,
	booktitle    = {Proceedings of the 8\textbackslashtextsuperscript{th} International Conference on Computer Vision ({ICCV} '01)},
	publisher    = {IEEE Comput. Soc},
	address      = {Vancouver},
	pages        = {359--366},
	keywords     = {litsurvey.bib}
}

@inproceedings{Hancock2004,
	title        = {Deception and design: the impact of communication technology on lying behavior},
	author       = {Hancock, Jeffrey T and Thom-Santelli, Jennifer and Ritchie, Thompson},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {129--134},
	institution  = {ACM},
	keywords     = {lying, communication, trust, deception, CMC, media;litsurvey.bib}
}

@article{Harms2004,
	title        = {Internal consistency and reliability of the networked minds measure of social presence},
	author       = {Harms, Chad and Biocca, Frank},
	year         = 2004,
	keywords     = {litsurvey.bib}
}

@inproceedings{Harrop2006,
	title        = {Real-time collaborative network monitoring and control using 3D game engines for representation and interaction},
	author       = {Harrop, Warren and Armitage, Grenville},
	year         = 2006,
	booktitle    = {Proceedings of the 3rd international workshop on Visualization for computer security},
	pages        = {31--40},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1179576.1179583.pdf:PDF}
}

@book{Hartley2003,
	title        = {{Multiple View Geometry in Computer Vision}},
	author       = {Hartley, Richard and Zisserman, Andrew},
	year         = 2003,
	publisher    = {Cambridge University Press},
	edition      = 2,
	abstract     = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@phdthesis{Hauber2008,
	title        = {Understanding Remote Collaboration in Video Collaborative Virtual Environments},
	author       = {Hauber, J{\"o}rg},
	year         = 2008,
	school       = {University of Canterbury},
	keywords     = {litsurvey.bib}
}

@inproceedings{Hauber2006,
	title        = {{Spatiality in videoconferencing: trade-offs between efficiency and social presence}},
	author       = {Hauber, J{\"o}rg and Regenbrecht, Holger and Billinghurst, Mark and Cockburn, Andy},
	year         = 2006,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work},
	location     = {Banff, Alberta, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '06},
	pages        = {413--422},
	keywords     = {2d and 3d video, are interested in comparing, collaborative virtual, distributed collaboration, environment, in our work we, photo-ware, social presence, videoconferencing; remote collaboration; collaborative virtual environment;litsurvey.bib}
}

@article{Hauber2005,
	title        = {Social presence in two-and three-dimensional videoconferencing},
	author       = {Hauber, J{\"o}rg and Regenbrecht, Holger and Hills, Aimee and Cockburn, Andrew and Billinghurst, Mark},
	year         = 2005,
	publisher    = {University of Canterbury. Computer Science and Software Engineering.},
	keywords     = {litsurvey.bib}
}

@incollection{Hauser2006,
	title        = {Generalizing focus+ context visualization},
	author       = {Hauser, Helwig},
	year         = 2006,
	booktitle    = {Scientific visualization: The visual extraction of knowledge from data},
	publisher    = {Springer},
	pages        = {305--327},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Generalizing Focus + Context Visualization.pdf:PDF}
}

@article{Hauser2005,
	title        = {Toward new grounds in visualization},
	author       = {Hauser, Helwig},
	year         = 2005,
	journal      = {ACM SIGGRAPH Computer Graphics},
	volume       = 39,
	number       = 2,
	pages        = {5--8},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Towards New Grounds in Visualization.pdf:PDF}
}

@inproceedings{hauser2003interactive,
	title        = {Interactive volume visualization of complex flow semantics.},
	author       = {Hauser, Helwig and Mlejnek, Matej},
	year         = 2003,
	booktitle    = {VMV},
	pages        = {191--198},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Interactive Volume Visualization of Complex Fl.pdf:PDF}
}

@article{Hawes2018,
	title        = {Factors informing outcomes for older cats and dogs in animal shelters},
	author       = {Hawes, Sloane and Kerrigan, Josephine and Morris, Kevin},
	year         = 2018,
	journal      = {Animals},
	publisher    = {Multidisciplinary Digital Publishing Institute},
	volume       = 8,
	number       = 3,
	pages        = 36,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/animals-08-00036.pdf:PDF}
}

@article{Haythornthwaite1995,
	title        = {Work relationships and media use: A social network analysis},
	author       = {Haythornthwaite, Caroline and Wellman, Barry and Mantei, Marilyn},
	year         = 1995,
	month        = {\#may\#},
	journal      = {Group Decision and Negotiation},
	publisher    = {Springer},
	volume       = 4,
	number       = 3,
	pages        = {193--211},
	abstract     = {Our research provided empirical evidence about the alternative means of communication used by 25 members of a research group who had available to them: unscheduled face-to-face encounters, sheduled face-to-face meetings, electronic mail, telephone, fax, and desktop videoconferencing. The intent of our research is to learn whether there are elements in existing group communication patterns that suggest how future communication systems can be designed or selected to fit the actual work relationships of a group. A detailed social network survey provided information about what members of the group communicated about, how they communicated, and with whom they communicated. Most communication was done through a combination of media, but predominately through unscheduled encounters, electronic mail, and scheduled meetings; people rarely videoconferenced, telephoned, or faxed. Factor analysis reduced the 24 work relationships to six distinct dimensions: receiving work, giving work, collaborative writing, major emotional support, sociability, and computer programming. The proportion in which the three main media were used varied according to the nature of the work dimension. Our findings suggest that a multivariate perspective that considers group norms and practices, social networks, and work dimensions is necessary to analyze media use.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Hedge1978,
	title        = {The Role Of Gaze In Dialogue},
	author       = {Hedge, B J and Everitt, B S and Frith, Christopher D},
	year         = 1978,
	publisher    = {Elsevier},
	volume       = 42,
	pages        = {453--475},
	keywords     = {litsurvey.bib}
}

@article{Heeter1992,
	title        = {Being There: The Subjective Experience of Presence},
	author       = {Heeter, Carrie},
	year         = 1992,
	month        = {\#jan\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 1,
	number       = 2,
	pages        = {262--271},
	keywords     = {litsurvey.bib}
}

@article{Heldal2005,
	title        = {Successes and Failures in {Co-Present} Situations},
	author       = {Heldal, Ilona and Steed, Anthony and Spante, Maria and Schroeder, Ralph and Bengtsson, Sophia and Partanen, Marja},
	year         = 2005,
	month        = {\#oct\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 14,
	number       = 5,
	pages        = {563--579},
	abstract     = {Virtual environments systems based on immersive projection technologies (IPTs) offer users the possibility of collaborating intuitively in a 3D environment. While considerable work has been done to examine interaction in desktop-based collaborative virtual environments (CVEs), there are currently no studies for collaborative interaction using IPTs. The aim of this paper is to examine how immersive technologies support interaction and to compare this to the experience with desktop systems. A study of collaboration is presented where two partners worked together using networked IPT environments. The data collected included observations, analysis of video and audio recordings, questionnaires and debriefing interviews from both IPT sites. This paper focuses on the successes and failures in collaboration through detailed examination of particular incidents during the interaction. We compare these successes and failures with the findings of a study by Hindmarsh, Fraser, Heath, \& Benford (Computer Supported Collaborative Work, CSCW'98, 1998, pp. 217?226) that examined object-focused interaction on a desktop-based CVE system. Our findings identify situations where interaction is better supported with the IPT system than the desktop system, and situations where interaction is not as well supported. We also present examples of how social interaction is critical to seamless collaboration.},
	keywords     = {litsurvey.bib}
}

@article{Heldner2010,
	title        = {Pauses, gaps and overlaps in conversations},
	author       = {Heldner, Mattias and Edlund, Jens},
	year         = 2010,
	month        = {\#oct\#},
	journal      = {J. Phon.},
	publisher    = {Elsevier},
	volume       = 38,
	number       = 4,
	pages        = {555--568},
	abstract     = {This paper explores durational aspects of pauses, gaps and overlaps in three different conversational corpora with a view to challenge claims about precision timing in turn-taking. Distributions of pause, gap and overlap durations in conversations are presented, and methodological issues regarding the statistical treatment of such distributions are discussed. The results are related to published minimal response times for spoken utterances and thresholds for detection of acoustic silences in speech. It is shown that turn-taking is generally less precise than is often claimed by researchers in the field of conversation analysis or interactional linguistics. These results are discussed in the light of their implications for models of timing in turn-taking, and for interaction control models in speech technology. In particular, it is argued that the proportion of speaker changes that could potentially be triggered by information immediately preceding the speaker change is large enough for reactive interaction controls models to be viable in speech technology.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Helm2018,
	title        = {Enabling Collaborative Decision Making Through Immersive Visualisation},
	author       = {Helm, Paul and Pickering, Julian and others},
	year         = 2018,
	booktitle    = {SPE Annual Technical Conference and Exhibition},
	organization = {Society of Petroleum Engineers},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/SPE-191525-MS.pdf:PDF}
}

@inproceedings{Herraiz2009,
	title        = {{{GPU} acceleration of a fully {3D} Iterative Reconstruction Software for {PET} using {CUDA}}},
	author       = {Herraiz, J L and Espa{\~n}a, S and Garc{\'\i}a, S and Cabido, R and Montemayor, A S and Desco, M and Vaquero, J J and Udias, J M},
	year         = 2009,
	month        = {\#oct\#},
	booktitle    = {2009 {IEEE} Nuclear Science Symposium Conference Record ({NSS/MIC})},
	pages        = {4064--4067},
	abstract     = {A CUDA implementation of the existing software FIRST (Fast Iterative Reconstruction Software for (PET) Tomography) is presented. This implementation uses consumer graphics processing units (GPUs) to accelerate the compute-intensive parts of the reconstruction: forward and backward projection. FIRST was originally developed in FORTRAN, and it has been migrated to C language to be used with NVIDIA C for CUDA, as well as for a straightforward implementation and performance comparison between the C versions of the code running on the CPU and on the GPU. We measured the execution time of the CUDA version compared to the fastest available CPU. The CUDA implementation includes a loop re-ordering and an optimized memory allocation, which improves even more the performance of the reconstruction on the GPUs.},
	keywords     = {C language;coprocessors;image reconstruction;iterative methods;medical image processing;positron emission tomography;transforms;GPU acceleration;fully 3D iterative reconstruction software;PET reconstruction software;CUDA;FIRST software;Fast Iterative Reconstruction Software for Tomography;graphics processing units;forward projection;backward projection;C language;NVIDIA C;loop reordering;optimised memory allocation;Acceleration;Positron emission tomography;Central Processing Unit;Hospitals;Nuclear and plasma sciences;Graphics;Time measurement;Iterative methods;Radiation detectors;Multicore processing;litsurvey.bib}
}

@inproceedings{Hilliges2012,
	title        = {{HoloDesk}: direct 3d interactions with a situated see-through display},
	author       = {Hilliges, Otmar and Kim, David and Izadi, Shahram and Weiss, Malte and Wilson, Andrew},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {2421--2430},
	institution  = {ACM},
	keywords     = {kinect, see-through display, 3d physics interactions, augmented reality (ar), natural human grasping;litsurvey.bib}
}

@article{Hilton2000,
	title        = {{Whole-body modelling of people from multiview images to populate virtual worlds}},
	author       = {Hilton, Adrian and Beresford, Daniel and Gentils, Thomas and Smith, Raymond and Sun, Wei and Illingworth, John},
	year         = 2000,
	month        = {\#nov\#},
	journal      = {Vis. Comput.},
	volume       = 16,
	number       = 7,
	pages        = {411--436},
	abstract     = {In this paper a new technique is introduced for automatically building recognisable, moving 3D models of individual people. A set of multiview colour images of a person is captured from the front, sides and back by one or more cameras. Model-based reconstruction of shape from silhouettes is used to transform a standard 3D generic humanoid model to approximate a person's shape and anatomical structure. Realistic appearance is achieved by colour texture mapping from the multiview images. The results show the reconstruction of a realistic 3D facsimile of the person suitable for animation in a virtual world. The system is inexpensive and is reliable for large variations in shape, size and clothing. This is the first approach to achieve realistic model capture for clothed people and automatic reconstruction of animated models. A commercial system based on this approach has recently been used to capture thousands of models of the general public.},
	keywords     = {litsurvey.bib}
}

@unpublished{Hindmarsh2000,
	title        = {Object-focused interaction in collaborative virtual environments},
	author       = {Hindmarsh, Jon and Fraser, Mike and Heath, Christian and Benford, Steve and Greenhalgh, Chris},
	year         = 2000,
	month        = {\#dec\#},
	keywords     = {embodiment, user interface design, objects, virtual reality, CSCW, shared spaces, social interaction;litsurvey.bib}
}

@article{Ho2010,
	title        = {Revisiting the uncanny valley theory: Developing and validating an alternative to the Godspeed indices},
	author       = {Ho, Chin-Chang and MacDorman, Karl F},
	year         = 2010,
	month        = {\#nov\#},
	journal      = {Comput. Human Behav.},
	publisher    = {Elsevier Science Publishers B. V.},
	address      = {Amsterdam, The Netherlands, The Netherlands},
	volume       = 26,
	number       = 6,
	pages        = {1508--1518},
	abstract     = {Mori (1970) proposed a hypothetical graph describing a nonlinear relation between a character's degree of human likeness and the emotional response of the human perceiver. However, the index construction of these variables could result in their strong correlation, thus preventing rated characters from being plotted accurately. Phase 1 of this study tested the indices of the Godspeed questionnaire as measures of humanlike characters. The results indicate significant and strong correlations among the relevant indices (Bartneck, Kuli{\'c}, Croft, \& Zoghbi, 2009). Phase 2 of this study developed alternative indices with nonsignificant correlations (p>.05) between the proposed y-axis eeriness and x-axis perceived humanness (r=.02). The new humanness and eeriness indices facilitate plotting relations among rated characters of varying human likeness.},
	keywords     = {Affective appraisal, Embodied agents, Human-robot interaction, Psychometric scales, Social perception; Human--robot interaction;litsurvey.bib}
}

@inproceedings{Ho2008,
	title        = {Human emotion and the uncanny valley: a {GLM}, {MDS}, and Isomap analysis of robot video ratings},
	author       = {Ho, Chin-Chang and MacDorman, Karl F and Pramono, Z A D Dwi},
	year         = 2008,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the 3rd {ACM/IEEE} international conference on Human robot interaction},
	location     = {Amsterdam, The Netherlands},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {HRI '08},
	pages        = {169--176},
	institution  = {ACM},
	keywords     = {data visualization, android science, uncanny valley, emotion;litsurvey.bib}
}

@article{Hofmann2006,
	title        = {Sex differences in face recognition and influence of facial affect},
	author       = {Hofmann, Stefan G and Suvak, Michael and Litz, Brett T},
	year         = 2006,
	month        = {\#jun\#},
	journal      = {Pers. Individ. Dif.},
	volume       = 40,
	number       = 8,
	pages        = {1683--1690},
	abstract     = {To study sex differences in the recognition of human faces with different facial expressions, 65 female and 64 male participants learned to associate names with various male and female neutral faces. During the recall phase, participants were then asked to name the same persons depicting different emotional expressions (neutral, happy, angry, and fearful). Females were faster than males at naming male faces, and males were faster than females at naming female faces. All participants were faster at naming neutral or happy female faces than neural or happy male faces. These results suggest that opposite-sex faces require less processing time than same-sex faces, which is consistent with an evolutionary account.},
	keywords     = {Sex difference; Recognition; Facial affect; Emotional processing; Reaction time; Evolutionary psychology;litsurvey.bib}
}

@article{Holm2010,
	title        = {Face-to-face lying -- An experimental study in Sweden and Japan},
	author       = {Holm, H{\aa}kan J and Kawagoe, Toshiji},
	year         = 2010,
	month        = {\#jun\#},
	journal      = {J. Econ. Psychol.},
	publisher    = {Elsevier},
	volume       = 31,
	number       = 3,
	pages        = {310--321},
	abstract     = {This paper investigates face-to-face lying and beliefs associated with it. In experiments in Sweden and Japan, subjects answer questions about personal characteristics, play a face-to-face sender--receiver game and participate in an elicitation of lie-detection beliefs. The previous finding of too much truth-telling (compared to the equilibrium prediction) also holds in the face-to-face setting. A new result is that although many people claim that they are good at lie-detection, few reveal belief in this ability when money is at stake. Correlations between the subjects' characteristics and their behavior and performances in the game are also explored.},
	keywords     = {Lying; Game theory; Truth detection; Lie-detection; Experiment;litsurvey.bib}
}

@book{Horgen1999,
	title        = {Excellence by design: Transforming workplace and work practice},
	author       = {Horgen, Turid},
	year         = 1999,
	publisher    = {John Wiley \& Sons},
	keywords     = {litsurvey.bib}
}

@inproceedings{Howard2006,
	title        = {Negotiating presence-in-absence: contact, content and context},
	author       = {Howard, Steve and Kjeldskov, Jesper and Skov, Mikael B and Garn{\ae}s, Kasper and Gr{\"u}nberger, Olga},
	year         = 2006,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Montr{\'e}al, Qu{\'e}bec, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '06},
	pages        = {909--912},
	institution  = {ACM},
	keywords     = {presence-in-absence, asynchronous, intimacy;litsurvey.bib}
}

@inproceedings{Hu1986,
	title        = {{Shape from light stripe texture}},
	author       = {Hu, G and Jain, A K and Stockman, G},
	year         = 1986,
	booktitle    = {{IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR} '86)},
	address      = {Miami},
	pages        = {412--414},
	keywords     = {litsurvey.bib}
}

@article{Hua2004,
	title        = {Scape: supporting stereoscopic collaboration in augmented and projective environments},
	author       = {Hua, Hong and Brown, Leonard D and Gao, Chunyu},
	year         = 2004,
	month        = {\#jan\#},
	journal      = {IEEE Comput. Graph. Appl.},
	volume       = 24,
	number       = 1,
	pages        = {66--75},
	keywords     = {application program interfaces;augmented reality;data visualisation;groupware;stereo image processing;3D environment;API;Scape;application-programming interface;augmented reality;collaborative augmented reality system;multimodality interface device;multiple user;stereoscopic collaboration;virtual reality;widget interface;litsurvey.bib},
	language     = {en}
}

@inproceedings{Huang2003,
	title        = {Semi-public displays for small, co-located groups},
	author       = {Huang, Elaine M and Mynatt, Elizabeth D},
	year         = 2003,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Ft. Lauderdale, Florida, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '03},
	pages        = {49--56},
	institution  = {ACM},
	keywords     = {community, information visualization, awareness, ubiquitous computing, peripheral displays;litsurvey.bib}
}

@article{Hugot2007,
	title        = {Eye gaze analysis in human-human interactions},
	author       = {Hugot, Vanessa},
	year         = 2007,
	journal      = {Unpublished master{\^a}â‚¬{\v s}{\~A}â€ž{\~A}Â´s thesis, CSC, KTH, Sweden},
	publisher    = {Citeseer},
	keywords     = {litsurvey.bib}
}

@incollection{Ichikawa1995,
	title        = {{MAJIC} Videoconferencing System: Experiments, Evaluation and Improvement},
	author       = {Ichikawa, Yusuke and Okada, Ken-Ichi and Jeong, Giseok and Tanaka, Shunsuke and Matsushita, Yutaka},
	year         = 1995,
	booktitle    = {Proceedings of the Fourth European Conference on {Computer-Supported} Cooperative Work {ECSCW} '95: 10--14 September, 1995, Stockholm, Sweden},
	publisher    = {Springer Netherlands},
	address      = {Dordrecht},
	pages        = {279--292},
	editor       = {Marmolin, Hans and Sundblad, Yngve and Schmidt, Kjeld},
	abstract     = {We need to know the real intentions of participants that are not expressed by verbal languages. This means that not only verbal information but also non-verbal information (i.e., gestures, facial expression, eyes of participant, etc.) is a very important factor. We proposed and implemented MAJIC, a multi-party videoconferencing system that enables eye contact among people in remote places, with life-sized images of participants.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Ichikawa1995,
	title        = {{MAJIC} videoconferencing system: experiments, evaluation and improvement},
	author       = {Ichikawa, Yusuke and Okada, Ken-Ichi and Jeong, Giseok and Tanaka, Shunsuke and Matsushita, Yutaka},
	year         = 1995,
	booktitle    = {Proceedings of the Fourth European Conference on {Computer-Supported} Cooperative Work {ECSCW{\^a}â‚¬â„¢95}},
	pages        = {279--292},
	institution  = {Springer},
	keywords     = {litsurvey.bib}
}

@article{ijiri1986framework,
	title        = {A framework for triple-entry bookkeeping},
	author       = {Ijiri, Yuji},
	year         = 1986,
	journal      = {Accounting Review},
	publisher    = {JSTOR},
	pages        = {745--759}
}

@inproceedings{Inami2000,
	title        = {Visuo-haptic display using head-mounted projector},
	author       = {Inami, Masahiko and Kawakami, Naoki and Sekiguchi, Dairoku and Yanagida, Yasuyuki and Maeda, Taro and Tachi, Susumu},
	year         = 2000,
	booktitle    = {Virtual Reality, 2000. Proceedings. {IEEE}},
	pages        = {233--240},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Isaacs1997,
	title        = {Studying video-based collaboration in context: From small workgroups to large organizations},
	author       = {Isaacs, Ellen A and Tang, John C},
	year         = 1997,
	journal      = {Video-mediated communication},
	publisher    = {New Jersey: Lawrence Erlbaum},
	pages        = {173--197},
	keywords     = {litsurvey.bib}
}

@inproceedings{Ishii1992,
	title        = {{{ClearBoard}: a seamless medium for shared drawing and conversation with eye contact}},
	author       = {Ishii, Hiroshi and Kobayashi, Minoru},
	year         = 1992,
	month        = {\#jun\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Monterey, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '92},
	pages        = {525--532},
	keywords     = {litsurvey.bib}
}

@unpublished{Ishii1993,
	title        = {Integration of interpersonal space and shared workspace: {ClearBoard} design and experiments},
	author       = {Ishii, Hiroshi and Kobayashi, Minoru and Grudin, Jonathan},
	year         = 1993,
	month        = {\#oct\#},
	keywords     = {gaze awareness, groupware, gaze direction, seamless design, shared drawing, eye contact, video conference;litsurvey.bib}
}

@inproceedings{Itoh2005,
	title        = {Development of face robot to express the individual face by optimizing the facial features},
	author       = {Itoh, Kazuko and Miwa, Hiroyasu and Onishi, Yoshitaka and Imanishi, Kazutaka and Hayashi, Kouki and Takanishi, Atsuo},
	year         = 2005,
	booktitle    = {Humanoid Robots, International Conference on},
	pages        = {412--417},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Iverson2005,
	title        = {Gesture paves the way for language development},
	author       = {Iverson, Jana M and Goldin-Meadow, Susan},
	year         = 2005,
	month        = {\#may\#},
	journal      = {Psychol. Sci.},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 16,
	number       = 5,
	pages        = {367--371},
	abstract     = {In development, children often use gesture to communicate before they use words. The question is whether these gestures merely precede language development or are fundamentally tied to it. We examined 10 children making the transition from single words to two-word combinations and found that gesture had a tight relation to the children's lexical and syntactic development. First, a great many of the lexical items that each child produced initially in gesture later moved to that child's verbal lexicon. Second, children who were first to produce gesture-plus-word combinations conveying two elements in a proposition (point at bird and say ``nap'') were also first to produce two-word combinations (``bird nap''). Changes in gesture thus not only predate but also predict changes in language, suggesting that early gesture may be paving the way for future developments in language.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@book{Jacko2007,
	title        = {{Human-Computer} Interaction. Interaction Design and Usability: 12th International Conference, {HCI} International 2007, Beijing, China, July 22-27, 2007, Proceedings, Part {I}},
	author       = {Jacko, Julie A},
	year         = 2007,
	month        = {\#jul\#},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 4550,
	pages        = {802--811},
	editor       = {Jacko, Julie A},
	abstract     = {The 12th International Conference on Human-Computer Interaction, HCI Inter- tional 2007, was held in Beijing, P.R. China, 22-27 July 2007, jointly with the S- posium on Human Interface (Japan) 2007, the 7th International Conference on Engineering Psychology and Cognitive Ergonomics, the 4th International Conference on Universal Access in Human-Computer Interaction, the 2nd International Conf- ence on Virtual Reality, the 2nd International Conference on Usability and Inter- tionalization, the 2nd International Conference on Online Communities and Social Computing, the 3rd International Conference on Augmented Cognition, and the 1st International Conference on Digital Human Modeling. A total of 3403 individuals from academia, research institutes, industry and g- ernmental agencies from 76 countries submitted contributions, and 1681 papers, judged to be of high scientific quality, were included in the program. These papers address the latest research and development efforts and highlight the human aspects of design and use of computing systems. The papers accepted for presentation th- oughly cover the entire field of Human-Computer Interaction, addressing major - vances in knowledge and effective use of computers in a variety of application areas. This volume, edited by Julie A. Jacko, contains papers in the thematic area of Human-Computer Interaction, addressing the following major topics: â€¢ Interaction Design: Theoretical Issues, Methods, Techniques and Practice â€¢ Usability and Evaluation Methods and Tools â€¢ Understanding Users and Contexts of Use â€¢ Models and Patterns in HCI},
	keywords     = {Computer Science;litsurvey.bib},
	language     = {en}
}

@inproceedings{Jacob2008,
	title        = {Reality-based interaction: a framework for {post-WIMP} interfaces},
	author       = {Jacob, Robert J K and Girouard, Audrey and Hirshfield, Leanne M and Horn, Michael S and Shaer, Orit and Solovey, Erin Treacy and Zigelbaum, Jamie},
	year         = 2008,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Florence, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '08},
	pages        = {201--210},
	institution  = {ACM},
	keywords     = {multimodal, interaction styles, reality-based interaction, next-generation, virtual reality, tangible interfaces, context-aware, post-wimp interfaces, ubiquitous computing;litsurvey.bib}
}

@inproceedings{Jamil2011,
	title        = {The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables},
	author       = {Jamil, Izdihar and O'Hara, Kenton and Perry, Mark and Karnik, Abhijit and Subramanian, Sriram},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {3043--3052},
	institution  = {ACM},
	keywords     = {communication, interaction techniques, children, collaborative learning, tabletop;litsurvey.bib}
}

@inproceedings{Jan2007,
	title        = {Dynamic movement and positioning of embodied agents in multiparty conversations},
	author       = {Jan, Du{\v s}an and Traum, David R},
	year         = 2007,
	month        = {\#jun\#},
	booktitle    = {Proceedings of the Workshop on Embodied Language Processing},
	location     = {Prague, Czech Republic},
	publisher    = {Association for Computational Linguistics},
	address      = {USA},
	series       = {EmbodiedNLP '07},
	pages        = {59--66},
	institution  = {Association for Computational Linguistics},
	keywords     = {litsurvey.bib}
}

@article{Jarvenpaa1988,
	title        = {Computer Support for Meetings of Groups Working on Unstructured Problems: A Field Experiment},
	author       = {Jarvenpaa, Sirkka L and Rao, V Srinivasan and Huber, George P},
	year         = 1988,
	journal      = {Miss. Q.},
	publisher    = {Management Information Systems Research Center, University of Minnesota},
	volume       = 12,
	number       = 4,
	pages        = {645--666},
	abstract     = {[This preliminary study was conducted to learn about the consequences of computer support for teams working on unstructured, high-level conceptual software design problems in face-to-face group settings. A networked workstation technology and electronic blackboard technology were contrasted with their conventional counterparts. Twenty-one software designers, assigned to three teams, performed team tasks that involved generating ideas and reaching consensus. Positive effects on the thoroughness of information exchange and quality of team performance were found in the meetings in which electronic blackboard technology was available. The networked workstations provided mixed results. Significant team differences were found in performance and interaction measures. The results and their implications are discussed in terms of the necessary future developments and nature of future research in computer-based meeting support technology.]},
	keywords     = {litsurvey.bib}
}

@inproceedings{Jetter2011,
	title        = {Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops},
	author       = {Jetter, Hans-Christian and Gerken, Jens and Z{\"o}llner, Michael and Reiterer, Harald and Milic-Frayling, Natasa},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {3013--3022},
	institution  = {ACM},
	keywords     = {collaborative search, tangible user interfaces, tabletop;litsurvey.bib}
}

@article{Jin2015,
	title        = {Significance and challenges of big data research},
	author       = {Jin, Xiaolong and Wah, Benjamin W and Cheng, Xueqi and Wang, Yuanzhuo},
	year         = 2015,
	journal      = {Big Data Research},
	publisher    = {Elsevier},
	volume       = 2,
	number       = 2,
	pages        = {59--64},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S2214579615000076-main.pdf:PDF}
}

@article{Johnson1998,
	title        = {What's in a representation, why do we care, and what does it mean? Examining evidence from psychology},
	author       = {Johnson, Scott},
	year         = 1998,
	month        = {\#nov\#},
	journal      = {Autom. Constr.},
	publisher    = {Elsevier},
	volume       = 8,
	number       = 1,
	pages        = {15--24},
	abstract     = {This paper examines psychological evidence on the nature and role of representations in cognition. Both internal (mental) and external (physical or digital) representations are considered. It is discovered that both types of representation are deeply linked to thought processes. They are linked to learning, the ability to use existing knowledge, and problem solving strategies. The links between representations, thought processes, and behavior are so deep that even eye movements are partly governed by representations. Choice of representations can affect limited cognitive resources like attention and short-term memory by forcing a person to try to utilize poorly organized information or perform `translations' from one representation to another. The implications of this evidence are discussed. Based on these findings, a set of guidelines are presented, for digital representations which minimize drain of cognitive resources. These guidelines describe what sorts of characteristics and behaviors a representation should exhibit, and what sorts of information it should contain in order to accommodate and facilitate design. Current attempts to implement such representations are discussed.},
	keywords     = {Representation in cognition; Learning; Thought process;litsurvey.bib}
}

@inproceedings{Jones2009,
	title        = {{HeadSPIN}: a one-to-many {3D} video teleconferencing system},
	author       = {Jones, Andrew and Lang, Magnus and Fyffe, Graham and Yu, Xueming and Busch, Jay and McDowall, Ian and Bolas, Mark and Debevec, Paul},
	year         = 2009,
	month        = {\#aug\#},
	booktitle    = {{ACM} {SIGGRAPH} 2009 Emerging Technologies},
	location     = {New Orleans, Louisiana},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGGRAPH '09},
	number       = {Article 13},
	pages        = 1,
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@inproceedings{Jones2009,
	title        = {{Achieving eye contact in a one-to-many {3D} video teleconferencing system}},
	author       = {Jones, Andrew and Lang, Magnus and Fyffe, Graham and Yu, Xueming and Busch, Jay and McDowall, Ian and Bolas, Mark and Debevec, Paul},
	year         = 2009,
	month        = {\#jul\#},
	booktitle    = {{ACM} {SIGGRAPH} 2009 papers},
	location     = {New Orleans, Louisiana},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGGRAPH '09},
	volume       = 28,
	number       = {Article 64},
	pages        = {1--8},
	keywords     = {litsurvey.bib}
}

@inproceedings{Jones2014,
	title        = {{RoomAlive}: magical experiences enabled by scalable, adaptive projector-camera units},
	author       = {Jones, Brett and Sodhi, Rajinder and Murdock, Michael and Mehra, Ravish and Benko, Hrvoje and Wilson, Andrew and Ofek, Eyal and MacIntyre, Blair and Raghuvanshi, Nikunj and Shapira, Lior},
	year         = 2014,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 27th annual {ACM} symposium on User interface software and technology},
	location     = {Honolulu, Hawaii, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '14},
	pages        = {637--644},
	institution  = {ACM},
	keywords     = {spatial augmented reality, projection mapping, projector-camera system;litsurvey.bib}
}

@inproceedings{Jones1971,
	title        = {The Actor And The Observer: Divergent Perceptions Of The Causes Of Behavior},
	author       = {Jones, Edward Ellsworth and Nisbett, Richard E},
	year         = 1971,
	publisher    = {General Learning Press Morristown, NJ},
	keywords     = {litsurvey.bib}
}

@article{jones2008trust,
	title        = {Trust in consumer-to-consumer electronic commerce},
	author       = {Jones, Kiku and Leonard, Lori NK},
	year         = 2008,
	journal      = {Information \& management},
	publisher    = {Elsevier},
	volume       = 45,
	number       = 2,
	pages        = {88--95}
}

@inproceedings{Jouppi2004,
	title        = {Bireality: mutually-immersive telepresence},
	author       = {Jouppi, Norman P and Iyer, Subu and Thomas, Stan and Slayden, April},
	year         = 2004,
	booktitle    = {Proceedings of the 12th annual ACM international conference on Multimedia},
	pages        = {860--867}
}

@inproceedings{Jouppi2002,
	title        = {Mutually-immersive audio telepresence},
	author       = {Jouppi, Norman P and Pan, Michael J},
	year         = 2002,
	booktitle    = {Audio Engineering Society Convention 113},
	institution  = {Audio Engineering Society},
	keywords     = {litsurvey.bib}
}

@inproceedings{Judge2010,
	title        = {Sharing conversation and sharing life: video conferencing in the home},
	author       = {Judge, Tejinder K and Neustaedter, Carman},
	year         = 2010,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Atlanta, Georgia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '10},
	pages        = {655--658},
	institution  = {ACM},
	keywords     = {families, media spaces, domestic, video conferencing;litsurvey.bib}
}

@inproceedings{Junuzovic2012,
	title        = {To see or not to see: a study comparing four-way avatar, video, and audio conferencing for work},
	author       = {Junuzovic, Sasa and Inkpen, Kori and Tang, John and Sedlins, Mara and Fisher, Kristie},
	year         = 2012,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 17th {ACM} international conference on Supporting group work},
	location     = {Sanibel Island, Florida, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {GROUP '12},
	pages        = {31--34},
	institution  = {ACM},
	keywords     = {video, audio, conferencing, distributed teams, avatar;litsurvey.bib}
}

@book{Kalawsky2004,
	title        = {{Science of Virtual Reality and Virtual Environments}},
	author       = {Kalawsky, Roy S},
	year         = 2004,
	publisher    = {Addison Wesley Longman Publishing Co., Inc},
	keywords     = {litsurvey.bib}
}

@inproceedings{Kang2008,
	title        = {Social copresence in anonymous social interactions using a mobile video telephone},
	author       = {Kang, Sin-Hwa and Watt, James H and Ala, Sasi Kanth},
	year         = 2008,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Florence, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '08},
	pages        = {1535--1544},
	institution  = {ACM},
	keywords     = {social copresence, avatar realism, affective behavior, social presence, mobile phone communication, anonymity;litsurvey.bib}
}

@inproceedings{Karahalios2004,
	title        = {Telemurals: linking remote spaces with social catalysts},
	author       = {Karahalios, Karrie and Donath, Judith},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {615--622},
	institution  = {ACM},
	keywords     = {mediated spaces, video, mediated communication, social catalyst, remote connections, telepresence, ethnography, social interaction;litsurvey.bib}
}

@inproceedings{Kashagiri2007,
	title        = {Aiduti in Japanese multi-party design conversations},
	author       = {Kashagiri, Yasuhero},
	year         = 2007,
	keywords     = {litsurvey.bib}
}

@inproceedings{Kauff2002,
	title        = {An immersive {3D} video-conferencing system using shared virtual team user environments},
	author       = {Kauff, Peter and Schreer, Oliver},
	year         = 2002,
	month        = {\#sep\#},
	booktitle    = {Proceedings of the 4th international conference on Collaborative virtual environments},
	location     = {Bonn, Germany},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CVE '02},
	pages        = {105--112},
	institution  = {ACM},
	keywords     = {presence research, image based rendering, disparity estimation, MPEG-4 video coding, shared virtual table environment, tele-cubicles, next generation video conference, tele-immersion, arbitrarily shaped video objects, 3D video processing;litsurvey.bib}
}

@inproceedings{Kauff2002a,
	title        = {Virtual team user environments-a step from tele-cubicles towards distributed tele-collaboration in mediated workspaces},
	author       = {Kauff, Peter and Schreer, Oliver},
	year         = 2002,
	booktitle    = {Multimedia and Expo, 2002. {ICME'02}. Proceedings. 2002 {IEEE} International Conference on},
	volume       = 2,
	pages        = {9--12},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{Kendon1967,
	title        = {{Some functions of gaze-direction in social interaction.}},
	author       = {Kendon, A},
	year         = 1967,
	journal      = {Acta Psychol.},
	publisher    = {Elsevier BV, Radarweg 29, Amsterdam, 1043 NX, Netherlands,},
	volume       = 26,
	number       = 1,
	pages        = {22--63},
	abstract     = {Films of two-person conversations were transcribed and analyzed from the point of view of how gaze direction is related to utterance and silence. It was found that patterns of looking were systematically related to features of talk and could be accounted for in terms of the monitoring functions of gaze. At the same time, evidence was presented that suggested that gaze direction may also play a role in the regulation of turn-taking in conversation.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Kim2012,
	title        = {{TeleHuman}: effects of 3d perspective on gaze and pose estimation with a life-size cylindrical telepresence pod},
	author       = {Kim, Kibum and Bolton, John and Girouard, Audrey and Cooperstock, Jeremy and Vertegaal, Roel},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {2531--2540},
	institution  = {ACM},
	keywords     = {motion parallax, cylindrical display, videoconference, organic user interfaces, 3d video, telepresence;litsurvey.bib}
}

@article{Kim2015,
	title        = {Development of a Moon Exploring Simulator},
	author       = {Kim, Seong-Pil and Kwon, Ohung},
	year         = 2015,
	journal      = {í•œêµ­ì½˜ ?ì¸ í•™íšŒ ICCC ë…¼ë¬¸ì§‘},
	pages        = {51--52},
	keywords     = {litsurvey.bib}
}

@article{Kleinke1986,
	title        = {Gaze and eye contact: a research review},
	author       = {Kleinke, C L},
	year         = 1986,
	month        = {\#jul\#},
	journal      = {Psychol. Bull.},
	publisher    = {American Psychological Association},
	volume       = 100,
	number       = 1,
	pages        = {78--100},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Kleinsmith2013,
	title        = {Affective Body Expression Perception and Recognition: A Survey},
	author       = {Kleinsmith, A and Bianchi-Berthouze, N},
	year         = 2013,
	month        = {\#jan\#},
	journal      = {IEEE Transactions on Affective Computing},
	publisher    = {IEEE},
	volume       = 4,
	number       = 1,
	pages        = {15--33},
	abstract     = {Thanks to the decreasing cost of whole-body sensing technology and its increasing reliability, there is an increasing interest in, and understanding of, the role played by body expressions as a powerful affective communication channel. The aim of this survey is to review the literature on affective body expression perception and recognition. One issue is whether there are universal aspects to affect expression perception and recognition models or if they are affected by human factors such as culture. Next, we discuss the difference between form and movement information as studies have shown that they are governed by separate pathways in the brain. We also review psychological studies that have investigated bodily configurations to evaluate if specific features can be identified that contribute to the recognition of specific affective states. The survey then turns to automatic affect recognition systems using body expressions as at least one input modality. The survey ends by raising open questions on data collecting, labeling, modeling, and setting benchmarks for comparing automatic recognition systems.},
	keywords     = {pattern recognition;affective body expression perception;affective body expression recognition;whole-body sensing technology;affective communication channel;human factor;form information;movement information;input modality;data collection;data labeling;data modeling;automatic recognition system;Face recognition;Emotion recognition;Data models;Cultural differences;Face recognition;Emotion recognition;Data models;Cultural differences;spatiotemporal affective body features;Affective body posture;affective body movement;affective recognition systems;cross-cultural differences;litsurvey.bib}
}

@inproceedings{Klie2006,
	title        = {Vipid-virtual 3d person models for intuitive dialog systems},
	author       = {Klie, Patrick and B{\"u}schenfeld, Torsten and Ostermann, J{\"o}rn},
	year         = 2006,
	booktitle    = {{IEEE} Workshop on Content Generation and Coding for 3D-television},
	volume       = 1,
	keywords     = {litsurvey.bib}
}

@article{Kluttz2009,
	title        = {The effect of head turn on the perception of gaze},
	author       = {Kluttz, Nathan L and Mayes, Brandon R and West, Roger W and Kerby, Dave S},
	year         = 2009,
	month        = {\#jul\#},
	journal      = {Vision Res.},
	publisher    = {Elsevier Ltd},
	volume       = 49,
	number       = 15,
	pages        = {1979--1993},
	abstract     = {When subjects viewed straight and turned eyes that were isolated singly or in pairs from a head that was straight or turned, they underestimated their true direction of gaze. They also underestimated the direction of head turn when both eyes were closed. However, the judged direction of gaze was improved when the eyes were layered against the heads. Judged direction of averted gaze was primarily based on the abducting eye. The effect that the deviation between an eye's optical axis and its true direction of gaze (angle kappa) has on its judged direction of gaze is discussed.},
	keywords     = {Adult, Attention, Cues, Eye Movements, Female, Head Movements, Humans, Male, Models, Psychological, Optical Illusions, Psychophysics, Visual Perception, Visual Perception: physiology, Young Adult;litsurvey.bib},
	language     = {en}
}

@inproceedings{Knoblauch2008,
	title        = {{VirtualizeMe}: interactive model reconstruction from stereo video streams},
	author       = {Knoblauch, Daniel and Kuester, Falko},
	year         = 2008,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 2008 {ACM} symposium on Virtual reality software and technology},
	location     = {Bordeaux, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {VRST '08},
	pages        = {193--196},
	institution  = {ACM},
	keywords     = {point cloud streaming, background extraction, tele-immersion, disparity maps, 3D from video;litsurvey.bib}
}

@article{Kollock1998,
	title        = {Social Dilemmas: The Anatomy of Cooperation},
	author       = {Kollock, Peter},
	year         = 1998,
	month        = {\#aug\#},
	journal      = {Annu. Rev. Sociol.},
	publisher    = {Annual Reviews},
	volume       = 24,
	number       = 1,
	pages        = {183--214},
	abstract     = {The study of social dilemmas is the study of the tension between individual and collective rationality. In a social dilemma, individually reasonable behavior leads to a situation in which everyone is worse off. The first part of this review is a discussion of categories of social dilemmas and how they are modeled. The key two-person social dilemmas (Prisoner's Dilemma, Assurance, Chicken) and multiple-person social dilemmas (public goods dilemmas and commons dilemmas) are examined. The second part is an extended treatment of possible solutions for social dilemmas. These solutions are organized into three broad categories based on whether the solutions assume egoistic actors and whether the structure of the situation can be changed: Motivational solutions assume actors are not completely egoistic and so give some weight to the outcomes of their partners. Strategic solutions assume egoistic actors, and neither of these categories of solutions involve changing the fundamental structure of the situation. Solutions that do involve changing the rules of the game are considered in the section on structural solutions. I conclude the review with a discussion of current research and directions for future work.},
	keywords     = {litsurvey.bib}
}

@article{Kouvril2018,
	title        = {Labels on levels: labeling of multi-scale multi-instance and crowded 3D biological environments},
	author       = {Kou{\v{r}}il, David and {\v{C}}mol{\'\i}k, Ladislav and Kozl{\'\i}kov{\'a}, Barbora and Wu, Hslanc-Yun and Johnson, Graham and Goodsell, David S and Olson, Arthur and Gr{\"o}ller, M Eduard and Viola, Ivan},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {977--986},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440077.pdf:PDF}
}

@incollection{Krauss1996,
	title        = {Nonverbal Behavior and Nonverbal Communication: What do Conversational Hand Gestures Tell Us?},
	author       = {Krauss, Robert M and Chen, Yihsiu and Chawla, Purnima},
	year         = 1996,
	month        = {\#jan\#},
	booktitle    = {Advances in Experimental Social Psychology},
	publisher    = {Academic Press},
	volume       = 28,
	pages        = {389--450},
	editor       = {Zanna, Mark P},
	abstract     = {Publisher Summary This chapter explores how gestures contribute to comprehension, how gesturing affect speech and what can be learned from studying conversational gestures. The primary function of conversational hand gestures is to aid in the formulation of speech. Gestures can convey nonsemantic information. The study of speech and gestures overlaps with the study of person perception and attribution processes. The significance of gestures can be ambiguous and will affect the meanings and consequences to the observed gestures. A topology of gestures is adopters, symbolic gestures, and conversational gestures. Different types of conversational gestures can be distinguished as---namely, motor movements and lexical movements. Conversational hand gestures have been assumed to convey semantic information. Several studies that attempt to assess the kinds of information conversational gestures convey to naive observers and the extent to which gestures enhance the communicativeness of spoken messages are described in the chapter.},
	keywords     = {litsurvey.bib}
}

@article{Kristoffersson2013,
	title        = {A Review of Mobile Robotic Telepresence},
	author       = {Kristoffersson, Annica and Coradeschi, Silvia and Loutfi, Amy},
	year         = 2013,
	month        = {\#apr\#},
	journal      = {Advances in Human-Computer Interaction},
	publisher    = {Hindawi},
	volume       = 2013,
	pages        = 3,
	abstract     = {Mobile robotic telepresence (MRP) systems incorporate video conferencing equipment onto mobile robot devices which can be steered from remote locations. These systems, which are primarily used in the context of promoting social interaction between people, are becoming increasingly popular within certain application domains such as health care environments, independent living for the elderly, and office environments. In this paper, an overview of the various systems, application areas, and challenges found in the literature concerning mobile robotic telepresence is provided. The survey also proposes a set terminology for the field as there is currently a lack of standard terms for the different concepts related to MRP systems. Further, this paper provides an outlook on the various research directions for developing and enhancing mobile robotic telepresence systems per se, as well as evaluating the interaction in laboratory and field settings. Finally, the survey outlines a number of design implications for the future of mobile robotic telepresence systems for social interaction.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@incollection{Kristoffersson2011,
	title        = {Sense of Presence in a Robotic Telepresence Domain: 6th International Conference, {UAHCI} 2011, Held as Part of {HCI} International 2011, Orlando, {FL}, {USA}, July 9-14, 2011, Proceedings, Part {II}},
	author       = {Kristoffersson, Annica and Coradeschi, Silvia and Severinson Eklundh, Kerstin and Loutfi, Amy},
	year         = 2011,
	booktitle    = {Universal Access in {Human-Computer} Interaction. Users Diversity},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 6766,
	pages        = {479--487},
	editor       = {Stephanidis, Constantine},
	keywords     = {litsurvey.bib}
}

@article{Krum2012,
	title        = {Augmented reality using personal projection and retroreflection},
	author       = {Krum, David M and Suma, Evan A and Bolas, Mark},
	year         = 2012,
	journal      = {Pers. Ubiquit. Comput.},
	publisher    = {Springer},
	volume       = 16,
	number       = 1,
	pages        = {17--26},
	keywords     = {litsurvey.bib}
}

@article{Kubota2007,
	title        = {Multiview Imaging and {3DTV}},
	author       = {Kubota, A and Smolic, A and Magnor, M and Tanimoto, M and Chen, T and Zhang, C},
	year         = 2007,
	month        = {\#nov\#},
	journal      = {IEEE Signal Process. Mag.},
	volume       = 24,
	number       = 6,
	pages        = {10--21},
	abstract     = {The eight articles in this special section are devoted to multi-view imaging and three dimensional television displays.},
	keywords     = {Cameras;Layout;Rendering (computer graphics);Image coding;Displays;Costs;TV;Application software;Stereo vision;Navigation;litsurvey.bib}
}

@inproceedings{Kulik2011,
	title        = {C1x6: a stereoscopic six-user display for co-located collaboration in shared virtual environments},
	author       = {Kulik, Alexander and Kunert, Andr{\'e} and Beck, Stephan and Reichel, Roman and Blach, Roland and Zink, Armin and Froehlich, Bernd},
	year         = 2011,
	month        = {\#dec\#},
	booktitle    = {Proceedings of the 2011 {SIGGRAPH} Asia Conference},
	location     = {Hong Kong, China},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SA '11},
	volume       = 30,
	number       = {Article 188},
	pages        = {1--12},
	keywords     = {display technology, virtual reality, collaboration;litsurvey.bib}
}

@inproceedings{Kum2003,
	title        = {Real-time compression for dynamic {3D} environments},
	author       = {Kum, Sang-Uok and Mayer-Patel, Ketan and Fuchs, Henry},
	year         = 2003,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the eleventh {ACM} international conference on Multimedia},
	location     = {Berkeley, CA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {MULTIMEDIA '03},
	pages        = {185--194},
	institution  = {ACM},
	keywords     = {virtual reality, tele-immersion, K-Means algorithm, real-time compression, K-Means initialization;litsurvey.bib}
}

@inproceedings{Kurillo2008,
	title        = {{Immersive {3D} Environment for Remote Collaboration and Training of Physical Activities}},
	author       = {Kurillo, G and Bajcsy, R and Nahrsted, K and Kreylos, O},
	year         = 2008,
	month        = {\#mar\#},
	booktitle    = {2008 {IEEE} Virtual Reality Conference},
	address      = {Reno},
	pages        = {269--270},
	abstract     = {In this paper we present a framework for immersive virtual environment intended for remote collaboration and training of physical activities. Our multi-camera system performs full-body 3D reconstruction of human user(s) in real time and renders their image in the virtual space allowing remote users to interact. The paper features a short overview of the technology used for the capturing and reconstruction. Some of the applications where we have successfully demonstrated use of the system in combination with the tele-immersive virtual environment are described. Finally, we address current drawbacks with regard to data capturing and networking and provide some ideas for future work.},
	keywords     = {image reconstruction;stereo image processing;virtual reality;immersive 3D virtual environment;remote collaboration;physical activity training;multi-camera system;full-body 3D reconstruction;Collaboration;Image reconstruction;Cameras;Humans;Real time systems;Rendering (computer graphics);Space technology;Avatars;Virtual environment;Computer vision;3D reconstruction;immersion;real-time systems;remote collaboration;tele-immersion;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial, Augmented, and Virtual Realities;I.4.10 [Image Processing and Computer Vision]: Image Representation\?\`Volumetric;litsurvey.bib}
}

@unpublished{Kuster2012,
	title        = {{Gaze correction for home video conferencing}},
	author       = {Kuster, Claudia and Popa, Tiberiu and Bazin, Jean-Charles and Gotsman, Craig and Gross, Markus},
	year         = 2012,
	month        = {\#nov\#},
	number       = {Article 174},
	keywords     = {gaze correction, depth camera, video conferencing;litsurvey.bib}
}

@inproceedings{Kuster2012,
	title        = {Gaze Correction For Home Video Conferencing},
	author       = {Kuster, Claudia and Popa, Tiberiu and Bazin, Jean-Charles and Gotsman, Craig and Gross, Markus},
	year         = 2012,
	publisher    = {ACM},
	volume       = 31,
	pages        = 174,
	keywords     = {litsurvey.bib}
}

@inproceedings{Kuster2012,
	title        = {Towards next generation {3D} teleconferencing systems},
	author       = {Kuster, C and Ranieri, N and {Agustina} and Zimmer, H and Bazin, J C and Sun, C and Popa, T and Gross, M},
	year         = 2012,
	month        = {\#oct\#},
	booktitle    = {2012 {3DTV-Conference}: The True Vision - Capture, Transmission and Display of {3D} Video ({3DTV-CON})},
	pages        = {1--4},
	abstract     = {Teleconferencing is becoming more and more important and popular in today's society and is mostly accomplished using 2D video conferencing systems. However, we believe there is a lot of room for improving the communication experience: one crucial aspect is to add 3D information, but also freeing the user from sitting in front of a computer. With these improvements, we aim at eventually creating a fully immersive 3D telepresence system that might improve the way we communicate over long distances. In this paper we review and analyze existing technology to achieve this goal and present a proof-of-concept, but fully functional prototype.},
	institution  = {IEEE},
	keywords     = {teleconferencing;virtual reality;next generation 3D teleconferencing;fully immersive 3D telepresence system;3D display;3D acquisition;Three dimensional displays;Cameras;Prototypes;Teleconferencing;Bandwidth;Streaming media;Geometry;3D teleconferencing;3D display;3D acquisition;litsurvey.bib}
}

@inproceedings{Kyoung_Shin_Park1999,
	title        = {Effects of network characteristics on human performance in a collaborative virtual environment},
	author       = {{Kyoung Shin Park} and Kenyon, R V},
	year         = 1999,
	month        = {\#mar\#},
	booktitle    = {Proceedings {IEEE} Virtual Reality (Cat. No. {99CB36316})},
	pages        = {104--111},
	abstract     = {We assessed the effects of network latency and jitter on a cooperative teleoperation task in a collaborative virtual environment. Two remote partners worked together to manipulate shared virtual objects over a network. The task was to minimize the time to transfer a ring through one of four paths with the least number of collisions. The performance of human subjects was measured and analyzed quantitatively as a function of network latency: 10 and 200 msec delays with and without jitter. Jitter had the greatest impact on coordination performance when the latency was high and the task was difficult. These results are discussed in light of current and future CVE tasks.},
	institution  = {IEEE},
	keywords     = {jitter;virtual reality;local area networks;ISDN;quality of service;wide area networks;groupware;network characteristics;human performance;collaborative virtual environment;network latency;jitter;cooperative teleoperation task;shared virtual objects;Humans;Intelligent networks;Collaboration;Virtual environment;Delay;Jitter;Quality of service;Collaborative work;Optical design;Wide area networks;litsurvey.bib}
}

@inproceedings{Laber2018a,
	title        = {Binary partitions with approximate minimum impurity},
	author       = {Laber, Eduardo and Molinaro, Marco and Pereira, Felipe Mello},
	year         = 2018,
	booktitle    = {International Conference on Machine Learning},
	pages        = {2854--2862},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/laber18a.pdf:PDF}
}

@article{Laber2018,
	title        = {Splitting criteria for classification problems with multi-valued attributes and large number of classes},
	author       = {Laber, Eduardo Sany and Pereira, Felipe de A Mello},
	year         = 2018,
	journal      = {Pattern Recognition Letters},
	publisher    = {Elsevier},
	volume       = 111,
	pages        = {58--63},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/1-s2.0-S0167865518301338-main.pdf:PDF}
}

@inproceedings{Ladikos2008,
	title        = {{Efficient visual hull computation for real-time {3D} reconstruction using {CUDA}}},
	author       = {Ladikos, A and Benhimane, S and Navab, N},
	year         = 2008,
	month        = {\#jun\#},
	booktitle    = {2008 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	address      = {Anchorage},
	pages        = {1--8},
	abstract     = {In this paper we present two efficient GPU-based visual hull computation algorithms. We compare them in terms of performance using image sets of varying size and different voxel resolutions. In addition, we present a real-time 3D reconstruction system which uses the proposed GPU-based reconstruction method to achieve real-time performance (30 fps) using 16 cameras and 4 PCs.},
	keywords     = {computational geometry;image reconstruction;image resolution;visual hull computation;real-time 3D reconstruction;CUDA;GPU;image sets;voxel resolutions;real-time performance;Image reconstruction;Cameras;Real time systems;Reconstruction algorithms;Personal communication networks;Shape;Hardware;Image segmentation;Distributed computing;Computer science;litsurvey.bib}
}

@article{Lamboray2005,
	title        = {Data streaming in telepresence environments},
	author       = {Lamboray, Edouard and W{\"u}rmlin, Stephan and Gross, Markus},
	year         = 2005,
	month        = {\#nov\#},
	journal      = {IEEE Trans. Vis. Comput. Graph.},
	publisher    = {IEEE},
	volume       = 11,
	number       = 6,
	pages        = {637--648},
	abstract     = {In this paper, we discuss data transmission in telepresence environments for collaborative virtual reality applications. We analyze data streams in the context of networked virtual environments and classify them according to their traffic characteristics. Special emphasis is put on geometry-enhanced (3D) video. We review architectures for real-time 3D video pipelines and derive theoretical bounds on the minimal system latency as a function of the transmission and processing delays. Furthermore, we discuss bandwidth issues of differential update coding for 3D video. In our telepresence system-the blue-c-we use a point-based 3D video technology which allows for differentially encoded 3D representations of human users. While we discuss the considerations which lead to the design of our three-stage 3D video pipeline, we also elucidate some critical implementation details regarding decoupling of acquisition, processing and rendering frame rates, and audio/video synchronization. Finally, we demonstrate the communication and networking features of the blue-c system in its full deployment. We show how the system can possibly be controlled to face processing or networking bottlenecks by adapting the multiple system components like audio, application data, and 3D video.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Lamping1996,
	title        = {The hyperbolic browser: A focus+ context technique for visualizing large hierarchies},
	author       = {Lamping, Jonh and Rao, Ramana},
	year         = 1996,
	journal      = {Journal of Visual Languages \& Computing},
	publisher    = {Elsevier},
	volume       = 7,
	number       = 1,
	pages        = {33--55},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/The Hyperbolic Browser A  Focus 1 Context Tech.pdf:PDF}
}

@article{Lamport1983,
	title        = {The weak Byzantine generals problem},
	author       = {Lamport, Leslie},
	year         = 1983,
	journal      = {Journal of the ACM (JACM)},
	publisher    = {ACM New York, NY, USA},
	volume       = 30,
	number       = 3,
	pages        = {668--676},
	file         = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\bitcoin\\byz.pdf:PDF}
}

@article{Langton2000,
	title        = {The mutual influence of gaze and head orientation in the analysis of social attention direction},
	author       = {Langton, S R},
	year         = 2000,
	month        = {\#aug\#},
	journal      = {Q. J. Exp. Psychol. A},
	publisher    = {Taylor \& Francis},
	volume       = 53,
	number       = 3,
	pages        = {825--845},
	abstract     = {Three experiments are reported that investigate the hypothesis that head orientation and gaze direction interact in the processing of another individual's direction of social attention. A Stroop-type interference paradigm was adopted, in which gaze and head cues were placed into conflict. In separate blocks of trials, participants were asked to make speeded keypress responses contingent on either the direction of gaze, or the orientation of the head displayed in a digitized photograph of a male face. In Experiments 1 and 2, head and gaze cues showed symmetrical interference effects. Compared with congruent arrangements, incongruent head cues slowed responses to gaze cues, and incongruent gaze cues slowed responses to head cues, suggesting that head and gaze are mutually influential in the analysis of social attention direction. This mutuality was also evident in a cross-modal version of the task (Experiment 3) where participants responded to spoken directional words whilst ignoring the head/gaze images. It is argued that these interference effects arise from the independent influences of gaze and head orientation on decisions concerning social attention direction.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Langton2000,
	title        = {Do the eyes have it? Cues to the direction of social attention},
	author       = {Langton, S R and Watt, R J and Bruce, I, I},
	year         = 2000,
	month        = {\#feb\#},
	journal      = {Trends Cogn. Sci.},
	publisher    = {Elsevier},
	volume       = 4,
	number       = 2,
	pages        = {50--59},
	abstract     = {The face communicates an impressive amount of visual information. We use it to identify its owner, how they are feeling and to help us understand what they are saying. Models of face processing have considered how we extract such meaning from the face but have ignored another important signal - eye gaze. In this article we begin by reviewing evidence from recent neurophysiological studies that suggests that the eyes constitute a special stimulus in at least two senses. First, the structure of the eyes is such that it provides us with a particularly powerful signal to the direction of another person's gaze, and second, we may have evolved neural mechanisms devoted to gaze processing. As a result, gaze direction is analysed rapidly and automatically, and is able to trigger reflexive shifts of an observer's visual attention. However, understanding where another individual is directing their attention involves more than simply analysing their gaze direction. We go on to describe research with adult participants, children and non-human primates that suggests that other cues such as head orientation and pointing gestures make significant contributions to the computation of another's direction of attention.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Langton2000,
	title        = {The Mutual Influence Of Gaze And Head Orientation In The Analysis Of Social Attention Direction},
	author       = {Langton, S R H},
	year         = 2000,
	pages        = {825--845},
	keywords     = {litsurvey.bib}
}

@inproceedings{Langton2000,
	title        = {Do The Eyes Have It? Cues To The Direction Of Social Attention},
	author       = {Langton, Stephen R H and Watt, Roger J and Bruce, Vicki},
	year         = 2000,
	volume       = 4,
	pages        = {50--59},
	abstract     = {The face communicates an impressive amount of visual information. We use it to identify its owner, how they are feeling and to help us understand what they are saying. Models of face processing have considered how we extract such meaning from the face but have ignored another important signal \textbackslashquotesinglbase{\"A}{\`\i} eye gaze. In this article we begin by reviewing evidence from recent neurophysiological studies that suggests that the eyes constitute a special stimulus in at least two senses. First, the structure of the eyes is such that it provides us with a particularly powerful signal to the direction of another person\textbackslashquotesinglbase{\"A}{\^o}s gaze, and second, we may have evolved neural mechanisms devoted to gaze processing. As a result, gaze direction is analysed rapidly and automatically, and is able to trigger reflexive shifts of an observer\textbackslashquotesinglbase{\"A}{\^o}s visual attention. However, understanding where another individual is directing their attention involves more than simply analysing their gaze direction. We go on to describe research with adult participants, children and non-human primates that suggests that other cues such as head orientation and pointing gestures make significant contributions to the computation of another\textbackslashquotesinglbase{\"A}{\^o}s direction of attention.},
	keywords     = {neuroscience;litsurvey.bib}
}

@unpublished{Lantz1997,
	title        = {Future directions in visual display systems},
	author       = {Lantz, Ed},
	year         = 1997,
	month        = {\#may\#},
	keywords     = {litsurvey.bib}
}

@article{Lau1998,
	title        = {Demographic Diversity and Faultlines: The Compositional Dynamics of Organizational Groups},
	author       = {Lau, Dora C and Murnighan, J Keith},
	year         = 1998,
	journal      = {Acad. Manage. Rev.},
	publisher    = {Academy of Management},
	volume       = 23,
	number       = 2,
	pages        = {325--340},
	abstract     = {In this article we address issues of diversity within organizational groups by discussing and summarizing previous approaches and by introducing a new variable-faultlines-which depends on the alignment of individual member characteristics. By analyzing a group's faultlines, we focus attention on the underlying patterns of group member characteristics, which can be an important determinant of subgroup conflict, particularly when the group's task is related to one of its faultlines. We discuss the dynamics of faultlines from the early to later stages of a group's development and show how they may be strongest and most likely when diversity of individual member characteristics is moderate.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Laurendeau1999,
	title        = {{The mapping of texture on {VR} polygonal models}},
	author       = {Laurendeau, Denis and Bertrand, Nathalie and Houde, R{\'e}gis},
	year         = 1999,
	booktitle    = {Proceedings of the 2\textbackslashtextsuperscript{nd} international conference on {3-D} digital imaging and modeling ({3DIM} '99)},
	publisher    = {IEEE Computer Society},
	address      = {Ottawa},
	keywords     = {litsurvey.bib}
}

@article{Laurentini1994,
	title        = {The visual hull concept for silhouette-based image understanding},
	author       = {Laurentini, A},
	year         = 1994,
	month        = {\#feb\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	publisher    = {IEEE},
	volume       = 16,
	number       = 2,
	pages        = {150--162},
	abstract     = {Many algorithms for both identifying and reconstructing a 3-D object are based on the 2-D silhouettes of the object. In general, identifying a nonconvex object using a silhouette-based approach implies neglecting some features of its surface as identification clues. The same features cannot be reconstructed by volume intersection techniques using multiple silhouettes of the object. This paper addresses the problem of finding which parts of a nonconvex object are relevant for silhouette-based image understanding. For this purpose, the geometric concept of visual hull of a 3-D object is introduced. This is the closest approximation of object S that can be obtained with the volume intersection approach; it is the maximal object silhouette-equivalent to S, i.e., which can be substituted for S without affecting any silhouette. Only the parts of the surface of S that also lie on the surface of the visual hull can be reconstructed or identified using silhouette-based algorithms. The visual hull depends not only on the object but also on the region allowed to the viewpoint. Two main viewing regions result in the external and internal visual hull. In the former case the viewing region is related to the convex hull of S, in the latter it is bounded by S. The internal visual hull also admits an interpretation not related to silhouettes. Algorithms for computing visual hulls are presented and their complexity analyzed. In general, the visual hull of a 3-D planar face object turns out to be bounded by planar and curved patches.},
	keywords     = {image reconstruction;silhouette-based image understanding;object identification;object reconstruction;nonconvex object;internal visual hull;external visual hull;Image reconstruction;Object recognition;Shape;Surface reconstruction;Computer vision;Algorithm design and analysis;Face detection;Image recognition;Layout;Navigation;litsurvey.bib}
}

@article{lavoie1990prefatory,
	title        = {Prefatory Note: The Origins of" The Agorics Project},
	author       = {Lavoie, Don},
	year         = 1990,
	journal      = {Market Process, v8, Spring},
	pages        = {116--119}
}

@inproceedings{Lazebnik2001,
	title        = {{On computing exact visual hulls of solids bounded by smooth surfaces}},
	author       = {Lazebnik, S and Boyer, E and Ponce, J},
	year         = 2001,
	booktitle    = {{IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR} '01)},
	address      = {Kauai},
	keywords     = {litsurvey.bib}
}

@article{Lazebnik2007,
	title        = {{Projective visual hulls}},
	author       = {Lazebnik, S and Furukawa, Y and Ponce, J},
	year         = 2007,
	journal      = {Int. J. Comput. Vis.},
	volume       = 74,
	number       = 2,
	pages        = {137--165},
	keywords     = {litsurvey.bib}
}

@article{Lee1985,
	title        = {{Determination of {3D} human body postures from a single view}},
	author       = {Lee, Hsi-Jian and Chen, Zen},
	year         = 1985,
	month        = {\#may\#},
	journal      = {Computer Vision, Graphics, and Image Processing},
	volume       = 30,
	number       = 2,
	pages        = {148--168},
	abstract     = {In this paper a method is proposed to recover and interpret the 3D body structures of a person from a single view, provided that (1) at least six feature points on the head and a set of body joints are available on the image plane, and (2) the geometry of head and lengths of body segments formed by joints are known. First of all, the feature points on the head in the head-centered coordinate system and their image projections are used to determine a transformation matrix. Then, the camera position and orientations are extracted from the matrix. Finally, the 3D coordinates of the head points expressed in the camera-centered coordinate system are obtained. Starting from the coordinates of the neck, which is a head feature point, the 3D coordinates of other joints one-by-one are determined under the assumption of the fixed lengths of the body segments. A binary interpretation tree is used to represent the 2n âˆ’ 1 possible body structures, if a human body has n joints. To determine the final feasible body structures, physical and motion constraints are used to prune the interpretation tree. Formulas and rules required for the tree pruning are formulated. Experiments are used to illustrate the pruning powers of these constraints. In the two cases of input data chosen, a unique or nearly unique solution of the body structure is obtained.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Lee2011,
	title        = {``Now, i have a body'': uses and social norms for mobile remote presence in the workplace},
	author       = {Lee, Min Kyung and Takayama, Leila},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {33--42},
	institution  = {ACM},
	keywords     = {computer supported collaborative work, human-robot interaction, mobile remote presence;litsurvey.bib}
}

@inproceedings{Lehment2014,
	title        = {Creating automatically aligned consensus realities for {AR} videoconferencing},
	author       = {Lehment, N H and Merget, D and Rigoll, G},
	year         = 2014,
	month        = {\#sep\#},
	booktitle    = {2014 {IEEE} International Symposium on Mixed and Augmented Reality ({ISMAR})},
	pages        = {201--206},
	abstract     = {This paper presents an AR videoconferencing approach merging two remote rooms into a shared workspace. Such bilateral AR telepresence inherently suffers from breaks in immersion stemming from the different physical layouts of participating spaces. As a remedy, we develop an automatic alignment scheme which ensures that participants share a maximum of common features in their physical surroundings. The system optimizes alignment with regard to initial user position, free shared floor space, camera positioning and other factors. Thus we can reduce discrepancies between different room and furniture layouts without actually modifying the rooms themselves. A description and discussion of our alignment scheme is given along with an exemplary implementation on real-world datasets.},
	institution  = {IEEE},
	keywords     = {augmented reality;teleconferencing;AR videoconferencing;augmented reality;bilateral AR telepresence;immersion stemming;automatic alignment scheme;user position;free shared floor space;camera positioning;Cameras;Three-dimensional displays;Avatars;Observability;Optimization;Teleconferencing;Computational modeling;H.4.3 [Information Systems Applications];Communications Applications --- Computer Conferencing;Teleconferencing;Videoconferencing;litsurvey.bib}
}

@inproceedings{Leshed2009,
	title        = {Visualizing real-time language-based feedback on teamwork behavior in computer-mediated groups},
	author       = {Leshed, Gilly and Perez, Diego and Hancock, Jeffrey T and Cosley, Dan and Birnholtz, Jeremy and Lee, Soyoung and McLeod, Poppy L and Gay, Geri},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {537--546},
	institution  = {ACM},
	keywords     = {peripheral displays, cmc, cscw, linguistic analysis, feedback visualization, teamwork;litsurvey.bib}
}

@inproceedings{Lessels2004,
	title        = {Changes in navigational behaviour produced by a wide field of view and a high fidelity visual scene},
	author       = {Lessels, S and Ruddle, R A},
	year         = 2004,
	booktitle    = {Proceedings of the 10\textbackslashtextsuperscript{th} Eurographics Symposium on Virtual Environments},
	pages        = {71--78},
	institution  = {Eurographics},
	keywords     = {litsurvey.bib}
}

@article{Lessiter2001,
	title        = {A {Cross-Media} Presence Questionnaire: The {ITC-Sense} of Presence Inventory},
	author       = {Lessiter, Jane and Freeman, Jonathan and Keogh, Edmund and Davidoff, Jules},
	year         = 2001,
	month        = {\#jun\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 10,
	number       = 3,
	pages        = {282--297},
	abstract     = {The presence research community would benefit from a reliable and valid cross-media presence measure that allows results from different laboratories to be compared and a more comprehensive knowledge base to be developed. The ITC-Sense of Presence Inventory (ITC-SOPI) is a new state questionnaire measure whose development has been informed by previous research on the determinants of presence and current self-report measures. It focuses on users' experiences of media, with no reference to objective system parameters. More than 600 people completed the ITC-SOPI following an experience with one of a range of noninteractive and interactive media. Exploratory analysis (principal axis factoring) revealed four factors: Sense of Physical Space, Engagement, Ecological Validity, and Negative Effects. Relations between the factors and the consistency of the factor structure with others reported in the literature are discussed. Preliminary analyses described here demonstrate that the ITC-SOPI is reliable and valid, but more rigorous testing of its psychometric properties and applicability to interactive virtual environments is required. Subject to satisfactory confirmatory analyses, the ITC-SOPI will offer researchers using a range of media systems a tool with which to measure four facets of a media experience that are putatively related to presence.},
	keywords     = {litsurvey.bib}
}

@article{Lessiter2000,
	title        = {{Development of a New {Cross-Media} Presence Questionnaire : The {ITC-Sense} of Presence Inventory}},
	author       = {Lessiter, Jane and Freeman, Jonathan and Keogh, Ed and Davidoff, Jules},
	year         = 2000,
	journal      = {3\textbackslashtextsuperscriptrd International Presence Workshop},
	number       = {ii},
	abstract     = {Summary l Previous studies have attempted to measure presence using simple post-test rating scales (e.g., Slater, Usoh \& Steed, 1994; Barfield \& Hendrix, 1996). l The stability of simple post-test ratings has been questioned (Freeman Avons, Pearson \& IJsselsteijn, 1999). l More detailed, carefully piloted and psychometrically-sound questionnaires offer a solution to potential instabilities in simple post-test ratings. This approach has been adopted by Schubert, Friedmann and Regenbrecht (1999), Witmer and Singer (1998), and Kim and Biocca (1997). l These attempts have limitations, such as restricted media applications. l We present research documenting the development of a new cross-media presence questionnaire - the ITC-Sense of Presence Inventory (ITC-SOPI). l Preliminary results indicate four components: Physical Space, Engagement, Naturalness and Negative Effects.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Lincoln2010,
	title        = {Multi-view lenticular display for group teleconferencing},
	author       = {Lincoln, Peter and Nashel, Andrew and Ilie, Adrian and Towles, Herman and Welch, Gregory and Fuchs, Henry},
	year         = 2010,
	month        = {\#may\#},
	booktitle    = {Proceedings of the 2nd International Conference on Immersive Telecommunications},
	publisher    = {ICST},
	pages        = 22,
	institution  = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
	keywords     = {litsurvey.bib}
}

@inproceedings{Lincoln2009,
	title        = {Animatronic Shader Lamps Avatars},
	author       = {Lincoln, P and Welch, G and Nashel, A and Ilie, A and State, A and Fuchs, H},
	year         = 2009,
	month        = {\#oct\#},
	booktitle    = {2009 8th {IEEE} International Symposium on Mixed and Augmented Reality},
	pages        = {27--33},
	abstract     = {Applications such as telepresence and training involve the display of real or synthetic humans to multiple viewers. When attempting to render the humans with conventional displays, non-verbal cues such as head pose, gaze direction, body posture, and facial expression are difficult to convey correctly to all viewers. In addition, a framed image of a human conveys only a limited physical sense of presence - primarily through the display's location. While progress continues on articulated robots that mimic humans, the focus has been on the motion and behavior of the robots. We introduce a new approach for robotic avatars of real people: the use of cameras and projectors to capture and map the dynamic motion and appearance of a real person onto a humanoid animatronic model. We call these devices Animatronic Shader Lamps Avatars (SLA).We present a proof-of-concept prototype comprised of a camera, a tracking system, a digital projector, and a life-sized styrofoam head mounted on a pan-tilt unit. The system captures imagery of a moving, talking user and maps the appearance and motion onto the animatronic SLA, delivering a dynamic, real-time representation of the user to multiple viewers.},
	institution  = {IEEE},
	keywords     = {avatars;computer vision;rendering (computer graphics);animatronic shader lamps avatars;articulated robots;robotic avatars;humanoid animatronic model;Animation;Lamps;Avatars;Humans;Displays;Robot sensing systems;Head;Robot vision systems;Cameras;Rendering (computer graphics);H.4.3 [Information Systems Applications]: Communications Applications;Computer conferencing, teleconferencing, and videoconferencing H.5.1 [Multimedia Information Systems]: Animations;Artificial, augmented, and virtual realities I.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism;Virtual Reality; I.3.8 [Computer Graphics]: Applications;litsurvey.bib}
}

@article{Lincoln2011,
	title        = {{Animatronic shader lamps avatars}},
	author       = {Lincoln, Peter and Welch, Greg and Nashel, Andrew and {State, Andrei} and Ilie, Adrian and Fuchs, Henry},
	year         = 2011,
	month        = {\#jun\#},
	journal      = {Virtual Real.},
	volume       = 15,
	number       = 2,
	pages        = {225--238},
	abstract     = {Applications such as telepresence and training involve the display of real or synthetic humans to multiple viewers. When attempting to render the humans with conventional displays, non-verbal cues such as head pose, gaze direction, body posture, and facial expression are difficult to convey correctly to all viewers. In addition, a framed image of a human conveys only a limited physical sense of presence---primarily through the display's location. While progress continues on articulated robots that mimic humans, the focus has been on the motion and behavior of the robots rather than on their appearance. We introduce a new approach for robotic avatars of real people: the use of cameras and projectors to capture and map both the dynamic motion and the appearance of a real person onto a humanoid animatronic model. We call these devices animatronic Shader Lamps Avatars (SLA). We present a proof-of-concept prototype comprised of a camera, a tracking system, a digital projector, and a life-sized styrofoam head mounted on a pan-tilt unit. The system captures imagery of a moving, talking user and maps the appearance and motion onto the animatronic SLA, delivering a dynamic, real-time representation of the user to multiple viewers.},
	keywords     = {litsurvey.bib}
}

@misc{Lister2020,
	title        = {Global Workplace Statistics},
	author       = {Lister, Kate},
	year         = 2020,
	howpublished = {\url{https://globalworkplaceanalytics.com/telecommuting-statistics}},
	keywords     = {litsurvey.bib}
}

@article{Liu2009,
	title        = {{Distributed volumetric scene geometry reconstruction with a network of distributed smart cameras}},
	author       = {Liu, Shubao and Kang, Kongbin and Tarel, J and Cooper, D},
	year         = 2009,
	journal      = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR '09)},
	pages        = {2334--2341},
	keywords     = {litsurvey.bib}
}

@article{Liu2007,
	title        = {{Shape from silhouette outlines using an adaptive dandelion model}},
	author       = {Liu, Xin and Yao, Hongxun and Gao, Wen},
	year         = 2007,
	month        = {\#feb\#},
	journal      = {Comput. Vis. Image Underst.},
	volume       = 105,
	number       = 2,
	pages        = {121--130},
	abstract     = {In this paper we study the problem of shape from silhouette outlines (SFO) using a novel adaptive dandelion model. SFO reconstructs a 3D model using only the outmost silhouette contours and produces a solid called the ``bounding hull''. The dandelion model is composed of a pencil of organized line segments emitted from a common point which samples the bounding hull surface in regularly distributed orientations with the ending points serving as sampling points. The orientations and the topology of the line segments are derived from a geodesic sphere. The lengths of the line segments are computed by cutting rays in 2D with silhouette outlines. Based on the subdivision structure of the geodesic sphere, the sampling resolution can be refined adaptively until the desired precision is achieved. Finally a manifold mesh is extracted from the dandelion model.},
	keywords     = {Shape from silhouette outlines; Bounding hull; Dandelion model;litsurvey.bib}
}

@article{Lohmann1998,
	title        = {BrainView: a computer program for reconstruction and interactive visualization of 3D data sets},
	author       = {Lohmann, Klaudia and Gundelfinger, Eckart D and Scheich, Henning and Grimm, Rita and Tischmeyer, Wolfgang and Richter, Karin and Hess, Andreas},
	year         = 1998,
	journal      = {Journal of neuroscience methods},
	publisher    = {Elsevier},
	volume       = 84,
	number       = {1-2},
	pages        = {143--154},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0165027098001034-main.pdf:PDF}
}

@article{Loomis2008,
	title        = {Psychophysics of perceiving eye-gaze and head direction with peripheral vision: implications for the dynamics of eye-gaze behavior},
	author       = {Loomis, Jack M and Kelly, Jonathan W and Pusch, Matthias and Bailenson, Jeremy N and Beall, Andrew C},
	year         = 2008,
	journal      = {Perception},
	publisher    = {SAGE Publications Sage UK: London, England},
	volume       = 37,
	number       = 9,
	pages        = {1443--1457},
	abstract     = {Two psychophysical experiments are reported, one dealing with the visual perception of the head orientation of another person (the 'looker') and the other dealing with the perception of the looker's direction of eye gaze. The participant viewed the looker with different retinal eccentricities, ranging from foveal to far-peripheral viewing. On average, judgments of head orientation were reliable even out to the extremes of peripheral vision (90 degrees eccentricity), with better performance at the extremes when the participant was able to view the looker changing head orientation from one trial to the next. In sharp contrast, judgments of eye-gaze direction were reliable only out to 4 degrees eccentricity, signifying that the eye-gaze social signal is available to people only when they fixate near the looker's eyes. While not unexpected, this vast difference in availability of information about head direction and eye direction, both of which can serve as indicators of the looker's focus of attention, is important for understanding the dynamics of eye-gaze behavior.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Loomis2008,
	title        = {Psychophysics Of Perceiving Eye-gaze And Head Direction With Peripheral {Vision:$\neg${\textbackslashdag}implications} For The Dynamics Of Eye-gaze Behavior},
	author       = {Loomis, Jack M and Kelly, Jonathan W and Pusch, Matthias and Bailenson, Jeremy N and Beall, Andrew C},
	year         = 2008,
	volume       = 37,
	pages        = {1443--1457},
	keywords     = {litsurvey.bib}
}

@incollection{Loomis2012,
	title        = {-Sensory Substitution of Vision: Importance of Perceptual and Cognitive Processing},
	author       = {Loomis, Jack M and Klatzky, Roberta L and Giudice, Nicholas A},
	year         = 2012,
	booktitle    = {Assistive technology for blindness and low vision},
	publisher    = {CRC Press},
	pages        = {179--210},
	keywords     = {litsurvey.bib}
}

@inproceedings{Lorensen1987,
	title        = {{Marching cubes: A high resolution {3D} surface construction algorithm}},
	author       = {Lorensen, W E and Cline, H E},
	year         = 1987,
	booktitle    = {Proceedings of the 14\textbackslashtextsuperscript{th} annual conference on Computer Graphics and Interactive Techniques ({SIGGRAPH} '87)},
	address      = {Anaheim},
	pages        = {163--169},
	keywords     = {litsurvey.bib}
}

@inproceedings{Lottridge2009,
	title        = {Sharing empty moments: design for remote couples},
	author       = {Lottridge, Danielle and Masson, Nicolas and Mackay, Wendy},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {2329--2338},
	institution  = {ACM},
	keywords     = {remote couples, presence, field trials, ambient, computer mediated communication, intimacy, domestic routines, reflective design, empty moments, intimate technology;litsurvey.bib}
}

@inproceedings{Luff2011,
	title        = {Hands on hitchcock: embodied reference to a moving scene},
	author       = {Luff, Paul and Yamashita, Naomi and Kuzuoka, Hideaki and Heath, Christian},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {43--52},
	institution  = {ACM},
	keywords     = {interaction analysis, cscw, media spaces, embodied interaction;litsurvey.bib}
}

@article{Luo2019,
	title        = {User choice of interactive data visualization format: The effects of cognitive style and spatial ability},
	author       = {Luo, Wenhong},
	year         = 2019,
	journal      = {Decision Support Systems},
	publisher    = {Elsevier},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0167923619300776-main.pdf:PDF}
}

@inproceedings{Ma2011,
	title        = {Perceptual analysis of talking avatar head movements: a quantitative perspective},
	author       = {Ma, Xiaohan and Le, Binh Huy and Deng, Zhigang},
	year         = 2011,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vancouver, BC, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '11},
	pages        = {2699--2702},
	institution  = {ACM},
	keywords     = {head motion, quantitative analysis, and audio-head motion features, perceptual modeling;litsurvey.bib}
}

@article{Macrae2002,
	title        = {Are you looking at me? Eye gaze and person perception},
	author       = {Macrae, C Neil and Hood, Bruce M and Milne, Alan B and Rowe, Angela C and Mason, Malia F},
	year         = 2002,
	month        = {\#sep\#},
	journal      = {Psychol. Sci.},
	volume       = 13,
	number       = 5,
	pages        = {460--464},
	abstract     = {Previous research has highlighted the pivotal role played by gaze detection and interpretation in the development of social cognition. Extending work of this kind, the present research investigated the effects of eye gaze on basic aspects of the person-perception process, namely, person construal and the extraction of category-related knowledge from semantic memory. It was anticipated that gaze direction would moderate the efficiency of the mental operations through which these social-cognitive products are generated. Specifically, eye gaze was expected to influence both the speed with which targets could be categorized as men and women and the rate at which associated stereotypic material could be accessed from semantic memory. The results of two experiments supported these predictions: Targets with nondeviated (i.e., direct) eye gaze elicited facilitated categorical responses. The implications of these findings for recent treatments of person perception are considered.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Macrae2002,
	title        = {Are You Looking At Me? Eye Gaze And Person Perception},
	author       = {Macrae, C Neil and Hood, Bruce M and Milne, Alan B and Rowe, Angela C and Mason, Malia F},
	year         = 2002,
	volume       = 13,
	pages        = {460--464},
	abstract     = {Previous research has highlighted the pivotal role played by gaze detection and interpretation in the development of social cognition. Extending work of this kind, the present research investigated the effects of eye gaze on basic aspects of the person-perception process, namely, person construal and the extraction of category-related knowledge from semantic memory. It was anticipated that gaze direction would moderate the efficiency of the mental operations through which these social-cognitive products are generated. Specifically, eye gaze was expected to influence both the speed with which targets could be categorized as men and women and the rate at which associated stereotypic material could be accessed from semantic memory. The results of two experiments supported these predictions: Targets with nondeviated (i.e., direct) eye gaze elicited facilitated categorical responses. The implications of these findings for recent treatments of person perception are considered.},
	keywords     = {Adult, Attention, Female, Fixation, Ocular, Gender Identity, Humans, Interpersonal Relations, Male, Mental Recall, Social Perception, Stereotyping;litsurvey.bib}
}

@inproceedings{Maeda2004,
	title        = {Real World Video Avatar: Transmission And Presentation Of Human Figure},
	author       = {Maeda, Hiroyuki and Tanikawa, Tomohiro and Yamashita, Jun and Hirota, Koichi and Hirose, Michitaka},
	year         = 2004,
	booktitle    = {Virtual Reality, 2004. Proceedings. {IEEE}},
	pages        = {237--238},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@inproceedings{Maimone2011,
	title        = {Encumbrance-free telepresence system with real-time {3D} capture and display using commodity depth cameras},
	author       = {Maimone, A and Fuchs, H},
	year         = 2011,
	month        = {\#oct\#},
	booktitle    = {2011 10th {IEEE} International Symposium on Mixed and Augmented Reality},
	pages        = {137--146},
	abstract     = {This paper introduces a proof-of-concept telepresence system that offers fully dynamic, real-time 3D scene capture and continuous-viewpoint, head-tracked stereo 3D display without requiring the user to wear any tracking or viewing apparatus. We present a complete software and hardware framework for implementing the system, which is based on an array of commodity Microsoft Kinectâ„¢color-plus-depth cameras. Novel contributions include an algorithm for merging data between multiple depth cameras and techniques for automatic color calibration and preserving stereo quality even with low rendering rates. Also presented is a solution to the problem of interference that occurs between Kinect cameras with overlapping views. Emphasis is placed on a fully GPU-accelerated data processing and rendering pipeline that can apply hole filling, smoothing, data merger, surface generation, and color correction at rates of up to 100 million triangles/sec on a single PC and graphics board. Also presented is a Kinect-based marker-less tracking system that combines 2D eye recognition with depth information to allow head-tracked stereo views to be rendered for a parallax barrier autostereoscopic display. Our system is affordable and reproducible, offering the opportunity to easily deliver 3D telepresence beyond the researcher's lab.},
	keywords     = {Cameras;Graphics processing unit;Image color analysis;Interference;Rendering (computer graphics);Smoothing methods;Three dimensional displays;camera calibration;color calibration;computer vision;filtering;object recognition;parallel processing;sensor fusion;surface fitting;teleconferencing;three-dimensional displays;tracking;virtual reality;litsurvey.bib}
}

@article{Maimone2011,
	title        = {A first look at a telepresence system with room-sized real-time 3d capture and life-sized tracked display wall},
	author       = {Maimone, Andrew and Fuchs, Henry},
	year         = 2011,
	journal      = {Proceedings of ICAT 2011, to appear},
	pages        = {4--9},
	keywords     = {litsurvey.bib}
}

@inproceedings{Maimone2013,
	title        = {General-purpose telepresence with head-worn optical see-through displays and projector-based lighting},
	author       = {Maimone, A and Yang, X and Dierk, N and State, A and Dou, M and Fuchs, H},
	year         = 2013,
	month        = {\#mar\#},
	booktitle    = {2013 {IEEE} Virtual Reality ({VR})},
	pages        = {23--26},
	abstract     = {In this paper we propose a general-purpose telepresence system design that can be adapted to a wide range of scenarios and present a framework for a proof-of-concept prototype. The prototype system allows users to see remote participants and their surroundings merged into the local environment through the use of an optical see-through head-worn display. Real-time 3D acquisition and head tracking allows the remote imagery to be seen from the correct point of view and with proper occlusion. A projector-based lighting control system permits the remote imagery to appear bright and opaque even in a lit room. Immersion can be adjusted across the VR continuum. Our approach relies only on commodity hardware; we also experiment with wider field of view custom displays.},
	institution  = {IEEE},
	keywords     = {data acquisition;helmet mounted displays;lighting control;object tracking;optical projectors;virtual reality;head-worn optical see-through displays;projector-based lighting;general-purpose telepresence system design;proof-of-concept prototype;optical see-through head-worn display;real-time 3D acquisition;head tracking;remote imagery;projector-based lighting control system;VR continuum;field-of-view custom displays;commodity hardware;Three-dimensional displays;Optical imaging;Optical sensors;Lighting control;Prototypes;Adaptive optics;Geometry;teleconferencing;augmented reality;virtual reality;litsurvey.bib}
}

@book{Marriott2018,
	title        = {Immersive Analytics},
	author       = {Marriott, Kim and Schreiber, Falk and Dwyer, Tim and Klein, Karsten and Riche, Nathalie Henry and Itoh, Takayuki and Stuerzlinger, Wolfgang and Thomas, Bruce H},
	year         = 2018,
	publisher    = {Springer},
	volume       = 11190,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/2018_Book_ImmersiveAnalytics.pdf:PDF}
}

@inproceedings{Marti2005,
	title        = {Physical embodiments for mobile communication agents},
	author       = {Marti, Stefan and Schmandt, Chris},
	year         = 2005,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 18th annual {ACM} symposium on User interface software and technology},
	location     = {Seattle, WA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '05},
	pages        = {231--240},
	institution  = {ACM},
	keywords     = {embodiment, conversational agent, robotic user interface, interruptions, human style non-verbal cues;litsurvey.bib}
}

@article{Martin1983,
	title        = {{Volumetric descriptions of objects from multiple views}},
	author       = {Martin, W N and Aggarwal, J K},
	year         = 1983,
	month        = {\#feb\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	volume       = 5,
	number       = 2,
	pages        = {150--158},
	abstract     = {Occluding contours from an image sequence with view-point specifications determine a bounding volume approximating the object generating the contours. The initial creation and continual refinement of the approximation requires a volumetric representation that facilitates modification yet is descriptive of surface detail. The ``volume segment'' representation presented in this paper is one such representation.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Matsuyama2004,
	title        = {{Real-time dynamic {3-D} object shape reconstruction and high-fidelity texture mapping for {3-D} video}},
	author       = {Matsuyama, T and {Xiaojun Wu} and Takai, T and Wada, T},
	year         = 2004,
	month        = {\#mar\#},
	journal      = {IEEE Trans. Circuits Syst. Video Technol.},
	volume       = 14,
	number       = 3,
	pages        = {357--369},
	abstract     = {Three-dimensional (3-D) video is a real 3-D movie recording the object's full 3-D shape, motion, and precise surface texture. This paper first proposes a parallel pipeline processing method for reconstructing a dynamic 3-D object shape from multiview video images, by which a temporal series of full 3-D voxel representations of the object behavior can be obtained in real time. To realize the real-time processing, we first introduce a plane-based volume intersection algorithm: first represent an observable 3-D space by a group of parallel plane slices, then back-project observed multiview object silhouettes onto each slice, and finally apply two-dimensional silhouette intersection on each slice. Then, we propose a method to parallelize this algorithm using a PC cluster, where we employ five-stage pipeline processing in each PC as well as slice-by-slice parallel silhouette intersection. Several results of the quantitative performance evaluation are given to demonstrate the effectiveness of the proposed methods. In the latter half of the paper, we present an algorithm of generating video texture on the reconstructed dynamic 3-D object surface. We first describe a naive view-independent rendering method and show its problems. Then, we improve the method by introducing image-based rendering techniques. Experimental results demonstrate the effectiveness of the improved method in generating high fidelity object images from arbitrary viewpoints.},
	keywords     = {real-time systems;image reconstruction;image texture;video signal processing;video recording;pipeline processing;image representation;real-time dynamic 3D object shape reconstruction;high-fidelity texture mapping;3D video;3D movie recording;parallel pipeline processing method;multiview video images;voxel representation;plane-based volume intersection algorithm;observable 3D space;parallel plane slices;back-project observed multiview object silhouette intersection;two-dimensional silhouette intersection;slice-by-slice parallel silhouette intersection;view-independent rendering method;image-based rendering technique;PC cluster;Shape;Image reconstruction;Real time systems;Humans;Surface reconstruction;Surface texture;Clustering algorithms;Pipeline processing;Rendering (computer graphics);Biomedical imaging;litsurvey.bib}
}

@inproceedings{Matusik2000,
	title        = {Image-based visual hulls},
	author       = {Matusik, Wojciech and Buehler, Chris and Raskar, Ramesh and Gortler, Steven J and McMillan, Leonard},
	year         = 2000,
	month        = {\#jul\#},
	booktitle    = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM Press/Addison-Wesley Publishing Co.},
	address      = {USA},
	series       = {SIGGRAPH '00},
	pages        = {369--374},
	institution  = {ACM Press/Addison-Wesley Publishing Co.},
	keywords     = {constructive solid geometry, misc. rendering algorithms, computer vision, image-based rendering;litsurvey.bib}
}

@inproceedings{McGrenere2000,
	title        = {Affordances: Clarifying and evolving a concept},
	author       = {McGrenere, Joanna and Ho, Wayne},
	year         = 2000,
	booktitle    = {Graphics interface},
	volume       = 2000,
	pages        = {179--186},
	keywords     = {litsurvey.bib}
}

@inproceedings{Mekuria2013,
	title        = {A {3D} tele-immersion system based on live captured mesh geometry},
	author       = {Mekuria, Rufael and Sanna, Michele and Asioli, Stefano and Izquierdo, Ebroul and Bulterman, Dick C A and Cesar, Pablo},
	year         = 2013,
	month        = {\#feb\#},
	booktitle    = {Proceedings of the 4th {ACM} Multimedia Systems Conference},
	location     = {Oslo, Norway},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {MMSys '13},
	pages        = {24--35},
	institution  = {ACM},
	keywords     = {compression algorithms, graphics streaming, architecture, 3D tele-immersion, 3D meshes, LT codes, networking;litsurvey.bib}
}

@article{Mendonca2001,
	title        = {{Epipolar geometry from profiles under circular motion}},
	author       = {Mendonca, P R S and -. K. Wong, K and Cipolla, R},
	year         = 2001,
	month        = {\#jun\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	volume       = 23,
	number       = 6,
	pages        = {604--616},
	abstract     = {Addresses the problem of motion estimation from profiles (apparent contours) of an object rotating on a turntable in front of a single camera. A practical and accurate technique for solving this problem from profiles alone is developed. It is precise enough to reconstruct the shape of the object. No correspondences between points or lines are necessary. Symmetry of the surface of revolution swept out by the rotating object is exploited to obtain the image of the rotation axis and the homography relating epipolar lines in two views robustly and elegantly. These, together with geometric constraints for images of rotating objects, are used to obtain first the image of the horizon, which is the projection of the plane that contains the camera centers, and then the epipoles, thus fully determining the epipolar geometry of the image sequence. The estimation of this geometry by this sequential approach avoids many of the problems found in other algorithms. The search for the epipoles, by far the most critical step, is carried out as a simple 1D optimization. Parameter initialization is trivial and completely automatic at all stages. After the estimation of the epipolar geometry, the Euclidean motion is recovered using the fixed intrinsic parameters of the camera obtained either from a calibration grid or from self-calibration techniques. Finally, the spinning object is reconstructed from its profiles using the motion estimated in the previous stage. Results from real data are presented, demonstrating the efficiency and usefulness of the proposed methods.},
	keywords     = {motion estimation;geometry;symmetry;image reconstruction;image sequences;search problems;optimisation;calibration;epipolar geometry;profiles;circular motion;apparent contours;shape reconstruction;homography;rotation axis;image sequence;1D optimization;parameter initialization;Euclidean motion;calibration grid;self-calibration techniques;Geometry;Motion estimation;Cameras;Image reconstruction;Shape;Surface reconstruction;Robustness;Image sequences;Calibration;Spinning;litsurvey.bib}
}

@article{merkle1978secure,
	title        = {Secure communications over insecure channels},
	author       = {Merkle, Ralph C},
	year         = 1978,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 21,
	number       = 4,
	pages        = {294--299}
}

@other{MichaelBroxton2020,
	title        = {Immersive Light Field Video with a Layered Mesh Representation},
	author       = {Michael Broxton, John Flynn, Ryan Overbeck, Daniel Erickson, Peter Hedman, Matthew DuVall, Jason Dourgarian, Jay Busch, Matt Whalen, and Paul Debevec},
	abstract     = {- Computing methodologies -> Image compression.Neural networks.Virtual reality.Image-based rendering.Computational photography.},
	file         = {:C\:\\Users\\its352\\OneDrive - University of Salford\\Research\\PostCovid\\Docear\\literature_repository\\ImmersiveLightFieldVideoWithALayeredMeshRepresentation.pdf:PDF},
	keywords     = {view synthesis, light fields, image-based rendering, deep learning}
}

@article{Mihoub2015,
	title        = {Learning multimodal behavioral models for face-to-face social interaction},
	author       = {Mihoub, Alaeddine and Bailly, G{\'e}rard and Wolf, Christian and Elisei, Fr{\'e}d{\'e}ric},
	year         = 2015,
	month        = {\#sep\#},
	journal      = {Journal on Multimodal User Interfaces},
	publisher    = {Springer},
	volume       = 9,
	number       = 3,
	pages        = {195--210},
	abstract     = {The aim of this paper is to model multimodal perception-action loops of human behavior in face-to-face interactions. To this end, we propose trainable behavioral models that predict the optimal actions for one specific person given others' perceived actions and the joint goals of the interlocutors. We first compare sequential models---in particular discrete hidden Markov models (DHMMs)---with standard classifiers (SVMs and decision trees). We propose a modification of the initialization of the DHMMs in order to better capture the recurrent structure of the sensory-motor states. We show that the explicit state duration modeling by discrete hidden semi markov models (DHSMMs) improves prediction performance. We applied these models to parallel speech and gaze data collected from interacting dyads. The challenge was to predict the gaze of one subject given the gaze of the interlocutor and the voice activity of both. For both DHMMs and DHSMMs the short-time Viterbi concept is used for incremental decoding and prediction. For the proposed models we evaluated objectively several properties in order to go beyond pure classification performance. Results show that incremental DHMMs (IDHMMs) were more efficient than classic classifiers and superseded by incremental DHSMMs (IDHSMMs). This later result emphasizes the relevance of state duration modeling.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Millais2018,
	title        = {Exploring data in virtual reality: Comparisons with 2d data visualizations},
	author       = {Millais, Patrick and Jones, Simon L and Kelly, Ryan},
	year         = 2018,
	booktitle    = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
	pages        = {LBW007},
	organization = {ACM},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/LBW007.pdf:PDF}
}

@article{Mitchell2011,
	title        = {A mismatch in the human realism of face and voice produces an uncanny valley},
	author       = {Mitchell, Wade J and Szerszen, Sr, Kevin A and Lu, Amy Shirong and Schermerhorn, Paul W and Scheutz, Matthias and Macdorman, Karl F},
	year         = 2011,
	month        = {\#mar\#},
	journal      = {Iperception},
	publisher    = {Pion Publications},
	volume       = 2,
	number       = 1,
	pages        = {10--12},
	abstract     = {The uncanny valley has become synonymous with the uneasy feeling of viewing an animated character or robot that looks imperfectly human. Although previous uncanny valley experiments have focused on relations among a character's visual elements, the current experiment examines whether a mismatch in the human realism of a character's face and voice causes it to be evaluated as eerie. The results support this hypothesis.},
	keywords     = {Masahiro Mori; anthropomorphism; facial--vocal mismatch; human realism; social perception;litsurvey.bib},
	language     = {en}
}

@techreport{Mitchelson2003,
	title        = {{Wand-based multiple camera studio calibration}},
	author       = {Mitchelson, Joel and Hilton, Adrian},
	year         = 2003,
	publisher    = {Centre for Vision, Speech and Signal Processing, University of Surrey, UK},
	keywords     = {litsurvey.bib}
}

@inproceedings{Moere2002,
	title        = {Infoticles: Information modeling in immersive environments},
	author       = {Moere, Andrew Vande},
	year         = 2002,
	booktitle    = {Proceedings Sixth International Conference on Information Visualisation},
	pages        = {457--461},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/01028813.pdf:PDF}
}

@article{Molina-Solana2017,
	title        = {Improving data exploration in graphs with fuzzy logic and large-scale visualisation},
	author       = {Molina-Solana, Miguel and Birch, David and Guo, Yi-ke},
	year         = 2017,
	journal      = {Applied Soft Computing},
	publisher    = {Elsevier},
	volume       = 53,
	pages        = {227--235},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S1568494616306731-main.pdf:PDF}
}

@article{Moloney2018,
	title        = {The affordance of virtual reality to enable the sensory representation of multi-dimensional data for immersive analytics: from experience to insight},
	author       = {Moloney, Jules and Spehar, Branka and Globa, Anastasia and Wang, Rui},
	year         = 2018,
	journal      = {Journal of Big Data},
	publisher    = {SpringerOpen},
	volume       = 5,
	number       = 1,
	pages        = 53,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/s40537-018-0158-z.pdf:PDF}
}

@book{Monge1989,
	title        = {A Profile of Meetings in Corporate {America}: Results of the {3M} Meeting Effectiveness Study},
	author       = {Monge, Peter R and McSween, Charles and Wyer, Joanne},
	year         = 1989,
	publisher    = {Annenberg School of Communications, University of Southern California},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Monk2002,
	title        = {A Look Is Worth a Thousand Words: Full Gaze Awareness in {Video-Mediated} Conversation},
	author       = {Monk, Andrew F and Gale, Caroline},
	year         = 2002,
	month        = {\#may\#},
	journal      = {Discourse Process.},
	publisher    = {Routledge},
	volume       = 33,
	number       = 3,
	pages        = {257--278},
	abstract     = {Full gaze awareness, defined here as knowing what someone is looking at, might be expected to be a powerful communicative resource when the conversation concerns some object of common interest in the environment. This article sets out to demonstrate this possibility in the context of video-mediated communication. An experiment is reported in which pairs complete a communication task using a novel apparatus that supports full gaze awareness (GA) and mutual gaze (eye contact). This ``GA display'' was contrasted with 2 control conditions, mutual gaze without full gaze awareness and audio only. The GA display reduced the number of turns and number of words required to complete the task by about 1/2 in comparison with the 2 control conditions. The results of a subsequent conversational games analysis suggest that at least part of this saving comes about because full gaze awareness provides an alternative nonlinguistic channel for checking one's own and the other person's understanding of what was said.},
	keywords     = {litsurvey.bib}
}

@book{Moons2010,
	title        = {{3D} reconstruction from multiple images part 1: Principles},
	author       = {Moons, Theo and Van Gool, Luc and Vergauwen, Maarten and {Others}},
	year         = 2010,
	publisher    = {Now Publishers, Inc.},
	volume       = 4,
	pages        = {287--404},
	keywords     = {litsurvey.bib}
}

@inproceedings{Moore2010,
	title        = {{Synchronization of Images from Multiple Cameras to Reconstruct a Moving Human}},
	author       = {Moore, C and Duckworth, T and Aspin, R and Roberts, D},
	year         = 2010,
	month        = {\#oct\#},
	booktitle    = {2010 {IEEE/ACM} 14th International Symposium on Distributed Simulation and Real Time Applications},
	publisher    = {IEEE},
	address      = {Fairfax},
	pages        = {53--60},
	abstract     = {What level of synchronization is necessary between images from multiple cameras in order to realistically reconstruct a moving human in 3D? Live reconstruction of the human form, from cameras surrounding the subject, could bridge the gap between video conferencing and Immersive Collaborative Virtual Environments (ICVEs). Video conferencing faithfully reproduces what someone looks like whereas ICVE faithfully reproduces what they look at. While 3D video has been demonstrated in tele-immersion prototypes, the visual/temporal quality has been way below what has become acceptable in video conferencing. Managed synchronization of the acquisition stage is universally used today to ensure multiple images feeding the reconstruction algorithm were taken at the same time. However, this inevitably increases latency and jitter. We measure the temporal characteristics of the capture stage and the impact of inconsistency on the reconstruction algorithm this feeds. This gives us both input and output characteristics for synchronization. From this we determine whether frame synchronization of multiple camera video streams actually needs to be delivered for 3D reconstruction, and if not what level of temporal divergence is acceptable across the captured image frames.},
	keywords     = {cameras;image motion analysis;image reconstruction;solid modelling;synchronisation;teleconferencing;video communication;image synchronization;moving human reconstruction algorithm;live reconstruction;video conferencing;immersive collaborative virtual environment;3D video;teleimmersion prototypes;visual-temporal quality;acquisition stage;multiple image feeding;jitter;frame synchronization;multiple camera video streams;3D reconstruction;temporal divergence;Head;Cameras;Three dimensional displays;Streaming media;Synchronization;Image reconstruction;Encoding;tele-immersion;telepresence;3D reconstruction;synchronisation;litsurvey.bib}
}

@inproceedings{Moore2011,
	title        = {{Investigating the Suitability of a Software Capture Trigger in a {3D} Reconstruction System for Telepresence}},
	author       = {Moore, C and Duckworth, T and Roberts, D J},
	year         = 2011,
	month        = {\#sep\#},
	booktitle    = {2011 {IEEE/ACM} 15th International Symposium on Distributed Simulation and Real Time Applications},
	pages        = {134--137},
	abstract     = {In this paper we examine how closely together images to be used in 3D reconstruction are captured, when acquisition is started using a software-based trigger delivered to multiple computers on a network. In addition we compare a software triggered pull system to a push system. Synchronisation is a key component in 3D reconstruction systems and can also be one of the most problematic. In a shape-from-silhouette based system, images are captured at the same moment to ensure the position of the object is consistent in all frames. Differences in position between captured frames results in deformations such as holes and missing or extended features. By capturing images of a projected clock, we can tell with around 10ms granularity, how closely together images are captured. This gives us an indication of whether software capture triggers delivered over a network can be used for image acquisition in a 3D reconstruction system, instead of hardware synchronised capture.},
	keywords     = {image reconstruction;telecontrol;virtual reality;software capture trigger;3D reconstruction system;telepresence;software triggered pull system;push system;shape-from-silhouette based system;image acquisition;Cameras;Three dimensional displays;Synchronization;Image reconstruction;Computers;Hardware;Software;synchronisation;3D reconstruction;networking;telepresence;teleimmersion;litsurvey.bib}
}

@article{Mori1970,
	title        = {The uncanny valley},
	author       = {Mori, Masahiro},
	year         = 1970,
	journal      = {Energy},
	volume       = 7,
	number       = 4,
	pages        = {33--35},
	keywords     = {litsurvey.bib}
}

@inproceedings{moritz2017trust,
	title        = {Trust, but verify: Optimistic visualizations of approximate queries for exploring big data},
	author       = {Moritz, Dominik and Fisher, Danyel and Ding, Bolin and Wang, Chi},
	year         = 2017,
	booktitle    = {Proceedings of the 2017 CHI conference on human factors in computing systems},
	pages        = {2904--2915},
	organization = {ACM},
	file         = {:../../../literature_repository/Data Visualisation/2017-TrustButVerify-CHI.pdf:PDF}
}

@inproceedings{Mortensen2002,
	title        = {Collaboration in tele-immersive environments},
	author       = {Mortensen, Jesper and Vinayagamoorthy, V and Slater, Mel and Steed, Anthony and Lok, B and Whitton, M C},
	year         = 2002,
	booktitle    = {{ACM} International Conference Proceeding Series},
	volume       = 23,
	pages        = {93--101},
	institution  = {Citeseer},
	keywords     = {litsurvey.bib}
}

@inproceedings{Moubayed2012,
	title        = {Taming Mona Lisa},
	author       = {Moubayed, Samer Al and Edlund, Jens and Beskow, Jonas},
	year         = 2012,
	volume       = 1,
	pages        = {1--25},
	keywords     = {litsurvey.bib}
}

@article{Mulligan2002,
	title        = {{Trinocular Stereo: A {Real-Time} Algorithm and its Evaluation}},
	author       = {Mulligan, Jane and Isler, Volkan and Daniilidis, Kostas},
	year         = 2002,
	journal      = {Int. J. Comput. Vis.},
	volume       = 47,
	number       = {1-3},
	pages        = {51--61},
	keywords     = {litsurvey.bib}
}

@inproceedings{Mulligan2000,
	title        = {{Trinocular stereo for non-parallel configurations}},
	author       = {Mulligan, Jane Jane and Kaniilidis, K},
	year         = 2000,
	booktitle    = {15\textbackslashtextsuperscript{th} International Conference on Pattern Recognition ({ICPR} 2000)},
	address      = {Barcelona},
	pages        = {567--570},
	keywords     = {litsurvey.bib}
}

@article{Munsell2013,
	title        = {Skype and messenger coming together: the next chapter},
	author       = {Munsell, Parri},
	year         = 2013,
	journal      = {URL: http://blogs. skype. com/2013/02/15/skype-and-messenger-coming-together-the-next-chapter/\# fbid= oFh6i6Q6aMm},
	keywords     = {litsurvey.bib}
}

@unpublished{Murray2007,
	title        = {An assessment of eye-gaze potential within immersive virtual environments},
	author       = {Murray, Norman and Roberts, Dave and Steed, Anthony and Sharkey, Paul and Dickerson, Paul and Rae, John},
	year         = 2007,
	month        = {\#dec\#},
	number       = {Article 8},
	keywords     = {eye gaze, Immersive virtual environments;litsurvey.bib}
}

@article{Murray2009,
	title        = {Eye gaze in virtual environments: evaluating the need and initial work on implementation},
	author       = {Murray, Norman and Roberts, Dave and Steed, Anthony and Sharkey, Paul and Dickerson, Paul and Rae, John and Wolff, Robin},
	year         = 2009,
	month        = {\#aug\#},
	journal      = {Concurr. Comput.},
	publisher    = {Wiley Online Library},
	volume       = 21,
	number       = 11,
	pages        = {1437--1449},
	abstract     = {Abstract For efficient collaboration between participants, eye gaze is seen as being critical for interaction. Video conferencing either does not attempt to support eye gaze (e.g. AcessGrid) or only approximates it in round table conditions (e.g. life size telepresence). Immersive collaborative virtual environments represent remote participants through avatars that follow their tracked movements. By additionally tracking people's eyes and representing their movement on their avatars, the line of gaze can be faithfully reproduced, as opposed to approximated. This paper presents the results of initial work that tested if the focus of gaze could be more accurately gauged if tracked eye movement was added to that of the head of an avatar observed in an immersive VE. An experiment was conducted to assess the difference between user's abilities to judge what objects an avatar is looking at with only head movements being displayed, while the eyes remained static, and with eye gaze and head movement information being displayed. The results from the experiment show that eye gaze is of vital importance to the subjects correctly identifying what a person is looking at in an immersive virtual environment. This is followed by a description of the work that is now being undertaken following the positive results from the experiment. We discuss the integration of an eye tracker more suitable for immersive mobile use and the software and techniques that were developed to integrate the user's real-world eye movements into calibrated eye gaze in an immersive virtual world. This is to be used in the creation of an immersive collaborative virtual environment supporting eye gaze and its ongoing experiments. Copyright ? 2009 John Wiley \& Sons, Ltd.},
	keywords     = {litsurvey.bib}
}

@article{Muhlbach1995,
	title        = {Telepresence in videocommunications: a study on stereoscopy and individual eye contact},
	author       = {M{\"u}hlbach, L and B{\"o}cker, M and Prussog, A},
	year         = 1995,
	month        = {\#jun\#},
	journal      = {Hum. Factors},
	volume       = 37,
	number       = 2,
	pages        = {290--305},
	abstract     = {We conducted two experiments to investigate how stereoscopy and technologies that allow individual eye contact affect the impression of telepresence in video-conferencing. Telepresence is defined as the degree to which participants of a telemeeting get the impression of sharing space with the remote site. Results revealed, among other things, that stereoscopy increases telepresence and makes videoconferencing more attractive. In addition, we found that reduced eye contact angles enhance the recognizability of individually addressed nonverbal signals. However, a setup that eliminates horizontal and vertical eye contact angles seems to be advantageous only in conferences with more than two persons per site.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Nagel1984,
	title        = {Spatio-temporal modeling based on image sequences},
	author       = {Nagel, H H},
	year         = 1984,
	booktitle    = {Proa. of the Inter. Symp. on Image Processing and it},
	pages        = {18--21},
	keywords     = {litsurvey.bib}
}

@inproceedings{Nagendran2012,
	title        = {Continuum of virtual-human space: towards improved interaction strategies for physical-virtual avatars},
	author       = {Nagendran, Arjun and Pillat, Remo and Hughes, Charles and Welch, Greg},
	year         = 2012,
	month        = {\#dec\#},
	booktitle    = {Proceedings of the 11th {ACM} {SIGGRAPH} International Conference on {Virtual-Reality} Continuum and its Applications in Industry},
	location     = {Singapore, Singapore},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {VRCAI '12},
	pages        = {135--142},
	keywords     = {Avatars, Microposes, Physical-Virtual Avatar, Remo; remote-operation;litsurvey.bib}
}

@article{Nakamoto2008,
	title        = {Re: Bitcoin P2P e-cash paper},
	author       = {Nakamoto, Satoshi},
	year         = 2008,
	journal      = {Email posted to listserv},
	volume       = 9,
	pages        = {04},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/bitcoin.pdf:PDF}
}

@inproceedings{Nakanishi2004,
	title        = {{FreeWalk/Q}: social interaction platform in virtual space},
	author       = {Nakanishi, Hideyuki and Ishida, Toru},
	year         = 2004,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the {ACM} symposium on Virtual reality software and technology},
	location     = {Hong Kong},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {VRST '04},
	pages        = {97--104},
	institution  = {ACM},
	keywords     = {scenario description, interaction platform, virtual city, virtual space, social interaction, virtual community, agent, virtual training, avatar;litsurvey.bib}
}

@inproceedings{Nakanishi2009,
	title        = {Movable cameras enhance social telepresence in media spaces},
	author       = {Nakanishi, Hideyuki and Murakami, Yuki and Kato, Kei},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {433--442},
	institution  = {ACM},
	keywords     = {media space, motion parallax, telepresence;litsurvey.bib}
}

@book{Napier1983,
	title        = {Making groups work: A guide for group leaders},
	author       = {Napier, Rodney and Gershenfeld, Matti K},
	year         = 1983,
	publisher    = {Houghton Mifflin},
	keywords     = {litsurvey.bib}
}

@book{Napier1973,
	title        = {Groups: Theory and experience},
	author       = {Napier, Rodney W and Gershenfeld, Matti K},
	year         = 1973,
	publisher    = {Houghton Mifflin},
	keywords     = {litsurvey.bib}
}

@inproceedings{Nguyen2005,
	title        = {{MultiView}: spatially faithful group video conferencing},
	author       = {Nguyen, David and Canny, John},
	year         = 2005,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Portland, Oregon, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '05},
	pages        = {799--808},
	institution  = {ACM},
	keywords     = {video conferencing, spatial faithfulness, deixis, eye contact, gaze;litsurvey.bib}
}

@inproceedings{Nguyen2009,
	title        = {More than face-to-face: empathy effects of video framing},
	author       = {Nguyen, David T and Canny, John},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {423--432},
	institution  = {ACM},
	keywords     = {video conferencing, empathy, oneness;litsurvey.bib}
}

@inproceedings{Nielsen1995,
	title        = {Usability inspection methods},
	author       = {Nielsen, Jakob},
	year         = 1995,
	month        = {\#may\#},
	booktitle    = {Conference Companion on Human Factors in Computing Systems},
	location     = {Denver, Colorado, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '95},
	pages        = {377--378},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@phdthesis{Nilsson2004,
	title        = {{Computer-Supported} Cooperative Work and Embodied Social Interaction},
	author       = {Nilsson, Cindy},
	year         = 2004,
	publisher    = {Institutionen f{\"o}r kommunikation och information},
	abstract     = {Research in Computer-Supported Cooperative Work (CSCW) has identified a gap - the, so called, social-technical gap - between the wide range of human social interactions that CSCW ideally should sup ...},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@book{Nishibe2016,
	title        = {The Enigma of Money: Gold, Central Banknotes, and Bitcoin},
	author       = {Nishibe, Makoto},
	year         = 2016,
	publisher    = {Springer},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/The_Enigma_of_Money_Gold_Central.pdf:PDF}
}

@book{Nitschke2007,
	title        = {{3D} Reconstruction},
	author       = {Nitschke, Christian},
	year         = 2007,
	publisher    = {VDM Verlag},
	series       = {Real-time Volumetric Scene Reconstruction from Multiple Views},
	keywords     = {litsurvey.bib}
}

@article{Norman2002,
	title        = {The psychopathology of everyday things},
	author       = {Norman, Donald A},
	year         = 2002,
	journal      = {Foundations of cognitive psychology: core readings. MIT Press, Cambridge, MA},
	pages        = {417--443},
	keywords     = {litsurvey.bib}
}

@article{Normand1999,
	title        = {The {COVEN} Project: Exploring Applicative, Technical, and Usage Dimensions of Collaborative Virtual Environments},
	author       = {Normand, V{\'e}ronique and Babski, Christian and Benford, Steve and Bullock, Adrian and Carion, St{\'e}phane and Chrysanthou, Yiorgos and Farcet, Nicolas and Fr{\'e}con, Emmanuel and Harvey, John and Kuijpers, Nico and Magnenat-Thalmann, Nadia and Raupp-Musse, Soraia and Rodden, Tom and Slater, Mel and Smith, Gareth and Steed, Anthony and Thalmann, Daniel and Tromp, Jolanda and Usoh, Martin and Van Liempd, Gidi and Kladias, Nicos},
	year         = 1999,
	month        = {\#apr\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 8,
	number       = 2,
	pages        = {218--236},
	abstract     = {COVEN (Collaborative Virtual Environments) is a European project that seeks to develop a comprehensive approach to the issues in the development of collaborative virtual environment (CVE) technology. COVEN brings together twelve academic and industrial partners with a wide range of expertise in CSCW, networked VR, computer graphics, human factors, HCI, and telecommunications infrastructures. After two years of work, we are presenting the main features of our approach and results, our driving applications, the main components of our technical investigations, and our experimental activities. With different citizen and professional application scenarios as driving forces, COVEN is exploring the requirements and supporting techniques for collaborative interaction in scalable CVEs. Technical results are being integrated in an enriched networked VR platform based on the dVS and DIVE systems. Taking advantage of a dedicated Europe-wide ISDN and ATM network infrastructure, a large component of the project is a trial and experimentation activity that should allow a comprehensive understanding of the network requirements of these systems as well as their usability issues and human factors aspects.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Norris2012,
	title        = {{CamBlend}: an object focused collaboration tool},
	author       = {Norris, James and Schn{\"a}delbach, Holger and Qiu, Guoping},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {627--636},
	institution  = {ACM},
	keywords     = {interaction analysis, focus+context, collaboration, cscw;litsurvey.bib}
}

@inproceedings{Norris2013,
	title        = {Putting things in focus: establishing co-orientation through video in context},
	author       = {Norris, James and Schn{\"a}delbach, Holger M and Luff, Paul K},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {1329--1338},
	institution  = {ACM},
	keywords     = {collaboration, cscw, focus+context, interaction analysis;litsurvey.bib}
}

@inproceedings{Novick1996,
	title        = {Coordinating turn-taking with gaze},
	author       = {Novick, D G and Hansen, B and Ward, K},
	year         = 1996,
	month        = {\#oct\#},
	booktitle    = {Proceeding of Fourth International Conference on Spoken Language Processing. {ICSLP} '96},
	volume       = 3,
	pages        = {1888--1891 vol.3},
	abstract     = {Explores the role of gaze in coordinating turn-taking in mixed-initiative conversation, and specifically how gaze indicators might be usefully modeled in computational dialogue systems. We analyzed about 20 minutes of videotape of eight dialogues by four pairs of subjects performing a simple face-to-face cooperative laboratory task. We extend previous studies by explicating gaze patterns in face-to-face conversations, formalizing the most frequent pattern as a computational model of turn-taking and testing the model through an agent-based simulation. Prior conversation simulations of conversational control acts relied on abstract speech-act representations of control. This study advances the computational account of dialogue through simulation of direct physical expression of gaze to coordinate conversational turns.},
	keywords     = {behavioural sciences;digital simulation;software agents;cooperative systems;behavioural sciences computing;conversational turn-taking;gaze indicators;coordination;mixed-initiative conversation;computational dialogue systems;videotape;face-to-face cooperative laboratory task;gaze patterns;face-to-face conversations;agent-based simulation;conversational control acts;abstract speech-act representations;physical expression;Computational modeling;Laboratories;Power system modeling;Testing;Frequency;Natural languages;Performance analysis;Physics computing;Monitoring;Communication system control;litsurvey.bib}
}

@inproceedings{Nowak2001,
	title        = {Defining and differentiating copresence, social presence and presence as transportation},
	author       = {Nowak, Kristen},
	year         = 2001,
	booktitle    = {Presence 2001 Conference, Philadelphia, {PA}},
	pages        = {1--23},
	institution  = {Citeseer},
	keywords     = {litsurvey.bib}
}

@article{Nowak2003,
	title        = {The Effect of the Agency and Anthropomorphism on Users' Sense of Telepresence, Copresence, and Social Presence in Virtual Environments},
	author       = {Nowak, Kristine L and Biocca, Frank},
	year         = 2003,
	month        = {\#oct\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 12,
	number       = 5,
	pages        = {481--494},
	abstract     = {We report on an experiment that examined the influence of anthropomorphism and perceived agency on presence, copresence, and social presence in a virtual environment. The experiment varied the level of anthropomorphism of the image of interactants: high anthropomorphism, low anthropomorphism, or no image. Perceived agency was manipulated by telling the participants that the image was either an avatar controlled by a human, or an agent controlled by a computer. The results support the prediction that people respond socially to both human and computer-controlled entities, and that the existence of a virtual image increases tele-presence. Participants interacting with the less-anthropomorphic image reported more copresence and social presence than those interacting with partners represented by either no image at all or by a highly anthropomorphic image of the other, indicating that the more anthropomorphic images set up higher expectations that lead to reduced presence when these expectations were not met.},
	keywords     = {litsurvey.bib}
}

@inproceedings{OHare2016,
	title        = {Is This Seat Taken? Behavioural Analysis of the Telethrone: A Novel Situated Telepresence Display},
	author       = {O'Hare, John and Bendall, Robert C A and Rae, John and Thomas, Graham and Weir, Bruce and Roberts, David J},
	year         = 2016,
	booktitle    = {{ICAT-EGVE}},
	pages        = {99--106},
	institution  = {Eurographics Association},
	keywords     = {litsurvey.bib}
}

@incollection{OHare2018,
	title        = {Telethrone Reconstructed; Ongoing Testing Toward a More Natural Situated Display},
	author       = {O'Hare, John and Fairchild, Allen J and Wolff, Robin and Roberts, David J},
	year         = 2018,
	booktitle    = {Augmented Reality and Virtual Reality: Empowering Human, Place and Business},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {323--337},
	editor       = {Jung, Timothy and tom Dieck, M Claudia},
	abstract     = {The concept of supporting ad hoc or dynamic membership tele-present meetings through pulling up a chair is novel. In real world business situations, people pull up a chair after catching the eye of someone already seated. Telethrone is a situated display on a chair which allows multiple correct views of a remote collaborator. The system has been expanded to support informal meetings where chairs can be moved around. This is facilitated through the novel integration of a 3D reconstructed model of a person, with live viewpoint dependent rendering onto a retro-reflective surface. This removes the need for painstaking alignment of multiple cameras and projectors each time a chair is moved. A between subjects experiment tested accuracy of reconnected mutual gaze mediated by part of the system. Subjectively easier and harder situations are compared. Specifically best and worst cases, both in terms of orientation of eyes in the reconstructed head, and angle of observer gaze onto the display. Discussion compares results to experiments that used other systems to attempt to convey eye gaze by different techniques. This research builds toward a scalable system for ad hoc business meetings; a paradigm poorly supported by current video conferencing. It is also applicable to supporting conversations between seated people in any scenario where seats might be moved, for example in interaction between client and therapist in tele-therapy.},
	keywords     = {litsurvey.bib}
}

@inproceedings{OMalley1996,
	title        = {Comparison Of Face-to-face And Video-mediated Interaction},
	author       = {O'Malley, C and Langton, Steve},
	year         = 1996,
	volume       = 2,
	pages        = {177--192},
	keywords     = {computer-supported;litsurvey.bib}
}

@article{oeppen2020human,
	title        = {Human factors recognition at virtual meetings and video conferencing: how to get the best performance from yourself and others},
	author       = {Oeppen, RS and Shaw, G and Brennan, PA},
	year         = 2020,
	journal      = {British Journal of Oral and Maxillofacial Surgery},
	publisher    = {Elsevier}
}

@inproceedings{ohba1998,
	title        = {Facial expression space for smooth tele-communications},
	author       = {Ohba, K and Tsukada, T and Kotoku, T and Tanie, K},
	year         = 1998,
	month        = {\#apr\#},
	booktitle    = {Proceedings Third {IEEE} International Conference on Automatic Face and Gesture Recognition},
	pages        = {378--383},
	abstract     = {In this paper, the facial expression is mainly focused to achieve the smooth tele-communications. The facial expressions has been considered as the most significant factor in tele-communications, such as tele-services. To realize the real time facial expression transportation system, we propose the facial expression space (FES) and a correspondence technique between each personal facial expression spaces. Then, real time facial expression transportation system is developed, which transports the facial expression but not the image itself. This final system is able to display the same facial expressions in another person and further more in cartoon characters. The experimental results show the validity of these criteria.},
	institution  = {IEEE},
	keywords     = {face recognition;facial expression space;smooth telecommunications;personal facial expression spaces;Humans;Telephony;Robot vision systems;TV;litsurvey.bib}
}

@phdthesis{Ohta1986,
	title        = {{Improving Depth Map by Right-angled Trinocular Stereo}},
	author       = {Ohta, Yuichi and Watanabe, Masaki and Ikeda, Katsuo},
	year         = 1986,
	school       = {University of Tsukuba},
	keywords     = {litsurvey.bib}
}

@article{Okada2019,
	title        = {VR system for spatio-temporal visualization of tweet data and support of map exploration},
	author       = {Okada, Kaya and Yoshida, Mitsuo and Itoh, Takayuki and Czauderna, Tobias and Stephens, Kingsley},
	year         = 2019,
	journal      = {Multimedia Tools and Applications},
	publisher    = {Springer},
	volume       = 78,
	number       = 23,
	pages        = {32849--32868},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08564144.pdf:PDF}
}

@inproceedings{Okada1994,
	title        = {{Multiparty videoconferencing at virtual social distance: {MAJIC} design}},
	author       = {Okada, Ken-Ichi and Maeda, Fumihiko and Ichikawaa, Yusuke and Matsushita, Yutaka},
	year         = 1994,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 1994 {ACM} conference on Computer supported cooperative work},
	location     = {Chapel Hill, North Carolina, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '94},
	pages        = {385--393},
	keywords     = {multiparty videoconferencing, networked realities, tele-presence, MAJIC, gaze awareness, groupware, multiple eye contact;litsurvey.bib}
}

@article{Okutomi1993,
	title        = {A multiple-baseline stereo},
	author       = {Okutomi, M and Kanade, T},
	year         = 1993,
	month        = {\#apr\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	publisher    = {IEEE},
	volume       = 15,
	number       = 4,
	pages        = {353--363},
	abstract     = {A stereo matching method that uses multiple stereo pairs with various baselines generated by a lateral displacement of a camera to obtain precise distance estimates without suffering from ambiguity is presented. Matching is performed simply by computing the sum of squared-difference (SSD) values. The SSD functions for individual stereo pairs are represented with respect to the inverse distance and are then added to produce the sum of SSDs. This resulting function is called the SSSD-in-inverse-distance. It is shown that the SSSD-in-inverse-distance function exhibits a unique and clear minimum at the correct matching position, even when the underlying intensity patterns of the scene include ambiguities or repetitive patterns. The authors first define a stereo algorithm based on the SSSD-in-inverse-distance and present a mathematical analysis to show how the algorithm can remove ambiguity and increase precision. Experimental results with real stereo images are presented to demonstrate the effectiveness of the algorithm.},
	keywords     = {computer vision;stereo image processing;computer vision;multiple-baseline stereo;stereo matching method;lateral displacement;precise distance estimates;Stereo vision;Cameras;Layout;Pattern matching;Matched filters;Filtering;Mathematical analysis;Image matching;Computer vision;US Department of Defense;litsurvey.bib}
}

@inproceedings{Olsson2007,
	title        = {Social decision making strategies in internet poker playing},
	author       = {Olsson, Anna-Carin and di Zazzo, Nicole and Tjaderborn, Johanna},
	year         = 2007,
	booktitle    = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	volume       = 29,
	pages        = 1831,
	keywords     = {litsurvey.bib}
}

@inproceedings{Orts-Escolano2016,
	title        = {Holoportation: Virtual {3D} Teleportation in Real-time},
	author       = {Orts-Escolano, Sergio and Rhemann, Christoph and Fanello, Sean and Chang, Wayne and Kowdle, Adarsh and Degtyarev, Yury and Kim, David and Davidson, Philip L and Khamis, Sameh and Dou, Mingsong and Tankovich, Vladimir and Loop, Charles and Cai, Qin and Chou, Philip A and Mennicken, Sarah and Valentin, Julien and Pradeep, Vivek and Wang, Shenlong and Kang, Sing Bing and Kohli, Pushmeet and Lutchyn, Yuliya and Keskin, Cem and Izadi, Shahram},
	year         = 2016,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	location     = {Tokyo, Japan},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '16},
	pages        = {741--754},
	institution  = {ACM},
	keywords     = {gpu, depth cameras, 3d capture, real-time, telepresence, non-rigid reconstruction, mixed reality;litsurvey.bib}
}

@inproceedings{Ostrem2014,
	title        = {A Behavior analytic perspective on gambling behavior},
	author       = {Ostrem, Camilla},
	year         = 2014,
	publisher    = {H{\o}gskolen i Oslo og Akershus},
	keywords     = {litsurvey.bib}
}

@inproceedings{Otsuka2013,
	title        = {{MM+Space}: n x 4 degree-of-freedom kinetic display for recreating multiparty conversation spaces},
	author       = {Otsuka, Kazuhiro and Kumano, Shiro and Ishii, Ryo and Zbogar, Maja and Yamato, Junji},
	year         = 2013,
	month        = {\#dec\#},
	booktitle    = {Proceedings of the 15th {ACM} on International conference on multimodal interaction},
	location     = {Sydney, Australia},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {ICMI '13},
	pages        = {389--396},
	institution  = {ACM},
	keywords     = {telepresence, face-to-face conversation, multimodal interaction, computer-mediated communication, projection mapping;litsurvey.bib}
}

@inproceedings{Otsuka2005,
	title        = {A probabilistic inference of multiparty-conversation structure based on Markov-switching models of gaze patterns, head directions, and utterances},
	author       = {Otsuka, Kazuhiro and Takemae, Yoshinao and Yamato, Junji},
	year         = 2005,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 7th international conference on Multimodal interfaces},
	location     = {Torento, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {ICMI '05},
	pages        = {191--198},
	institution  = {ACM},
	keywords     = {eye gaze, Markov-switching model, Gibbs sampler, dynamic Bayesian network, nonverbal cues, Markov chain Monte Carlo, face-to-face multiparty conversation;litsurvey.bib}
}

@inproceedings{Ott1993,
	title        = {Teleconferencing eye contract using a virtual camera},
	author       = {Ott, Maximilian and Lewis, John P and Cox, Ingemar},
	year         = 1993,
	month        = {\#apr\#},
	booktitle    = {{INTERACT} '93 and {CHI} '93 Conference Companion on Human Factors in Computing Systems},
	location     = {Amsterdam, The Netherlands},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '93},
	pages        = {109--110},
	institution  = {ACM},
	keywords     = {litsurvey.bib}
}

@inproceedings{Ou2005,
	title        = {Effects of task properties, partner actions, and message content on eye gaze patterns in a collaborative task},
	author       = {Ou, Jiazhi and Oh, Lui Min and Yang, Jie and Fussell, Susan R},
	year         = 2005,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Portland, Oregon, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '05},
	pages        = {231--240},
	institution  = {ACM},
	keywords     = {eye-tracking, conversational analysis, collaborative work, video mediated communication, gesture, empirical studies, video conferencing, computer-supported;litsurvey.bib}
}

@inproceedings{Oyekoya2012,
	title        = {{SphereAvatar}: a situated display to represent a remote collaborator},
	author       = {Oyekoya, Oyewole and Steptoe, William and Steed, Anthony},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {2551--2560},
	keywords     = {Spherical displays, remote collaboration, telepres; avatars; telepresence; mixed reality; telerobotics;litsurvey.bib}
}

@article{Pahins2016,
	title        = {Hashedcubes: Simple, low memory, real-time visual exploration of big data},
	author       = {Pahins, Cicero AL and Stephens, Sean A and Scheidegger, Carlos and Comba, Joao LD},
	year         = 2016,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 23,
	number       = 1,
	pages        = {671--680},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07539326.pdf:PDF}
}

@inproceedings{Pan2008,
	title        = {{Male Bodily Responses during an Interaction with a Virtual Woman}},
	author       = {Pan, Xueni and Gillies, Marco and Slater, Mel},
	year         = 2008,
	booktitle    = {Intelligent Virtual Agents},
	publisher    = {Springer Berlin Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 5208,
	pages        = {89--96},
	editor       = {Prendinger, Helmut and Lester, James C and Ishizuka, Mitsuru},
	abstract     = {This work presents the analysis of the body movement of male participants, while talking with a life-size virtual woman in a virtual social encounter within a CAVE-like system. We consider independent and explanatory variables including whether the participant is the centre of attention in the scenario, whether the participant is shy or confident, and his relationship status. We also examine whether this interaction between the participant and the virtual character changes as the conversation progresses. The results show that the participants tend to have different hand movements, head movements, and posture depending on these conditions. This research therefore provides strong evidence for using body movement as a systematic method to assess the responses of people within a virtual environment, especially when the participant interacts with a virtual character. These results also point the way towards the application of this technology to the treatment of social phobic males.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Pan_undated,
	title        = {Male Bodily Responses towards a Virtual Woman},
	author       = {Pan, Xueni and Gillies, Marco and Slater, Mel},
	booktitle    = {Symposium on Mental States, Emotions and their Embodiment},
	pages        = 8,
	keywords     = {litsurvey.bib}
}

@inproceedings{Pan2014,
	title        = {A gaze-preserving situated multiview telepresence system},
	author       = {Pan, Ye and Steed, Anthony},
	year         = 2014,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Toronto, Ontario, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '14},
	pages        = {2173--2176},
	institution  = {ACM},
	keywords     = {non-planar displays, camera arrays, gaze;litsurvey.bib}
}

@inproceedings{Pan2012,
	title        = {Preserving gaze direction in teleconferencing using a camera array and a spherical display},
	author       = {Pan, Y and Steed, A},
	year         = 2012,
	month        = {\#oct\#},
	booktitle    = {2012 {3DTV-Conference}: The True Vision - Capture, Transmission and Display of {3D} Video ({3DTV-CON})},
	pages        = {1--4},
	abstract     = {The movement of human gaze is very important in face to face conversation. Some of the quality of that movement is lost in videoconferencing because the participants look at a single planar image of the remote person. We use an array of cameras to capture a remote user, and then display video of that person on a spherical display. We compare the spherical display to a face to face setting and a planar display. We demonstrate the effectiveness of the camera array and spherical display system in that it allows observers to accurately judge where the remote user is placing their gaze.},
	institution  = {IEEE},
	keywords     = {cameras;computer displays;teleconferencing;video communication;video signal processing;gaze direction preservation;teleconferencing;camera array;videoconferencing;single planar image;display video;planar display;spherical display system;remote user;human gaze;Observers;Cameras;Face;Accuracy;Arrays;Streaming media;Non-planar displays;camera arrays;human gaze;litsurvey.bib}
}

@inproceedings{Pan2014,
	title        = {Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction},
	author       = {Pan, Ye and Steptoe, William and Steed, Anthony},
	year         = 2014,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Toronto, Ontario, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '14},
	pages        = {1397--1406},
	institution  = {ACM},
	keywords     = {avatars, telecommunication, spherical displays, trust, mixed reality;litsurvey.bib}
}

@article{Pandove2018,
	title        = {Systematic review of clustering high-dimensional and large datasets},
	author       = {Pandove, Divya and Goel, Shivan and Rani, Rinkl},
	year         = 2018,
	journal      = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
	publisher    = {ACM},
	volume       = 12,
	number       = 2,
	pages        = 16,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/3132088.pdf:PDF}
}

@inproceedings{Pappu2013,
	title        = {Situated Multiparty Interaction between Humans and Agents},
	author       = {Pappu, Aasish and Sun, Ming and Sridharan, Seshadri and Rudnicky, Alex},
	year         = 2013,
	booktitle    = {{Human-Computer} Interaction. Interaction Modalities and Techniques},
	publisher    = {Springer Berlin Heidelberg},
	pages        = {107--116},
	abstract     = {A social agent such as a receptionist or an escort robot encounters challenges when communicating with people in open areas. The agent must know not to react to distracting acoustic and visual events and it needs to appropriately handle situations that include multiple humans, being able to to focus on active interlocutors and appropriately shift attention based on the context. We describe a multiparty interaction agent that helps multiple users arrange a common activity. From the user study we conducted, we found that the agent can discriminate between active and inactive interlocutors well by using the skeletal and azimuth information. Participants found the addressee much clearer when an animated talking head was used.},
	institution  = {Springer},
	keywords     = {litsurvey.bib}
}

@article{Parsons1974,
	title        = {What Happened at Hawthorne?: New evidence suggests the Hawthorne effect resulted from operant reinforcement contingencies},
	author       = {Parsons, H M},
	year         = 1974,
	month        = {\#mar\#},
	journal      = {Science},
	publisher    = {American Association for the Advancement of Science},
	volume       = 183,
	number       = 4128,
	pages        = {922--932},
	abstract     = {The Hawthorne effect in experimental research is the unwanted effect of the experimental operations themselves. Following the Hawthorne studies, various explanations have been proposed to account for rising rates of production. Although in the Relay Assembly Test Room experiment the experimental operations may have produced other extraneous variables, a reexamination based on new and neglected evidence has yielded a new interpretation. The new variable, made more plausible because research in other contexts has shown it to have similar effects, is a combination of information feedback and financial reward. It is an example of the control of behavior by its consequences. Although several approaches may be taken to explain the effects of response-consequence contingencies, I have favored operant conditioning because it seems to account for progressive increases in response rate-the Hawthorne phenomenon. Generalizing from the particular situation at Hawthorne, I would define the Hawthorne effect as the confounding that occurs if experimenters fail to realize how the consequences of subjects' performance affect what subjects do. But the Hawthorne effect need not be viewed solely as a problem in conducting experiments. The phenomenon that created it should be studied in its own right, as Sommer (67) suggested with a different phenomenon in mind. The study of response-consequence contingencies might well be extended to the examination of motivation in industrial workers.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Paulos1998,
	title        = {{PRoP}: personal roving presence},
	author       = {Paulos, Eric and Canny, John},
	year         = 1998,
	month        = {\#jan\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Los Angeles, California, USA},
	publisher    = {ACM Press/Addison-Wesley Publishing Co.},
	address      = {USA},
	series       = {CHI '98},
	pages        = {296--303},
	institution  = {ACM Press/Addison-Wesley Publishing Co.},
	keywords     = {tele-embodiment, tele-presence, gesturing, robotics, telecommunications, tele-work, tele-robotics, tele-conferencing, computer-mediated human-human interaction, tele-action;litsurvey.bib}
}

@inproceedings{Paulos2004,
	title        = {The familiar stranger: anxiety, comfort, and play in public places},
	author       = {Paulos, Eric and Goodman, Elizabeth},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {223--230},
	institution  = {ACM},
	keywords     = {d{\'e}tournement, public place, wearable, urban computing, wireless, strangers, community, d{\'e}rive, digital scent;litsurvey.bib}
}

@inproceedings{Pece2013,
	title        = {Panoinserts: mobile spatial teleconferencing},
	author       = {Pece, Fabrizio and Steptoe, William and Wanner, Fabian and Julier, Simon and Weyrich, Tim and Kautz, Jan and Steed, Anthony},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {1319--1328},
	institution  = {ACM},
	keywords     = {camera tracking, mixed reality, remote collaboration, teleconferencing, telepresence, mobile phones, panoramas;litsurvey.bib}
}

@inproceedings{Pejsa2016,
	title        = {{Room2Room}: Enabling {Life-Size} Telepresence in a Projected Augmented Reality Environment},
	author       = {Pejsa, Tomislav and Kantor, Julian and Benko, Hrvoje and Ofek, Eyal and Wilson, Andrew},
	year         = 2016,
	month        = {\#feb\#},
	booktitle    = {Proceedings of the 19th {ACM} Conference on {Computer-Supported} Cooperative Work \& Social Computing},
	location     = {San Francisco, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '16},
	pages        = {1716--1725},
	institution  = {ACM},
	keywords     = {projector camera system, spatial augmented reality, projection-mapping, Telepresence, spatial interfaces;litsurvey.bib}
}

@inproceedings{Pelechano2008,
	title        = {Being a part of the crowd: towards validating {VR} crowds using presence},
	author       = {Pelechano, Nuria and Stocker, Catherine and Allbeck, Jan and Badler, Norman},
	year         = 2008,
	booktitle    = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
	pages        = {136--142},
	institution  = {International Foundation for Autonomous Agents and Multiagent Systems},
	keywords     = {litsurvey.bib}
}

@article{Perez-Marcos2012,
	title        = {A fully immersive set-up for remote interaction and neurorehabilitation based on virtual body ownership},
	author       = {Perez-Marcos, Daniel and Solazzi, Massimiliano and Steptoe, William and Oyekoya, Oyewole and Frisoli, Antonio and Weyrich, Tim and Steed, Anthony and Tecchia, Franco and Slater, Mel and Sanchez-Vives, Maria V},
	year         = 2012,
	month        = {\#jul\#},
	journal      = {Front. Neurol.},
	publisher    = {Frontiers Media SA},
	volume       = 3,
	pages        = 110,
	abstract     = {Although telerehabilitation systems represent one of the most technologically appealing clinical solutions for the immediate future, they still present limitations that prevent their standardization. Here we propose an integrated approach that includes three key and novel factors: (a) fully immersive virtual environments, including virtual body representation and ownership; (b) multimodal interaction with remote people and virtual objects including haptic interaction; and (c) a physical representation of the patient at the hospital through embodiment agents (e.g., as a physical robot). The importance of secure and rapid communication between the nodes is also stressed and an example implemented solution is described. Finally, we discuss the proposed approach with reference to the existing literature and systems.},
	keywords     = {body ownership; haptics; multisensory correlations; neurorehabilitation; rubber hand illusion; telemedicine; teleneurology; virtual reality;litsurvey.bib},
	language     = {en}
}

@inproceedings{Perez-Marcos2012,
	title        = {A Fully Immersive Set-up For Remote Interaction And Neurorehabilitation Based On Virtual Body Ownership},
	author       = {Perez-Marcos, Daniel and Solazzi, Massimiliano and Steptoe, William and Oyekoya, Oyewole and Frisoli, Antonio and Weyrich, Tim and Steed, Anthony and Tecchia, Franco and Slater, Mel and Sanchez-Vives, Maria V},
	year         = 2012,
	publisher    = {Frontiers Media SA},
	volume       = 3,
	keywords     = {litsurvey.bib}
}

@article{Perozzi2018,
	title        = {Discovering communities and anomalies in attributed graphs: Interactive visual exploration and summarization},
	author       = {Perozzi, Bryan and Akoglu, Leman},
	year         = 2018,
	journal      = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
	publisher    = {ACM},
	volume       = 12,
	number       = 2,
	pages        = 24,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/3139241.pdf:PDF}
}

@inproceedings{Petit2008,
	title        = {{Grimage: {3D} modeling for remote collaboration and telepresence}},
	author       = {Petit, Benjamin and Lesage, Jean-Denis and Franco, Jean-S{\'e}bastien and Boyer, Edmond and Raffin, Bruno},
	year         = 2008,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 2008 {ACM} symposium on Virtual reality software and technology},
	location     = {Bordeaux, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {VRST '08},
	pages        = {299--300},
	keywords     = {telepresence, marker-less 3D modeling, PC cluster, multi-cameras, collaborative 3D interactions;litsurvey.bib}
}

@article{Petit2009,
	title        = {{Multicamera {Real-Time} {3D} Modeling for Telepresence and Remote Collaboration}},
	author       = {Petit, Benjamin and Lesage, Jean-Denis and Menier, Cl{\'e}ment and Allard, J{\'e}r{\'e}mie and Franco, Jean-S{\'e}bastien and Raffin, Bruno and Boyer, Edmond and Faure, Fran{\c c}ois},
	year         = 2009,
	month        = {\#nov\#},
	journal      = {International Journal of Digital Multimedia Broadcasting},
	publisher    = {Hindawi},
	volume       = 2010,
	pages        = {1--12},
	abstract     = {We present a multicamera real-time 3D modeling system that aims at enabling new immersive and interactive environments. This system, called Grimage, allows to retrieve in real-time a 3D mesh of the observed scene as well as the associated textures. This information enables a strong visual presence of the user into virtual worlds. The 3D shape information is also used to compute collisions and reaction forces with virtual objects, enforcing the mechanical presence of the user in the virtual world. The innovation is a fully integrated system with both immersive and interactive capabilities. It embeds a parallel version of the EPVH modeling algorithm inside a distributed vision pipeline. It also adopts the hierarchical component approach of the FlowVR middleware to enforce software modularity and enable distributed executions. Results show high refresh rates and low latencies obtained by taking advantage of the I/O and computing resources of PC clusters. The applications we have developed demonstrate the quality of the visual and mechanical presence with a single platform and with a dual platform that allows telecollaboration.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{pienta2015scalable,
	title        = {Scalable graph exploration and visualization: Sensemaking challenges and opportunities},
	author       = {Pienta, Robert and Abello, James and Kahng, Minsuk and Chau, Duen Horng},
	year         = 2015,
	booktitle    = {2015 International Conference on Big Data and Smart Computing (BIGCOMP)},
	pages        = {271--278},
	organization = {IEEE},
	file         = {:../../../literature_repository/Data Visualisation/07072812.pdf:PDF}
}

@inproceedings{Po-Hao_Huang2008,
	title        = {{Silhouette-based camera calibration from sparse views under circular motion}},
	author       = {{Po-Hao Huang} and {Shang-Hong Lai}},
	year         = 2008,
	month        = {\#jun\#},
	booktitle    = {2008 {IEEE} Conference on Computer Vision and Pattern Recognition},
	address      = {Anchorage},
	pages        = {1--8},
	abstract     = {In this paper, we propose a new approach to camera calibration from silhouettes under circular motion with minimal data. We exploit the mirror symmetry property and derive a common homography that relates silhouettes with epipoles under circular motion. With the epipoles determined, the homography can be computed from the frontier points induced by epipolar tangencies. On the other hand, given the homography, the epipoles can be located directly from the bi-tangent lines of silhouettes. With the homography recovered, the image invariants under circular motion and camera parameters can be determined. If the epipoles are not available, camera parameters can be determined by a low-dimensional search of the optimal homography in a bounded region. In the degenerate case, when the camera optical axes intersect at one point, we derive a closed-form solution for the focal length to solve the problem. By using the proposed algorithm, we can achieve camera calibration simply from silhouettes of three images captured under circular motion. Experimental results on synthetic and real images are presented to show its performance.},
	keywords     = {calibration;cameras;image motion analysis;image silhouette-based camera calibration;sparse camera view;circular motion;mirror symmetry property;homography;bi-tangent line;camera optical intersect axes;camera focal length;Cameras;Calibration;Mirrors;Closed-form solution;Computer vision;Laboratories;Computer science;Image sequences;Robustness;Computational geometry;litsurvey.bib}
}

@incollection{Pollefeys2009,
	title        = {{CHAPTER} 2 - {Multi-View} Calibration, Synchronization, and Dynamic Scene Reconstruction},
	author       = {Pollefeys, Marc and Sinha, Sudipta N and Guan, Li and Franco, Jean-S{\'e}bastien},
	year         = 2009,
	month        = {\#jan\#},
	booktitle    = {{Multi-Camera} Networks},
	publisher    = {Academic Press},
	address      = {Oxford},
	pages        = {29--75},
	editor       = {Aghajan, Hamid and Cavallaro, Andrea},
	abstract     = {Abstract In this chapter, we first present a method for automatic camera network geometric calibration. The novel RANSAC-based calibration algorithm simultaneously computes camera poses and synchronization only from the objects of interest's (foreground object's) silhouette information in the videos from the multiple views. Then using this calibrated system, and again just from the silhouette cues, we introduce a probabilistic sensor fusion framework for 3D dynamic, scene reconstruction with potential static obstacles. Several real-world data sets show that despite lighting variation, photometric inconsistency between views, shadows, reflections, and so forth, not only are densely cluttered dynamic objects reconstructed and tracked, but static obstacles in the scene are also recovered.},
	keywords     = {epipolar geometry; frontier points; epipolar tangents; RANSAC; structure from motion; visual hulls; occlusion; dynamic scene reconstruction; shape from silhouette; sensor fusion; probability; Bayes rule;litsurvey.bib}
}

@article{Porter2008,
	title        = {Reading between the lies: identifying concealed and falsified emotions in universal facial expressions},
	author       = {Porter, Stephen and ten Brinke, Leanne},
	year         = 2008,
	month        = {\#may\#},
	journal      = {Psychol. Sci.},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 19,
	number       = 5,
	pages        = {508--514},
	abstract     = {The widespread supposition that aspects of facial communication are uncontrollable and can betray a deceiver's true emotion has received little empirical attention. We examined the presence of inconsistent emotional expressions and ``microexpressions'' (1/25-1/5 of a second) in genuine and deceptive facial expressions. Participants viewed disgusting, sad, frightening, happy, and neutral images, responding to each with a genuine or deceptive (simulated, neutralized, or masked) expression. Each 1/30-s frame (104,550 frames in 697 expressions) was analyzed for the presence and duration of universal expressions, microexpressions, and blink rate. Relative to genuine emotions, masked emotions were associated with more inconsistent expressions and an elevated blink rate; neutralized emotions showed a decreased blink rate. Negative emotions were more difficult to falsify than happiness. Although untrained observers performed only slightly above chance at detecting deception, inconsistent emotional leakage occurred in 100\% of participants at least once and lasted longer than the current definition of a microexpression suggests. Microexpressions were exhibited by 21.95\% of participants in 2\% of all expressions, and in the upper or lower face only.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Potmesil1987,
	title        = {{Generating octree models of {3D} objects from their silhouettes in a sequence of images}},
	author       = {Potmesil, Michael},
	year         = 1987,
	month        = {\#mar\#},
	journal      = {Computer Vision, Graphics, and Image Processing},
	volume       = 37,
	number       = 3,
	pages        = 438,
	keywords     = {litsurvey.bib}
}

@article{Potter_van_Loon2015,
	title        = {Beyond chance? The persistence of performance in online poker},
	author       = {Potter van Loon, Rogier J D and van den Assem, Martijn J and van Dolder, Dennie},
	year         = 2015,
	month        = {\#mar\#},
	journal      = {PLoS One},
	publisher    = {Public Library of Science},
	volume       = 10,
	number       = 3,
	pages        = {e0115479},
	abstract     = {A major issue in the widespread controversy about the legality of poker and the appropriate taxation of winnings is whether poker should be considered a game of skill or a game of chance. To inform this debate we present an analysis into the role of skill in the performance of online poker players, using a large database with hundreds of millions of player-hand observations from real money ring games at three different stakes levels. We find that players whose earlier profitability was in the top (bottom) deciles perform better (worse) and are substantially more likely to end up in the top (bottom) performance deciles of the following time period. Regression analyses of performance on historical performance and other skill-related proxies provide further evidence for persistence and predictability. Simulations point out that skill dominates chance when performance is measured over 1,500 or more hands of play.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Poullis2007,
	title        = {{Generating {High-Resolution} Textures for {3D} Virtual Environments using {View-Independent} Texture Mapping}},
	author       = {Poullis, C and You, S and Neumann, U},
	year         = 2007,
	month        = {\#jul\#},
	booktitle    = {2007 {IEEE} International Conference on Multimedia and Expo},
	address      = {Beijing},
	pages        = {1295--1298},
	abstract     = {Image based modeling and rendering techniques have become increasingly popular for creating and visualizing 3D models from a set of images. Typically, these techniques depend on view-dependent texture mapping to render the textured 3D models in which the texture of novel views is synthesized at runtime according to different view-points. This is computationally expensive and limits their application in domains where efficient computations are required, such as games and virtual reality. In this paper we present an offline technique for creating view-independent texture atlases for 3D models, given a set of registered images. The best texture map resolution is computed by considering the areas of the projected polygons in the images. Texture maps are generated by a weighted composition of all available image information in the scene.Assuming that all surfaces of the model are exhibiting Lambertian reflectance properties, ray-tracing is then employed, for creating the view-independent texture maps. Finally, all the generated texture maps are packed into texture atlases. The result is a 3D model with an associated view-independent texture atlas which can be used efficiently in any application without any knowledge of camera pose information.},
	keywords     = {image texture;ray tracing;rendering (computer graphics);virtual reality;high-resolution textures;3D virtual environments;view-independent texture mapping;image based modeling;rendering;games;virtual reality;3D models;texture map resolution;image information;Lambertian reflectance properties;ray tracing;Virtual environment;Rendering (computer graphics);Visualization;Runtime;Virtual reality;Image resolution;Surface texture;Reflectivity;Ray tracing;Cameras;litsurvey.bib}
}

@unpublished{ProjectionMappingCentral_undated-dj,
	title        = {History of projection mapping},
	author       = {{ProjectionMappingCentral}},
	keywords     = {litsurvey.bib}
}

@inproceedings{Qing-xi2009,
	title        = {An Easy System of Spatial Points Collection Based On {ARtoolKit}},
	author       = {Qing-xi, H and Tao, L and Yuan, Y},
	year         = 2009,
	month        = {\#mar\#},
	booktitle    = {2009 {WRI} World Congress on Computer Science and Information Engineering},
	volume       = 1,
	pages        = {582--586},
	abstract     = {In this paper, we propose and develop an interactive system based on ARtoolKit, which can be employed to pick up points in spatial environment. This system is composed of four parts: Detection Pen (DP), single marker, webcam and computer. It is tracked using markers and the system translates the center position of DPpsila s leading marker to the location of pen-point within the webcam coordinate system. Therefore, the positions in physical world can be detected by acquiring the pen-point coordinate within the single marker coordinate system. As the markers-based image segmentation for a small region is swift, the process is a real-time. The experimental result indicates that it is able to pick-up points steadily. In addition, the system is easy and quite convenient to operate. So it has good potential in 3D interaction design.},
	keywords     = {biology computing;computers;image segmentation;medical image processing;spatial points collection;ARtoolKit;detection pen;computer;webcam coordinate system;pen-point coordinate;single marker coordinate system;marker-based image segmentation;3D interaction design;Bones;Surgery;Interactive systems;Costs;Computer science;Systems engineering and theory;Computer aided manufacturing;Pulp manufacturing;Image segmentation;Focusing;Augmented Reality;3D design;interactive;ARtoolKit;litsurvey.bib}
}

@inproceedings{Radovan2006,
	title        = {Facial animation in a nutshell: past, present and future},
	author       = {Radovan, Mauricio and Pretorius, Laurette},
	year         = 2006,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 2006 annual research conference of the South African institute of computer scientists and information technologists on {IT} research in developing countries},
	location     = {Somerset West, South Africa},
	publisher    = {South African Institute for Computer Scientists and Information Technologists},
	address      = {ZAF},
	series       = {SAICSIT '06},
	pages        = {71--79},
	institution  = {South African Institute for Computer Scientists and Information Technologists},
	keywords     = {HCI, animation, computer graphics;litsurvey.bib}
}

@inproceedings{Rae2013,
	title        = {In-body experiences: embodiment, control, and trust in robot-mediated communication},
	author       = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {1921--1930},
	institution  = {ACM},
	keywords     = {computer-mediated communication, videoconferencing, robot-mediated communication, control, trust, embodiment, computer-supported collaborative work;litsurvey.bib}
}

@inproceedings{Rae2012,
	title        = {One of the gang: supporting in-group behavior for embodied mediated communication},
	author       = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {3091--3100},
	institution  = {ACM},
	keywords     = {in-group behavior, embodied mediated communication, remote presence;litsurvey.bib}
}

@article{Rae2001,
	title        = {Organizing Participation in Interaction: Doing Participation Framework},
	author       = {Rae, John},
	year         = 2001,
	month        = {\#apr\#},
	journal      = {Research on Language and Social Interaction},
	publisher    = {Routledge},
	volume       = 34,
	number       = 2,
	pages        = {253--278},
	abstract     = {Goffman (1981) introduced the terms participation status and participation framework to differentiate how people involved in an interactional setting participate in that setting. In this article, I examine a particular work context in which participants in an interaction reorganize their participation such that, although remaining physically copresent, one of them makes or receives telephone calls to or from a non-copresent party. I show how this is a major site of body movement, including synchronous postural change (Kendon, 1990) before and after the call, and I examine the participants' vocal and nonvocal resources for entry into involvement with the phone call. Examination of these resources leads to a critical assessment of the concept of participation frameworks.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Ramanathan2000,
	title        = {{Silhouette-Based} {Multiple-View} Camera Calibration},
	author       = {Ramanathan, Prashant and Steinbach, Eckehard G and Girod, Bernd},
	year         = 2000,
	booktitle    = {{VMV}},
	pages        = {3--10},
	keywords     = {litsurvey.bib}
}

@article{Ramesh2004,
	title        = {{Research in computer science: an empirical study}},
	author       = {Ramesh, V and Glass, Robert L and Vessey, Iris},
	year         = 2004,
	month        = {\#feb\#},
	journal      = {J. Syst. Softw.},
	volume       = 70,
	number       = 1,
	pages        = {165--176},
	abstract     = {In this paper, we examine the state of computer science (CS) research from the point of view of the following research questions:1.What topics do CS researchers address?2.What research approaches do CS researchers use?3.What research methods do CS researchers use?4.On what reference disciplines does CS research depend?5.At what levels of analysis do CS researchers conduct research? To answer these questions, we examined 628 papers published between 1995 and 1999 in 13 leading research journals in the CS field. Our results suggest that while CS research examines a variety of technical topics it is relatively focused in terms of the level at which research is conducted as well as the research techniques used. Further, CS research seldom relies on work outside the discipline for its theoretical foundations. We present our findings as an evaluation of the state of current research and as groundwork for future CS research efforts.},
	keywords     = {Topic=Computing research; Research Approach=Evaluative-Other; Research Method=Literature analysis; Reference Discipline=Not applicable; Level of Analysis=Profession;litsurvey.bib}
}

@inproceedings{Ranjan2007,
	title        = {Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task},
	author       = {Ranjan, Abhishek and Birnholtz, Jeremy P and Balakrishnan, Ravin},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1177--1186},
	institution  = {ACM},
	keywords     = {camera control, empirical studies, video mediated communication, video conferencing, computer-supported cooperative work, collaboration, motion tracking;litsurvey.bib}
}

@inproceedings{Rappoport1997,
	title        = {{Interactive Boolean operations for conceptual design of {3-D} solids}},
	author       = {Rappoport, Ari and Spitz, Steven},
	year         = 1997,
	month        = {\#aug\#},
	booktitle    = {Proceedings of the 24th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM Press/Addison-Wesley Publishing Co.},
	address      = {USA},
	series       = {SIGGRAPH '97},
	pages        = {269--278},
	keywords     = {solid modeling, convex differences aggregate, geometric modeling, Boolean operations, convex differences, convex polyhedra, conceptual design;litsurvey.bib}
}

@inproceedings{Raskar1998,
	title        = {The office of the future: A unified approach to image-based modeling and spatially immersive displays},
	author       = {Raskar, Ramesh and Welch, Greg and Cutts, Matt and Lake, Adam and Stesin, Lev and Fuchs, Henry},
	year         = 1998,
	booktitle    = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
	pages        = {179--188}
}

@incollection{Raskar2001,
	title        = {Shader Lamps: Animating Real Objects With {Image-Based} Illumination: Proceedings of the Eurographics Workshop in London, United Kingdom, June 25--27, 2001},
	author       = {Raskar, Ramesh and Welch, Greg and Low, Kok-Lim and Bandyopadhyay, Deepak},
	year         = 2001,
	booktitle    = {Rendering Techniques 2001},
	publisher    = {Springer Vienna},
	address      = {Vienna},
	series       = {Eurographics},
	volume       = 20,
	pages        = {89--102},
	editor       = {Gortler, Steven J and Myszkowski, Karol},
	keywords     = {litsurvey.bib}
}

@inproceedings{Raskar2001,
	title        = {Shader lamps},
	author       = {Raskar, Ramesh and Welch, Greg and Low, Kok-Lim and Bandyopadhyay, Deepak},
	year         = 2001,
	booktitle    = {Proc. Eurographics Workshop on Rendering},
	keywords     = {litsurvey.bib}
}

@article{Reflecmedia_undated,
	title        = {Reflecmedia Chromatte information},
	author       = {{Reflecmedia}},
	keywords     = {litsurvey.bib}
}

@article{Regenbrecht2015,
	title        = {Mutual Gaze Support in Videoconferencing Reviewed},
	author       = {Regenbrecht, Holger and Langlotz, Tobias},
	year         = 2015,
	journal      = {Communications of the Association for Information Systems},
	volume       = 37,
	number       = 1,
	pages        = 45,
	abstract     = {Videoconferencing allows geographically dispersed parties to communicate by simultaneous audio and video transmissions. It is used in a variety of application scenarios with a wide range of coordination needs and efforts, such as private chat, discussion meetings, and negotiation tasks. In particular, in scenarios requiring certain levels of trust and judgement non-verbal communication, cues are highly important for effective communication. Mutual gaze support plays a central role in those high coordination need scenarios but generally lacks adequate technical support from videoconferencing systems. In this paper, we review technical concepts and implementations for mutual gaze support in videoconferencing, classify them, evaluate them according to a defined set of criteria, and give recommendations for future developments. Our review gives decision makers, researchers, and developers a tool to systematically apply and further develop videoconferencing systems in ``serious'' settings requiring mutual gaze. This should lead to well-informed decisions regarding the use and development of this technology and to a more widespread exploitation of the benefits of videoconferencing in general. For example, if videoconferencing systems supported high-quality mutual gaze in an easy-to-set-up and easy-to-use way, we could hold more effective and efficient recruitment interviews, court hearings, or contract negotiations.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Regenbrecht2002,
	title        = {{Interaction in a collaborative augmented reality environment}},
	author       = {Regenbrecht, Holger T and Wagner, Michael T},
	year         = 2002,
	month        = {\#apr\#},
	booktitle    = {{CHI} '02 Extended Abstracts on Human Factors in Computing Systems},
	location     = {Minneapolis, Minnesota, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI EA '02},
	pages        = {504--505},
	keywords     = {augmented reality, collaboration, cscw, tangible user; 3DUI; tangible user interfaces;litsurvey.bib}
}

@inproceedings{Reitmaier2013,
	title        = {Designing and theorizing co-located interactions},
	author       = {Reitmaier, Thomas and Benz, Pierre and Marsden, Gary},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {381--390},
	institution  = {ACM},
	keywords     = {co-located interaction, design research, theory, co-presence;litsurvey.bib}
}

@article{Remondino2006,
	title        = {Image-based {3D} Modelling: A Review},
	author       = {Remondino, Fabio and El-Hakim, Sabry},
	year         = 2006,
	month        = {\#aug\#},
	journal      = {The Photogrammetric Record},
	publisher    = {Wiley Online Library},
	volume       = 21,
	number       = 115,
	pages        = {269--291},
	abstract     = {Abstract In this paper the main problems and the available solutions are addressed for the generation of 3D models from terrestrial images. Close range photogrammetry has dealt for many years with manual or automatic image measurements for precise 3D modelling. Nowadays 3D scanners are also becoming a standard source for input data in many application areas, but image-based modelling still remains the most complete, economical, portable, flexible and widely used approach. In this paper the full pipeline is presented for 3D modelling from terrestrial image data, considering the different approaches and analysing all the steps involved.},
	keywords     = {litsurvey.bib}
}

@unpublished{Rienks2010,
	title        = {Differences in head orientation behavior for speakers and listeners: An experiment in a virtual environment},
	author       = {Rienks, Rutger and Poppe, Ronald and Heylen, Dirk},
	year         = 2010,
	month        = {\#jan\#},
	number       = {Article 2},
	keywords     = {perception of gaze, virtual environments, gaze behavior, focus of attention, multiparty conversation, Head orientation;litsurvey.bib}
}

@article{Risko2011,
	title        = {Eyes wide shut: implied social presence, eye tracking and attention},
	author       = {Risko, Evan F and Kingstone, Alan},
	year         = 2011,
	month        = {\#feb\#},
	journal      = {Atten. Percept. Psychophys.},
	publisher    = {Springer},
	volume       = 73,
	number       = 2,
	pages        = {291--296},
	abstract     = {People often behave differently when they know they are being watched. Here, we report the first investigation of whether such social presence effects also influence looking behavior--a popular measure of attention allocation. We demonstrate that wearing an eye tracker, an implied social presence, leads individuals to avoid looking at particular stimuli. These results demonstrate that an implied social presence, here an eye tracker, can alter looking behavior. These data provide a new manipulation of social attention, as well as presenting a methodological challenge to researchers using eye tracking.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Rittenbruch2015,
	title        = {Supporting Collaboration on Very {Large-Scale} Interactive Wall Surfaces},
	author       = {Rittenbruch, Markus},
	year         = 2015,
	month        = {\#jun\#},
	journal      = {Comput. Support. Coop. Work},
	publisher    = {Springer},
	volume       = 24,
	number       = 2,
	pages        = {121--147},
	abstract     = {In this paper we describe CubIT, a multi-user presentation and collaboration system installed at the Queensland University of Technology's (QUT) Cube facility. The `Cube' is an interactive visualisation facility made up of five very large-scale interactive multi-panel wall displays, each consisting of up to twelve 55-inch multi-touch screens (48 screens in total) and massive projected display screens situated above the display panels. The paper outlines the unique design challenges, features, implementation and evaluation of CubIT. The system was built to make the Cube facility accessible to QUT's academic and student population. CubIT enables users to easily upload and share their own media content, and allows multiple users to simultaneously interact with the Cube's wall displays. The features of CubIT are implemented via three user interfaces, a multi-touch interface working on the wall displays, a mobile phone and tablet application and a web-based content management system. Each of these interfaces offers different interaction mechanisms. Together they support a wide range of collaborative features including multi-user shared workspaces, drag and drop upload and sharing between users, session management and dynamic state control between different parts of the system. The results of our evaluation study showed that CubIT was successfully used for a variety of tasks, but also highlighted specific challenges with regards to user expectations as well as issues arising from public use.},
	keywords     = {litsurvey.bib}
}

@article{Rivera-Gutierrez2012,
	title        = {Shader Lamps Virtual Patients: the physical manifestation of virtual patients},
	author       = {Rivera-Gutierrez, Diego and Welch, Greg and Lincoln, Peter and Whitton, Mary and Cendan, Juan and Chesnutt, David A and Fuchs, Henry and Lok, Benjamin},
	year         = 2012,
	journal      = {Stud. Health Technol. Inform.},
	volume       = 173,
	pages        = {372--378},
	abstract     = {We introduce the notion of Shader Lamps Virtual Patients (SLVP) - the combination of projector-based Shader Lamps Avatars and interactive virtual humans. This paradigm uses Shader Lamps Avatars technology to give a 3D physical presence to conversational virtual humans, improving their social interactivity and enabling them to share the physical space with the user. The paradigm scales naturally to multiple viewers, allowing for scenarios where an instructor and multiple students are involved in the training. We have developed a physical-virtual patient for medical students to conduct ophthalmic exams, in an interactive training experience. In this experience, the trainee practices multiple skills simultaneously, including using a surrogate optical instrument in front of a physical head, conversing with the patient about his fears, observing realistic head motion, and practicing patient safety. Here we present a prototype system and results from a preliminary formative evaluation of the system.},
	keywords     = {Clinical Competence, Computer Simulation, Diagnostic Techniques, Ophthalmological, Humans, Imaging, Three-Dimensional, Patients, User-Computer Interface;litsurvey.bib},
	language     = {en}
}

@article{Roberts2009,
	title        = {{Talking with the Furniture}},
	author       = {Roberts, David},
	year         = 2009,
	abstract     = {Telethrone paper},
	keywords     = {litsurvey.bib}
}

@inproceedings{Roberts2005,
	title        = {Reducing Fragmentation in Telecollaboration by Using {IPT} Interfaces},
	author       = {Roberts, D and Al-Liabi, M and Wolff, R and Otto, O and Al-Khalifah, A},
	year         = 2005,
	booktitle    = {{IPT/EGVE}},
	pages        = {211--216},
	institution  = {Eurographics Association},
	keywords     = {litsurvey.bib}
}

@inproceedings{Roberts2009,
	title        = {Comparing the End to End Latency of an Immersive Collaborative Environment and a Video Conference},
	author       = {Roberts, D and Duckworth, T and Moore, C and Wolff, R and O'Hare, J},
	year         = 2009,
	month        = {\#oct\#},
	booktitle    = {2009 13th {IEEE/ACM} International Symposium on Distributed Simulation and Real Time Applications},
	pages        = {89--94},
	abstract     = {Latency in a communication system can result in confusing a conversation through loss of causality as people exchange verbal and non-verbal nuances. This paper compares true end-to-end latencies across an immersive virtual environment and a video conference link using the same approach to measure both. Our approach is to measure end-to-end latency through filming the movements of a participant and their remote representation through synchronised cameras. We also compare contemporary and traditional immersive display and capture devices, whilst also measuring event latency taken from log files. We compare an immersive collaborative virtual environment to a video conference as both attempt to reproduce different aspects of the face-to- face meeting, the former favouring appearance and the latter attention. Results inform not only the designers of both approaches but also set the requirements for future developments for 3D video which has the potential to faithfully reproduce both appearance and attention.},
	institution  = {IEEE Computer Society},
	keywords     = {teleconferencing;video communication;virtual reality;end to end latency;immersive collaborative environment;video conference;immersive virtual environment;synchronised cameras;immersive display devices;capture devices;event latency;log files;face-to-face meeting;Delay;Collaboration;Videoconference;Virtual environment;Cameras;Virtual reality;Analytical models;Aerospace simulation;Computational modeling;Computer displays;David Roberts;Toby Duckworth;Carl Moore;Robin Wolff and John O'Hare;litsurvey.bib}
}

@article{Roberts2003,
	title        = {Constructing a Gazebo: Supporting Teamwork in a Tightly Coupled, Distributed Task in Virtual Reality},
	author       = {Roberts, David and Wolff, Robin and Otto, Oliver and Steed, Anthony},
	year         = 2003,
	month        = {\#dec\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 12,
	number       = 6,
	pages        = {644--657},
	abstract     = {Many tasks require teamwork. Team members may work concurrently, but there must be some occasions of coming together. Collaborative virtual environments (CVEs) allow distributed teams to come together across distance to share a task. Studies of CVE systems have tended to focus on the sense of presence or copresence with other people. They have avoided studying close interaction between us-ers, such as the shared manipulation of objects, because CVEs suffer from inherent network delays and often have cumbersome user interfaces. Little is known about the ef-fectiveness of collaboration in tasks requiring various forms of object sharing and, in particular, the concurrent manipu-lation of objects. This paper investigates the effectiveness of supporting teamwork among a geographically distributed group in a task that requires the shared manipulation of objects. To complete the task, users must share objects through con-current manipulation of both the same and distinct at-tributes. The effectiveness of teamwork is measured in terms of time taken to achieve each step, as well as the impression of users. The effect of interface is examined by comparing various combinations of walk-in cubic immersive projection technology (IPT) displays and desktop devices.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Roberts2009,
	title        = {Communicating Eye-gaze Across a Distance: Comparing an Eye-gaze enabled Immersive Collaborative Virtual Environment, Aligned Video Conferencing, and Being Together},
	author       = {Roberts, D and Wolff, R and Rae, J and Steed, A and Aspin, R and McIntyre, M and Pena, A and Oyekoya, O and Steptoe, W},
	year         = 2009,
	month        = {\#mar\#},
	booktitle    = {2009 {IEEE} Virtual Reality Conference},
	pages        = {135--142},
	abstract     = {Eye gaze is an important and widely studied non-verbal resource in co-located social interaction. When we attempt to support tele-presence between people, there are two main technologies that can be used today: video-conferencing (VC) and collaborative virtual environments (CVEs). In VC, one can observe eye-gaze behaviour but practically the targets of eye-gaze are only correct if the participants remain relatively still. We attempt to support eye-gaze behaviour in an unconstrained manner by integrating eye-trackers into an Immersive CVE (ICVE) system. This paper aims to show that while both ICVE and VC allow people to discern being looked at and what else is looked at, when someone gazes into their space from another location, ICVE alone can continue to do this as people move. The conditions of aligned VC, ICVE, eye-gaze enabled ICVE and co-location are compared. The impact of factors of alignment, lighting, resolution, and perspective distortion are minimised through a set of pilot experiments, before a formal experiment records results for optimal settings. Results show that both VC and ICVE support eye-gaze in constrained situations, but only ICVE supports movement of the observer. We quantify the mis-judgements that are made and discuss how our findings might inform research into supporting eye-gaze through interpolated free viewpoint video based methods.},
	institution  = {IEEE},
	keywords     = {groupware;teleconferencing;video communication;virtual reality;eye-gaze enabled immersive collaborative virtual environment;video conferencing;nonverbal resource;colocated social interaction;telepresence;eye-trackers;Collaboration;Virtual environment;Videoconference;Virtual colonoscopy;Cameras;Avatars;Computer graphics;Displays;Video sharing;Head;Immersive Collaborative Virtual Environments;Eye-Tracking;Gaze-Tracking;Video Conferencing;Tele-presence;H.5.1 [Communications Applications]: Computer conferencing, teleconferencing, and videoconferencing;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism: Virtual Reality;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism: Animation;litsurvey.bib}
}

@article{Roberts2015,
	title        = {withyou---An Experimental {End-to-End} Telepresence System Using {Video-Based} Reconstruction},
	author       = {Roberts, D J and Fairchild, A J and Campion, S P and O'Hare, J and Moore, C M and Aspin, R and Duckworth, T and Gasparello, P and Tecchia, F},
	year         = 2015,
	month        = {\#apr\#},
	journal      = {IEEE J. Sel. Top. Signal Process.},
	publisher    = {IEEE},
	volume       = 9,
	number       = 3,
	pages        = {562--574},
	abstract     = {Supporting a wide set of linked non-verbal resources remains an evergreen challenge for communication technology, limiting effectiveness in many applications. Interpersonal distance, gaze, posture and facial expression, are interpreted together to manage and add meaning to most conversations. Yet today's technologies favor some above others. This induces confusion in conversations, and is believed to limit both feelings of togetherness and trust, and growth of empathy and rapport. Solving this problem will allow technologies to support most rather than a few interactional scenarios. It is likely to benefit teamwork and team cohesion, distributed decision-making and health and wellbeing applications such as tele-therapy, tele-consultation, and isolation. We introduce withyou, our telepresence research platform. This paper describes the end-to-end system including the psychology of human interaction and how this drives requirements throughout the design and implementation. Our technology approach is to combine the winning characteristics of video conferencing and immersive collaborative virtual environments. This is to allow, for example, people walking past each other to exchange a glance and smile. A systematic explanation of the theory brings together the linked nature of non-verbal communication and how it is influenced by technology. This leads to functional requirements for telepresence, in terms of the balance of visual, spatial and temporal qualities. The first end-to-end description of withyou describes all major processes and the display and capture environment. An unprecedented characterization of our approach is given in terms of the above qualities and what influences them. This leads to non-functional requirements in terms of number and place of cameras and the avoidance of resultant bottlenecks. Proposals are given for improved distribution of processes across networks, computers, and multi-core CPU and GPU. Simple conservative estimation shows that both approaches should meet our requirements. One is implemented and shown to meet minimum and come close to desirable requirements.},
	keywords     = {groupware;teleconferencing;virtual reality;end-to-end telepresence system;video-based reconstruction;human interaction psychology;video conferencing;immersive collaborative virtual environments;nonverbal communication;functional requirements;temporal qualities;spatial qualities;visual qualities;resultant bottlenecks;withyou;Visualization;Avatars;Cameras;Three-dimensional displays;Context;Image reconstruction;Collaboration;Computer supported cooperative working;computer vision;virtual reality;litsurvey.bib}
}

@article{Roberts2013,
	title        = {Estimating the gaze of a virtuality human},
	author       = {Roberts, David J and Rae, John and Duckworth, Tobias W and Moore, Carl M and Aspin, Rob},
	year         = 2013,
	month        = {\#apr\#},
	journal      = {IEEE Trans. Vis. Comput. Graph.},
	publisher    = {IEEE},
	volume       = 19,
	number       = 4,
	pages        = {681--690},
	abstract     = {The aim of our experiment is to determine if eye-gaze can be estimated from a virtuality human: to within the accuracies that underpin social interaction; and reliably across gaze poses and camera arrangements likely in every day settings. The scene is set by explaining why Immersive Virtuality Telepresence has the potential to meet the grand challenge of faithfully communicating both the appearance and the focus of attention of a remote human participant within a shared 3D computer-supported context. Within the experiment n=22 participants rotated static 3D virtuality humans, reconstructed from surround images, until they felt most looked at. The dependent variable was absolute angular error, which was compared to that underpinning social gaze behaviour in the natural world. Independent variables were 1) relative orientations of eye, head and body of captured subject; and 2) subset of cameras used to texture the form. Analysis looked for statistical and practical significance and qualitative corroborating evidence. The analysed results tell us much about the importance and detail of the relationship between gaze pose, method of video based reconstruction, and camera arrangement. They tell us that virtuality can reproduce gaze to an accuracy useful in social interaction, but with the adopted method of Video Based Reconstruction, this is highly dependent on combination of gaze pose and camera arrangement. This suggests changes in the VBR approach in order to allow more flexible camera arrangements. The work is of interest to those wanting to support expressive meetings that are both socially and spatially situated, and particular those using or building Immersive Virtuality Telepresence to accomplish this. It is also of relevance to the use of virtuality humans in applications ranging from the study of human interactions to gaming and the crossing of the stage line in films and TV.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Roberts2012,
	title        = {Supporting a Closely Coupled Task between a Distributed Team: Using Immersive Virtual Reality Technology},
	author       = {Roberts, David J and Wolff, Robin and Otto, Oliver},
	year         = 2012,
	month        = {\#mar\#},
	journal      = {Comput. Inform.},
	volume       = 24,
	number       = 1,
	pages        = {7--29},
	abstract     = {Collaboration and teamwork is important in many areas of our lives. People come together to share and discuss ideas, split and distribute work or help and support each other. The sharing of information and artefacts is a central part of collaboration. This often involves the manipulation of shared objects, both sequentially as well as concurrently. For coordinating an efficient collaboration, communication between the team members is necessary. This can happen verbally in form of speech or text and non-verbally through gesturing, pointing, gaze or facial expressions and the referencing and manipulation of shared objects. Collaborative Virtual Environments (CVE) allow remote users to come together and interact with each other and virtual objects within a computer simulated environment. Immersive display interfaces, such as a walk-in display (e.g. CAVE), that place a human physically into the synthetic environment, lend themselves well to support a natural manipulation of objects as well a set of natural non-verbal human communication, as they can both capture and display human movement. Communication of tracking data, however, can saturate the network and result in delay or loss of messages vital to the manipulation of shared objects. This paper investigates the reality of shared object manipulation between remote users collaborating through linked walk-in displays and extends our research in [27]. Various forms of shared interaction are examined through a set of structured sub tasks within a representative construction task. We report on extensive user-trials between three walk-in displays in the UK and Austria linked over the Internet using a CVE, and demonstrate such effects on a naive implementation of a benchmark application, the Gazebo building task. We then present and evaluate application-level workarounds and conclude by suggesting solutions that may be implemented within next-generation CVE infrastructures.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Robinson2002,
	title        = {Data mining information visualisation-beyond charts and graphs},
	author       = {Robinson, Nigel and Shapcott, Mary},
	year         = 2002,
	booktitle    = {Proceedings Sixth International Conference on Information Visualisation},
	pages        = {577--583},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/01028832.pdf:PDF}
}

@inproceedings{Romano2001,
	title        = {Meeting analysis: findings from research and practice},
	author       = {Romano, N C and Nunamaker, J F},
	year         = 2001,
	month        = {\#jan\#},
	booktitle    = {Proceedings of the 34th Annual Hawaii International Conference on System Sciences},
	pages        = {13 pp.--},
	abstract     = {Meeting analysis, that is the study of meeting expenses, productivity, processes, and outcomes, is relevant to GSS practice and research for several reasons. Many reviews and surveys reveal that meetings dominate workers' and managers' time and yet are considered to be costly, unproductive and dissatisfying. Studies show that meetings are essential and that the number of meetings and their duration has been steadily increasing. Studies of managers and knowledge workers reveal that they spend between 25\%-80\% of their time in meetings, suggesting that meetings are an important part of one's working life. Estimates of meeting expenses range from costs of $30 million to over 100 million per year to losses between $54 million and 3.7 billion annually! Self estimates of meeting productivity by managers in many different functional areas range from 33\%-47\%.},
	institution  = {IEEE},
	keywords     = {group decision support systems;meeting analysis;meeting expenses;productivity;GSS practice;knowledge workers;meeting productivity;group support systems;Productivity;Meeting planning;Teleworking;Business communication;Educational institutions;Information management;Knowledge management;Costs;Collaboration;Design methodology;litsurvey.bib}
}

@misc{Rosenthal1947,
	title        = {Two-way television communication unit},
	author       = {Rosenthal, Adolph H},
	year         = 1947,
	publisher    = {Google Patents},
	keywords     = {litsurvey.bib}
}

@article{Rovira2009,
	title        = {{The Use of Virtual Reality in the Study of People's Responses to Violent Incidents}},
	author       = {Rovira, Aitor and Swapp, David and Spanlang, Bernhard and Slater, Mel},
	year         = 2009,
	month        = {\#dec\#},
	journal      = {Front. Behav. Neurosci.},
	publisher    = {Frontiers Research Foundation},
	volume       = 3,
	number       = {December},
	pages        = 59,
	abstract     = {This paper reviews experimental methods for the study of the responses of people to violence in digital media, and in particular considers the issues of internal validity and ecological validity or generalisability of results to events in the real world. Experimental methods typically involve a significant level of abstraction from reality, with participants required to carry out tasks that are far removed from violence in real life, and hence their ecological validity is questionable. On the other hand studies based on field data, while having ecological validity, cannot control multiple confounding variables that may have an impact on observed results, so that their internal validity is questionable. It is argued that immersive virtual reality may provide a unification of these two approaches. Since people tend to respond realistically to situations and events that occur in virtual reality, and since virtual reality simulations can be completely controlled for experimental purposes, studies of responses to violence within virtual reality are likely to have both ecological and internal validity. This depends on a property that we call 'plausibility' - including the fidelity of the depicted situation with prior knowledge and expectations. We illustrate this with data from a previously published experiment, a virtual reprise of Stanley Milgram's 1960s obedience experiment, and also with pilot data from a new study being developed that looks at bystander responses to violent incidents.},
	keywords     = {bystander, obedience, presence, stanley milgram, violence, virtual reality;litsurvey.bib},
	language     = {en}
}

@inproceedings{Rusinkiewicz2002,
	title        = {{Real-time {3D} model acquisition}},
	author       = {Rusinkiewicz, Szymon and Hall-Holt, Olaf and Levoy, Marc},
	year         = 2002,
	booktitle    = {Proceedings of the 29th annual conference on Computer graphics and interactive techniques - {SIGGRAPH} '02},
	location     = {San Antonio, Texas},
	publisher    = {ACM Press},
	address      = {New York, New York, USA},
	pages        = 438,
	conference   = {the 29th annual conference},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sadagic2001,
	title        = {Tele-immersion portal: Towards an ultimate synthesis of computer graphics and computer vision systems},
	author       = {Sadagic, Amela and Towles, Herman and Holden, Loring and Daniilidis, Kostas and Zeleznik, Bob},
	year         = 2001,
	booktitle    = {4th Annual International Workshop on Presence},
	pages        = {21--23},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sakamoto2007,
	title        = {Android as a telecommunication medium with a human-like presence},
	author       = {Sakamoto, Daisuke and Kanda, Takayuki and Ono, Tetsuo and Ishiguro, Hiroshi and Hagita, Norihiro},
	year         = 2007,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the {ACM/IEEE} international conference on Human-robot interaction},
	location     = {Arlington, Virginia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {HRI '07},
	pages        = {193--200},
	institution  = {IEEE},
	keywords     = {android science, telepresence, telecommunication, humanoid robot;litsurvey.bib}
}

@misc{salinCosts,
	title        = {Costs and Computers},
	author       = {Salin, Phil},
	year         = 1991,
	url          = {http://cdn.oreillystatic.com/radar/r1/11-91.pdf},
	owner        = {its352},
	timestamp    = {2021.12.02}
}

@article{sangster2015earliest,
	title        = {The earliest known treatise on double entry bookkeeping by Marino de Raphaeli},
	author       = {Sangster, Alan},
	year         = 2015,
	journal      = {Accounting Historians Journal},
	publisher    = {American Accounting Association},
	volume       = 42,
	number       = 2,
	pages        = {1--33}
}

@inproceedings{Sassa2019,
	title        = {3D Visualization of Network Including Nodes with Labels},
	author       = {Sassa, Hinako and Itoh, Takayuki and Toyoda, Mitsuo},
	year         = 2019,
	booktitle    = {2019 23rd International Conference Information Visualisation (IV)},
	pages        = {19--24},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08812066.pdf:PDF}
}

@article{Sauer2016,
	title        = {The Structure of Interaction at Meetings: A Social Network Analysis},
	author       = {Sauer, Nils Christian and Kauffeld, Simone},
	year         = 2016,
	month        = {\#jan\#},
	journal      = {Zeitschrift f{\"u}r Arbeits- und Organisationspsychologie A\&O},
	publisher    = {Hogrefe Verlag},
	volume       = 60,
	number       = 1,
	pages        = {33--49},
	abstract     = {Abstract. Which factors contribute to effective meetings? The interaction among participants plays a key role. Interaction is a relational, interdependent process that constitutes social structure. Applying a network perspective to meeting interactions allows us to take account of the social structure. The aim of this study was to use social network analysis to distinguish functional and dysfunctional interaction structures and gain insight into the facilitation of meetings by analyzing antecedents and consequences of functional interaction structures. Data were based on a field study in which 51 regular meetings were videotaped and coded with act4teams. Analyses revealed that compared with dysfunctional networks, functional interaction is less centralized and has a positive effect on team performance. Social similarity has a crucial effect on functional interaction because participants significantly interact with others who are similar in personal initiative and self-efficacy. Our results provide important information about how to assist the interaction process and promote team success.},
	keywords     = {litsurvey.bib}
}

@article{Schegloff1998,
	title        = {Body torque},
	author       = {Schegloff, Emanuel A},
	year         = 1998,
	journal      = {Soc. Res.},
	publisher    = {JSTOR},
	pages        = {535--596},
	keywords     = {litsurvey.bib}
}

@inproceedings{schiano2004,
	title        = {Categorical imperative {NOT}: facial affect is perceived continuously},
	author       = {Schiano, Diane J and Ehrlich, Sheryl M and Sheridan, Kyle},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {49--56},
	institution  = {ACM},
	keywords     = {nonverbal communication, affective computing, naturalistic computing, face, video compression, avatars, VMC, facial affect, affect, emotion, facial expression of emotion;litsurvey.bib}
}

@inproceedings{Schrammel2007,
	title        = {``Look!'': using the gaze direction of embodied agents},
	author       = {Schrammel, Johann and Geven, Arjan and Sefelin, Reinhard and Tscheligi, Manfred},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1187--1190},
	institution  = {ACM},
	keywords     = {gaze direction, embodied agent, computer vision;litsurvey.bib}
}

@article{Schreer2001,
	title        = {Hybrid recursive matching and segmentation-based postprocessing in real-time immersive video conferencing},
	author       = {Schreer, Oliver and Brandenburg, Nicole and Askar, Serap and Kauff, Peter},
	year         = 2001,
	journal      = {Proceedings of VMV2001},
	publisher    = {researchgate.net},
	pages        = {383--390},
	abstract     = {We present a novel, real-time disparity analysis frame work developed for immersive teleconferencing. This two-stage method computes a limited number of highly reliable disparities in the first step and then, filling the remaining holes based on segmentation â€¦},
	keywords     = {litsurvey.bib}
}

@inproceedings{Schreer2008,
	title        = {{3D} presence - a system concept for multi-user and multi-party immersive {3D} video conferencing},
	author       = {Schreer, O and Feldmann, I and Atzpadin, N and Eisert, P and Kauff, P and Belt, H J W},
	year         = 2008,
	booktitle    = {{IET} 5th European Conference on Visual Media Production ({CVMP} 2008)},
	location     = {London, UK},
	publisher    = {IEE},
	pages        = {10--10},
	conference   = {IET 5th European Conference on Visual Media Production (CVMP 2008)},
	keywords     = {litsurvey.bib}
}

@incollection{Schreer2005,
	title        = {{Real-Time} Avatar Animation Steered by Live Body Motion},
	author       = {Schreer, Oliver and Tanger, Ralf and Eisert, Peter and Kauff, Peter and Kaspar, Bernhard and Englert, Roman},
	year         = 2005,
	booktitle    = {Image Analysis and Processing -- {ICIAP} 2005},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 3617,
	pages        = {147--154},
	editor       = {Roli, Fabio and Vitulano, Sergio},
	keywords     = {litsurvey.bib}
}

@article{Schroeder2001,
	title        = {Collaborating in networked immersive spaces: as good as being there together?},
	author       = {Schroeder, Ralph and Steed, Anthony and Axelsson, Ann-Sofie and Heldal, Ilona and Abelin, {\AA}sa and Widestr{\"o}m, Josef and Nilsson, Alexander and Slater, Mel},
	year         = 2001,
	month        = {\#oct\#},
	journal      = {Comput. Graph.},
	publisher    = {Elsevier},
	volume       = 25,
	number       = 5,
	pages        = {781--788},
	abstract     = {In this paper we present the results of a trial in which two participants collaborated on a puzzle-solving task in networked virtual environments. The task was a Rubik's cube type puzzle, and this meant that the two participants had to interact with the space and with each other very intensively---and they did this successfully despite the limitation of the networked situation. We compare collaboration in networked immersive projection technology (IPT's) systems with previous results concerning collaboration in an IPT system linked with a desktop computer, and also with collaboration on the same task in the real world. Our findings show that the task performance in networked IPT's and in the real scenario are very similar to each other---whereas IPT-to-desktop performance is much poorer. Results about participants' experience of `presence', `co-presence' and collaboration shed further light on these findings.},
	keywords     = {Virtual environments; Immersive projection technology systems; Collaboration; Presence; Co-presence;litsurvey.bib}
}

@article{Schuemie2001,
	title        = {Research on presence in virtual reality: a survey},
	author       = {Schuemie, M J and van der Straaten, P and Krijn, M and van der Mast, C A},
	year         = 2001,
	month        = {\#apr\#},
	journal      = {Cyberpsychol. Behav.},
	publisher    = {Mary Ann Liebert, Inc.},
	volume       = 4,
	number       = 2,
	pages        = {183--201},
	abstract     = {Virtual Reality (VR) is starting to be used in psychological therapy around the world. However, a thorough understanding of the reason why VR is effective and what effect it has on the human psyche is still missing. Most research on this subject is related to the concept of presence. This paper gives an up-to-date overview of research in this diverse field. It starts with the most prevailing definitions and theories on presence, most of which attribute special roles for the mental process of attention and for mental models of the virtual space. A review of the phenomena thought to be effected by presence shows that there is still a strong need for research on this subject because little conclusive evidence exists regarding the relationship between presence and phenoma such as emotional responses to virtual stimuli. An investigation shows there has been substantial research for developing methods for measuring presence and research regarding factors that contribute to presence. Knowledge of these contributing factors can play a vital role in development of new VR applications, but key knowledge elements in this area are still missing.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Schwartzman1986,
	title        = {The meeting as a neglected social form in organizational studies},
	author       = {Schwartzman, Helen B},
	year         = 1986,
	journal      = {Research in Organizational Behavior},
	publisher    = {JAI Press, Inc.},
	volume       = 8,
	pages        = {233--258},
	abstract     = {Discusses the use of meetings and the available studies of meetings that have been conducted by anthropologists, psychologists, sociologists, political scientists, business administrators, and others. It is argued that researchers have made meetings a tool of analysis, when they should have been the topic of investigation. A framework for a theory of meetings is presented, which sees meetings as rituals, social metaphors, and homeostats as prerequisite to the study of meetings in organizations. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	keywords     = {litsurvey.bib}
}

@article{Scott2012,
	title        = {Meetings at Work: Advancing the Theory and Practice of Meetings},
	author       = {Scott, Cliff W and Shanock, Linda Rhoades and Rogelberg, Steven G},
	year         = 2012,
	month        = {\#apr\#},
	journal      = {Small Group Research},
	publisher    = {SAGE Publications Inc},
	volume       = 43,
	number       = 2,
	pages        = {127--129},
	abstract     = {Although advances in communication technology were once expected to diminish the need for synchronous work meetings, meeting activity in organizations continues to rise. Regrettably, the time and energy employees spend in work meetings is not matched by the amount of direct attention group and organizational scholars have paid to meeting phenomena. This special issue of Small Group Research helps to address this gap by presenting empirical studies of work meetings that explore the theory and practice of work meetings.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sellen1992,
	title        = {{Using spatial cues to improve videoconferencing}},
	author       = {Sellen, Abigail and Buxton, Bill and Arnott, John},
	year         = 1992,
	month        = {\#jun\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Monterey, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '92},
	pages        = {651--652},
	keywords     = {litsurvey.bib}
}

@article{Sellen1995,
	title        = {Remote Conversations: The Effects of Mediating Talk With Technology},
	author       = {Sellen, Abigail J},
	year         = 1995,
	month        = {\#dec\#},
	journal      = {Human--Computer Interaction},
	publisher    = {Taylor \& Francis},
	volume       = 10,
	number       = 4,
	pages        = {401--444},
	abstract     = {Three different videoconferencing systems for supporting multiparty, remote conversations are described and evaluated experimentally. The three systems differed by how many participants were visible at once, their spatial arrangement, and control over who was seen. Conversations using these systems were compared to same-room (Experiment 1) and audio-only (Experiment 2) conversations. Specialized speech-tracking equipment recorded the on-off patterns of speech that allowed objective measurement of structural aspects of the conversations, such as turn length, pauses, and interruptions. Questionnaires and interviews also documented participants' opinions and perceptions in the various settings. Contrary to expectation, systems in which visual cues such as selective gaze were absent produced no differences in turn-taking or in any other aspect of the structure of conversation. In fact, turn-taking was unaffected even when visual information was completely absent. Overall, only the same-room condition showed any significant differences from any other condition; people in the same room produced more interruptions and fewer formal handovers of the floor than in any of the technology-mediated conditions. In this respect, the audio-only and video systems examined in these studies were equivalent. However, analyses of participants' perceptions showed that participants felt that visual access in mediated conversations was both important and beneficial in conversation. Further, there were indications that the particular design of the different video systems did affect some aspects of conversational behavior, such as the ability to hold side and parallel conversations.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sellen1992,
	title        = {Speech patterns in video-mediated conversations},
	author       = {Sellen, Abigail J},
	year         = 1992,
	month        = {\#jun\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Monterey, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '92},
	pages        = {49--59},
	institution  = {ACM},
	keywords     = {videoconferencing, conversation patterns, CSCW;litsurvey.bib}
}

@inproceedings{Sellis1987,
	title        = {{The {R+-Tree}: A Dynamic Index for {Multi-Dimensional} Objects}},
	author       = {Sellis, Timos K and Roussopoulos, Nick and Faloutsos, Christos},
	year         = 1987,
	booktitle    = {Proceedings of the 13th International Conference on Very Large Data Bases ({VLDB} '87)},
	publisher    = {Morgan Kaufmann Publishers Inc},
	address      = {Brighton},
	keywords     = {litsurvey.bib}
}

@article{Sermon2016,
	title        = {Over one hundred years of telepresence},
	author       = {Sermon, Paul},
	year         = 2016,
	publisher    = {Plymouth University},
	keywords     = {litsurvey.bib}
}

@article{Sermon2000,
	title        = {Telematic Dreaming},
	author       = {Sermon, Paul},
	year         = 2000,
	month        = {\#apr\#},
	journal      = {Leonardo},
	publisher    = {MIT Press},
	volume       = 33,
	number       = 2,
	pages        = {90--90},
	keywords     = {litsurvey.bib}
}

@article{Sermon2013,
	title        = {Occupy the screen},
	author       = {Sermon, Paul and Gould, Charlotte},
	year         = 2013,
	keywords     = {litsurvey.bib}
}

@article{Shahid2012,
	title        = {Video-mediated and co-present gameplay: Effects of mutual gaze on game experience, expressiveness and perceived social presence},
	author       = {Shahid, Suleman and Krahmer, Emiel and Swerts, Marc},
	year         = 2012,
	month        = {\#jul\#},
	journal      = {Interact. Comput.},
	publisher    = {Oxford Academic},
	volume       = 24,
	number       = 4,
	pages        = {292--305},
	abstract     = {Abstract. We study how pairs of children interact socially and express their emotions while playing games in different communicative settings. In particular, w},
	keywords     = {litsurvey.bib}
}

@book{Shaw2001,
	title        = {Proceedings of the [eighth Annual] {ACM} Symposium on Virtual Reality Software and Technology, {VRST} 2001, Banff, Alberta, Canada, 15-17.11.2001: Organized and Sponsored by {ACM} [et Al.]},
	author       = {Shaw, Chris and Wang, Wenping},
	year         = 2001,
	publisher    = {A.C.M.},
	address      = {New York, New York, USA},
	pages        = 93,
	keywords     = {augmented, diorama, immersive visualization, multiprojector display system, shader lamp, spatially-augmented reality, user, virtual environment, virtual reality, virtuality;litsurvey.bib},
	language     = {en}
}

@inproceedings{Shen2008,
	title        = {Multi-camera calibration using a globe},
	author       = {Shen, Rui and Cheng, Irene and Basu, Anup},
	year         = 2008,
	booktitle    = {8\textbackslashtextsuperscript{th} Workshop on Omnidirectional Vision, Camera Networks and Non-classical Cameras ({OMNIVIS} '08)},
	address      = {Marseille},
	keywords     = {litsurvey.bib}
}

@article{Shlyakhter2001,
	title        = {{Reconstruction of plausible {3D} tree models from instrumented photographs}},
	author       = {Shlyakhter, I and Rozenoer, M and Dorsey, J and Teller, S},
	year         = 2001,
	journal      = {IEEE Comput. Graph. Appl.},
	volume       = 21,
	number       = 3,
	pages        = {53--61},
	keywords     = {litsurvey.bib}
}

@book{Short1976,
	title        = {The Social Psychology of Telecommunications},
	author       = {Short, John and Williams, Ederyn and Christie, Bruce},
	year         = 1976,
	month        = {\#jan\#},
	publisher    = {Wiley},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Sibert2000,
	title        = {{Evaluation of eye gaze interaction}},
	author       = {Sibert, Linda E and Jacob, Robert J K},
	year         = 2000,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} conference on Human Factors in Computing Systems},
	location     = {The Hague, The Netherlands},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '00},
	pages        = {281--288},
	keywords     = {eye movements, eye tracking, interaction techniques, user interfaces;litsurvey.bib}
}

@article{Sicat2018,
	title        = {Dxr: A toolkit for building immersive data visualizations},
	author       = {Sicat, Ronell and Li, Jiabao and Choi, JunYoung and Cordeil, Maxime and Jeong, Won-Ki and Bach, Benjamin and Pfister, Hanspeter},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {715--725},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440858.pdf:PDF}
}

@article{Simanek_undated,
	title        = {The illusion of reality in stereoscopy},
	author       = {Simanek., Donald E},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sinha2004,
	title        = {Synchronization and calibration of camera networks from silhouettes},
	author       = {Sinha, S N and Pollefeys, M},
	year         = 2004,
	month        = {\#aug\#},
	booktitle    = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. {ICPR} 2004.},
	address      = {Cambridge},
	volume       = 1,
	pages        = {116--119 Vol.1},
	abstract     = {We propose an automatic approach to synchronize a network of uncalibrated and unsynchronized video cameras, and recover the complete calibration of all these cameras. In this paper, we extend recent work on computing the epipolar geometry from dynamic silhouettes, to deal with unsynchronized sequences and find the temporal offset between them. This is used to compute the fundamental matrices and the temporal offsets between many view-pairs in the network. Knowing the time-shifts between enough view-pairs allows us to robustly synchronize the whole network. The calibration of all the cameras is recovered from these fundamental matrices. The dynamic shape of the object can then be recovered using a visual-hull algorithm. Our method is especially useful for multi-camera shape-from-silhouette systems, as visual hulls can now be reconstructed without the need for a specific calibration session.},
	keywords     = {image reconstruction;image sequences;video cameras;synchronisation;calibration;matrix algebra;video signal processing;camera network synchronization;camera network calibration;unsynchronized video cameras;uncalibrated video cameras;epipolar geometry;dynamic silhouettes;unsynchronized sequences;fundamental matrices;visual hull algorithm;multicamera shape;silhouette systems;temporal offsets;image reconstruction;Calibration;Cameras;Image reconstruction;Video sequences;Character generation;Computational geometry;Transmission line matrix methods;Robustness;Shape;Computer networks;litsurvey.bib}
}

@article{Slater2004,
	title        = {How Colorful Was Your Day? Why Questionnaires Cannot Assess Presence in Virtual Environments},
	author       = {Slater, Mel},
	year         = 2004,
	month        = {\#aug\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 13,
	number       = 4,
	pages        = {484--493},
	abstract     = {This paper argues that a scientific basis for ?presence? as it's usually understood in virtual environments research, can not be established on the basis of postexperience presence questionnaires alone. To illustrate the point, an arbitrary mental attribute called ?colorfulness of the experience? is conjured up, and a set of questions administered to 74 respondents with an online questionnaire. The results suggested that colorfulness of yesterday's experiences was associated with the extent to which a person accomplished their tasks, and also associated with yesterday being a ?good?, ?pleasant?, but not frustrating day. The meaning lessness of this analysis illustrates that the equivalent methodology used by presence researchers, may, similarly, bring into being the idea of presence in the minds of VE participants. However, it is argued that there can be no evidence on this methodological basis that presence played any role in their actual mental activity or behavior at the time of the experience. It is concluded that presence researchers must move away from heavy reliance on questionnaires in order to make any progress in this area.},
	keywords     = {litsurvey.bib}
}

@article{Slater1999,
	title        = {Measuring Presence: A Response to the Witmer and Singer Presence Questionnaire},
	author       = {Slater, Mel},
	year         = 1999,
	month        = {\#oct\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 8,
	number       = 5,
	pages        = {560--565},
	keywords     = {litsurvey.bib}
}

@inproceedings{Slater2000,
	title        = {{Small-Group} Behavior in a Virtual and Real Environment: A Comparative Study},
	author       = {Slater, Mel and Sadagic, Amela and Usoh, Martin and Schroeder, Ralph},
	year         = 2000,
	publisher    = {MIT Press},
	volume       = 9,
	pages        = {37--51},
	abstract     = {This paper describes an experiment that compares behavior in small groups when its members carry out a task in a virtual environment (VE) and then continue the same task in a similar, real-world environment. The purpose of the experiment was not to examine task performance, but to compare various aspects of the social relations among the group members in the two environments. Ten groups of three people each, who had never met before, met first in a shared VE and carried out a task that required the identification and solution of puzzles that were presented on pieces of paper displayed around the walls of a room. The puzzle involved identifying that the same-numbered words across all the pieces of paper formed a riddle or saying. The group continued this task for fifteen minutes, and then stopped to answer a questionnaire. The group then reconvened in the real world and continued the same task. The experiment also required one of the group members to continually monitor a particular one of the others in order to examine whether social discomfort could be generated within a VE. In each group, there was one immersed person with a head-mounted display and head-tracking and two non-immersed people who experienced the environment on a workstation display. The results suggest that the immersed person tended to emerge as the leader in the virtual group, but not in the real meeting. Group accord tended to be higher in the real meeting than in the virtual meeting. Socially conditioned responses such as embarrassment could be generated in the virtual meeting, even though the individuals were presented to one another by very simple avatars. The study also found a positive relationship between presence of being in a place and copresence - the sense of being with the other people. Accord in the group increased with presence, the performance of the group, and the presence of women in the group. The study is seen as part of a much larger planned study, for which this experiment was used to begin to understand the issues involved in comparing real and virtual meetings. ABSTRACT FROM AUTHOR},
	keywords     = {litsurvey.bib}
}

@article{Slater2000,
	title        = {{Small-Group} Behavior in a Virtual and Real Environment: A Comparative Study},
	author       = {Slater, Mel and Sadagic, Amela and Usoh, Martin and Schroeder, Ralph},
	year         = 2000,
	month        = {\#feb\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 9,
	number       = 1,
	pages        = {37--51},
	abstract     = {This paper describes an experiment that compares behavior in small groups when its members carry out a task in a virtual environment (VE) and then continue the same task in a similar, real-world environment. The purpose of the experiment was not to examine task performance, but to compare various aspects of the social relations among the group members in the two environments. Ten groups of three people each, who had never met before, met first in a shared VE and carried out a task that required the identification and solution of puzzles that were presented on pieces of paper displayed around the walls of a room. The puzzle involved identifying that the same-numbered words across all the pieces of paper formed a riddle or saying. The group continued this task for fifteen minutes, and then stopped to answer a questionnaire. The group then reconvened in the real world and continued the same task. The experiment also required one of the group members to continually monitor a particular one of the others in order to examine whether social discomfort could be generated within a VE. In each group, there was one immersed person with a head-mounted display and head-tracking and two non-immersed people who experienced the environment on a workstation display. The results suggest that the immersed person tended to emerge as the leader in the virtual group, but not in the real meeting. Group accord tended to be higher in the real meeting than in the virtual meeting. Socially conditioned responses such as embarrassment could be generated in the virtual meeting, even though the individuals were presented to one another by very simple avatars. The study also found a positive relationship between presence of being in a place and copresence?the sense of being with the other people. Accord in the group increased with presence, the performance of the group, and the presence of women in the group. The study is seen as part of a much larger planned study, for which this experiment was used to begin to understand the issues involved in comparing real and virtual meetings.},
	keywords     = {litsurvey.bib}
}

@article{Slater1958,
	title        = {Contrasting Correlates of Group Size},
	author       = {Slater, Philip E},
	year         = 1958,
	journal      = {Sociometry},
	publisher    = {[American Sociological Association, Sage Publications, Inc.]},
	volume       = 21,
	number       = 2,
	pages        = {129--139},
	keywords     = {litsurvey.bib}
}

@article{Slessor2008,
	title        = {Age-related declines in basic social perception: evidence from tasks assessing eye-gaze processing},
	author       = {Slessor, Gillian and Phillips, Louise H and Bull, Rebecca},
	year         = 2008,
	month        = {\#dec\#},
	journal      = {Psychol. Aging},
	publisher    = {American Psychological Association},
	volume       = 23,
	number       = 4,
	pages        = {812--822},
	abstract     = {Previous research has investigated age differences in complex social perception tasks such as theory of mind and emotion recognition, with predominant findings of age-related declines. The present study investigated whether there are also age-related changes in basic aspects of social perception. Individuals' ability both to detect subtle differences in eye-gaze direction (e.g., where someone is looking in the environment) and to subsequently use these gaze cues to engage in joint attention with others was assessed. Age-related declines were found in the detection of the most subtle differences in gaze aversion. The ability to engage in joint attention by following gaze cues also declined with age. These age differences were not solely attributable to age impairments in visual perception and visual attention. The potential role of age-related neural declines in social perception problems was considered, along with the implications that age deficits in these basic social skills may have for older adults' social perception.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@incollection{Slovak2009,
	title        = {{GColl}: A Flexible Videoconferencing Environment for {Group-to-Group} Interaction},
	author       = {Slov{\'a}k, Petr and Troubil, Pavel and Holub, Petr},
	year         = 2009,
	booktitle    = {{Human-Computer} Interaction -- {INTERACT} 2009},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 5727,
	pages        = {165--168},
	editor       = {Gross, Tom and Gulliksen, Jan and Kotz{\'e}, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
	keywords     = {litsurvey.bib}
}

@inproceedings{Smith1997,
	title        = {Using subjective views to enhance 3D applications},
	author       = {Smith, Gareth and Mariani, John},
	year         = 1997,
	booktitle    = {Proceedings of the ACM symposium on Virtual reality software and technology},
	pages        = {139--146},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p139-smith.pdf:PDF}
}

@article{Snowdon1995,
	title        = {What you see is not what {I} see: Subjectivity in virtual environments},
	author       = {Snowdon, Dave and Greenhalgh, Chris and Benford, Steve},
	year         = 1995,
	journal      = {Framework for Immersive Virtual Environments (FIVE'95)},
	publisher    = {researchgate.net},
	abstract     = {This paper discusses the issue of subjectivity in collaborative virtual environments. First, we identify current uses of subjectivity in virtual reality systems. We then examine three existing and representative collaborative applications to identify potential benefits of subjectivity. A â€¦},
	keywords     = {litsurvey.bib}
}

@inproceedings{Sodhi2013,
	title        = {{BeThere}: {3D} mobile collaboration with spatial input},
	author       = {Sodhi, Rajinder S and Jones, Brett R and Forsyth, David and Bailey, Brian P and Maciocci, Giuliano},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {179--188},
	institution  = {ACM},
	keywords     = {depth sensors, around device interaction, collaboration, augmented reality;litsurvey.bib}
}

@inproceedings{Song_Zhang2004,
	title        = {{{High-Resolution}, Real-time {3D} Shape Acquisition}},
	author       = {{Song Zhang} and {Peisen Huang}},
	year         = 2004,
	month        = {\#jun\#},
	booktitle    = {2004 Conference on Computer Vision and Pattern Recognition Workshop},
	address      = {Washington},
	pages        = {28--28},
	abstract     = {In this paper we describe a high-resolution, real-time 3D shape acquisition system based on structured light techniques. This system uses a color pattern whose RGB channels are coded with either sinusoidal or trapezoidal fringe patterns. When projected by a modified DLP projector (color filters removed), this color pattern results in three grayscale patterns projected sequentially at a frequency of 240 Hz. A high-speed B/W CCD camera synchronized with the projector captures the three images, from which the 3D shape of the object is reconstructed. A color CCD camera is also used to capture images for texture mapping. The maximum 3D shape acquisition speed is 120 Hz (532 $\times$ 500 pixels), which is high enough for capturing the 3D shapes of moving objects. Two coding methods, sinusoidal phase-shifting method and trapezoidal phase-shifting method, were tested and results with good accuracy were obtained. The trapezoidal phase-shifting algorithm also makes real-time 3D reconstruction possible.},
	institution  = {State University of New York},
	keywords     = {Shape;Stereo vision;Image reconstruction;Charge-coupled image sensors;Charge coupled devices;Real time systems;Cameras;Stereo image processing;Mechanical engineering;Filters;litsurvey.bib}
}

@article{Song2019,
	title        = {Programming Bitcoin: Learn How to Program Bitcoin from Scratch},
	author       = {Song, Jimmy},
	year         = 2019,
	publisher    = {O'Reilly Media, Inc.},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/Jimmy Song - Programming Bitcoin_ Learn How to Program Bitcoin from Scratch (2019, OReilly Media).pdf:PDF}
}

@article{Sonnenwald1995,
	title        = {Contested collaboration: A descriptive model of intergroup communication in information system design},
	author       = {Sonnenwald, Diane H},
	year         = 1995,
	month        = {\#nov\#},
	journal      = {Inf. Process. Manag.},
	publisher    = {Elsevier},
	volume       = 31,
	number       = 6,
	pages        = {859--877},
	abstract     = {Many information system design situations today include users, designers, and developers who, with their own unique group and individual perspectives, need to interact so that they can come to a working understanding of how the information system being developed will coexist with and ideally support patterns of work activities, social groups, and personal beliefs. In these situations, design is fundamentally an interactive process that requires communication among users, designers, and developers. However, communication among these groups is often difficult although of paramount importance to design outcomes. Through a qualitative analysis of a house, expert system, and telecommunications network architecture and management system design situations, a descriptive model of design that characterizes communication among users, designers, and developers as they create an artifact was developed. The model describes design phases, roles, themes, and intergroup communication networks as they evolve throughout the design process and characterizes design as a process of ``contested collaboration''. It is a first step towards a predictive design model that suggests strategies which may help participants interact more effectively and ultimately improve the quality of design outcomes and the design process.},
	keywords     = {litsurvey.bib}
}

@article{Sorapure2019,
	title        = {Text, Image, Data, Interaction: Understanding Information Visualization},
	author       = {Sorapure, Madeleine},
	year         = 2019,
	journal      = {Computers and Composition},
	publisher    = {Elsevier},
	volume       = 54,
	pages        = 102519,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S875546151830032X-main.pdf:PDF}
}

@article{St_John2001,
	title        = {The use of {2D} and {3D} displays for shape-understanding versus relative-position tasks},
	author       = {St John, M and Cowen, M B and Smallman, H S and Oonk, H M},
	year         = 2001,
	journal      = {Hum. Factors},
	publisher    = {SAGE Publications},
	volume       = 43,
	number       = 1,
	pages        = {79--98},
	abstract     = {Research on when and how to use three-dimensional (3D) perspective views on flat screens for operational tasks such as air traffic control is complex. We propose a functional distinction between tasks: those that require shape understanding versus those that require precise judgments of relative position. The distortions inherent in 3D displays hamper judging relative positions, whereas the integration of dimensions in 3D displays facilitates shape understanding. We confirmed these hypotheses with two initial experiments involving simple block shapes. The shape-understanding tasks were identification or mental rotation. The relative-position tasks were locating shadows and determining directions and distances between objects. We then extended the results to four experiments involving complex natural terrain. We compare our distinction with the integral/separable task distinction of Haskel and Wickens (1993). Applications for this research include displays for air traffic control, geoplots for military command and control, and potentially, any display of 3D information.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Standaert2013,
	title        = {Assessing the effectiveness of telepresence for business meetings},
	author       = {Standaert, W and Muylle, S and Basu, A},
	year         = 2013,
	month        = {\#jan\#},
	booktitle    = {2013 46th Hawaii International Conference on System Sciences},
	pages        = {549--558},
	abstract     = {Business meetings conducted using fully-immersive telepresence systems provide participants with the lifelike-experience of a face-to-face meeting and offer the cost- and time-saving advantages of computer-mediated communication. However, telepresence systems are still much more expensive than simpler computer-mediated meeting modes, which makes the choice of this technology for business meetings a non-trivial decision problem. In this study, drawing upon the literature on social presence, media richness, and media appropriateness that relate media choice to task characteristics and objectives, we identify 19 objectives for business meetings. We then present hypotheses on the effectiveness of various meeting modes for achieving these objectives, focusing on the social presence dimension of four meeting modes (audio-conferencing, video-conferencing, telepresence, and face-to-face). We test these hypotheses using survey data from a large company in which all the technologies are available on a relatively broad basis.},
	institution  = {IEEE},
	keywords     = {business communication;computer mediated communication;teleconferencing;virtual reality;business meetings;telepresence systems;lifelike-experience;face-to-face meeting;cost-saving advantages;time-saving advantages;computer-mediated communication;computer-mediated meeting modes;media richness;media appropriateness;task characteristics;social presence dimension;audio-conferencing;video-conferencing;Media;Electronic mail;Computer mediated communication;Companies;Meetings;Telepresence;Social presence;Media richness;Media appropriateness;Meeting modes;Meeting objectives;litsurvey.bib}
}

@article{Starck2008,
	title        = {Model-based human shape reconstruction from multiple views},
	author       = {Starck, Jonathan and Hilton, Adrian},
	year         = 2008,
	month        = {\#aug\#},
	journal      = {Comput. Vis. Image Underst.},
	publisher    = {Elsevier},
	volume       = 111,
	number       = 2,
	pages        = {179--194},
	abstract     = {Image-based modelling allows the reconstruction of highly realistic digital models from real-world objects. This paper presents a model-based approach to recover animated models of people from multiple view video images. Two contributions are made, a multiple resolution model-based framework is introduced that combines multiple visual cues in reconstruction. Second, a novel mesh parameterisation is presented to preserve the vertex parameterisation in the model for animation. A prior humanoid surface model is first decomposed into multiple levels of detail and represented as a hierarchical deformable model for image fitting. A novel mesh parameterisation is presented that allows propagation of deformation in the model hierarchy and regularisation of surface deformation to preserve vertex parameterisation and animation structure. The hierarchical model is then used to fuse multiple shape cues from silhouette, stereo and sparse feature data in a coarse-to-fine strategy to recover a model that reproduces the appearance in the images. The framework is compared to physics-based deformable surface fitting at a single resolution, demonstrating an improved reconstruction accuracy against ground-truth data with a reduced model distortion. Results demonstrate realistic modelling of real people with accurate shape and appearance while preserving model structure for use in animation.},
	keywords     = {Image-based modelling; Deformable model; Multiple resolution mesh; Shape-from-silhouette; Stereo vision; Character animation;litsurvey.bib}
}

@phdthesis{Starck2003,
	title        = {Human modelling from multiple views},
	author       = {Starck, J R},
	year         = 2003,
	school       = {Citeseer},
	keywords     = {litsurvey.bib}
}

@book{Steinmeyer2013,
	title        = {The Science Behind the Ghost!: A Brief History of Pepper's Ghost},
	author       = {Steinmeyer, Jim},
	year         = 2013,
	publisher    = {Hahne},
	keywords     = {litsurvey.bib}
}

@phdthesis{Steptoe2010,
	title        = {Eye tracking and avatar-mediated communication in immersive collaborative virtual environments},
	author       = {Steptoe, William Arthur Hugh},
	year         = 2010,
	school       = {University College London (University of London)},
	keywords     = {litsurvey.bib}
}

@inproceedings{Steptoe2009,
	title        = {Eye Tracking for Avatar Eye Gaze Control During {Object-Focused} Multiparty Interaction in Immersive Collaborative Virtual Environments},
	author       = {Steptoe, W and Oyekoya, O and Murgia, A and Wolff, R and Rae, J and Guimaraes, E and Roberts, D and Steed, A},
	year         = 2009,
	month        = {\#mar\#},
	booktitle    = {2009 {IEEE} Virtual Reality Conference},
	pages        = {83--90},
	abstract     = {In face-to-face collaboration, eye gaze is used both as a bidirectional signal to monitor and indicate focus of attention and action, as well as a resource to manage the interaction. In remote interaction supported by immersive collaborative virtual environments (ICVEs), embodied avatars representing and controlled by each participant share a virtual space. We report on a study designed to evaluate methods of avatar eye gaze control during an object-focused puzzle scenario performed between three networked CAVEtrade-like systems. We compare tracked gaze, in which avatars' eyes are controlled by head-mounted mobile eye trackers worn by participants, to a gaze model informed by head orientation for saccade generation, and static gaze featuring non-moving eyes. We analyse task performance, subjective user experience, and interactional behaviour. While not providing statistically significant benefit over static gaze, tracked gaze is observed as the highest performing condition. However, the gaze model resulted in significantly lower task performance and increased error rate.},
	institution  = {IEEE},
	keywords     = {avatars;groupware;human computer interaction;avatar eye gaze control;object-focused multiparty interaction;immersive collaborative virtual environment;face-to-face collaboration;remote interaction;puzzle scenario;head-mounted mobile eye tracking;saccade generation;Avatars;Collaboration;Virtual environment;Eyes;Remote monitoring;Resource management;Design methodology;Control systems;Performance evaluation;Performance analysis;Immersive Collaborative Virtual Environments;Eye Tracking;Avatars;Eye Gaze;Behavioural Realism;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism\?\`Virtual Reality;H.4.3 [Information Systems Applications]: Communications Applications\?\`Computer conferencing, teleconferencing, and videoconferencing;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism\?\`Animation;litsurvey.bib}
}

@inproceedings{Steptoe2010,
	title        = {Lie tracking: social presence, truth and deception in avatar-mediated telecommunication},
	author       = {Steptoe, William and Steed, Anthony and Rovira, Aitor and Rae, John},
	year         = 2010,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Atlanta, Georgia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '10},
	pages        = {1039--1048},
	abstract     = {The success of visual telecommunication systems depends on their ability to transmit and display users' natural nonverbal behavior. While video-mediated communication (VMC) is the most widely used form of interpersonal remote interaction, avatar-mediated communication (AMC) in shared virtual environments is increasingly common. This paper presents two experiments investigating eye tracking in AMC. The first experiment compares the degree of social presence experienced in AMC and VMC during truthful and deceptive discourse. Eye tracking data (gaze, blinking, and pupil size) demonstrates that oculesic behavior is similar in both mediation types, and uncovers systematic differences between truth telling and lying. Subjective measures show users' psychological arousal to be greater in VMC than AMC. The second experiment demonstrates that observers of AMC can more accurately detect truth and deception when viewing avatars with added oculesic behavior driven by eye tracking. We discuss implications for the design of future visual telecommunication media interfaces.},
	keywords     = {avatar video mediated communication, behavior, communication, cues, deception, design, eye tracking, information, social presence, trust, virtual environments; avatar-mediated communication; video-mediated communication;litsurvey.bib}
}

@inproceedings{Steptoe2008,
	title        = {{Eye-tracking for avatar eye-gaze and interactional analysis in immersive collaborative virtual environments}},
	author       = {Steptoe, William and Wolff, Robin and Murgia, Alessio and Guimaraes, Estefania and Rae, John and Sharkey, Paul and Roberts, David and Steed, Anthony},
	year         = 2008,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2008 {ACM} conference on Computer supported cooperative work},
	location     = {San Diego, CA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '08},
	pages        = {197--200},
	keywords     = {social presence, eye-tracking, eye-gaze, immersive collaborative virtual environments, telecommunication, avatars;litsurvey.bib}
}

@article{Steuer2006,
	title        = {{Defining virtual reality: Dimensions determining telepresence}},
	author       = {Steuer, Jonathan},
	year         = 2006,
	journal      = {J. Commun.},
	pages        = {1--25},
	keywords     = {litsurvey.bib}
}

@article{Steuer1992,
	title        = {Defining Virtual Reality: Dimensions Determining Telepresence},
	author       = {Steuer, Jonathan},
	year         = 1992,
	month        = {\#dec\#},
	journal      = {J. Commun.},
	publisher    = {Oxford Academic},
	volume       = 42,
	number       = 4,
	pages        = {73--93},
	abstract     = {Jonathan Steuer; Defining Virtual Reality: Dimensions Determining Telepresence, Journal of Communication, Volume 42, Issue 4, 1 December 1992, Pages 73--93, htt},
	keywords     = {virtual reality;litsurvey.bib}
}

@inproceedings{Stiefelhagen2002,
	title        = {Tracking focus of attention in meetings},
	author       = {Stiefelhagen, R},
	year         = 2002,
	month        = {\#oct\#},
	booktitle    = {Proceedings. Fourth {IEEE} International Conference on Multimodal Interfaces},
	pages        = {273--280},
	abstract     = {The author presents an overview of his work on tracking focus of attention in meeting situations. He has developed a system capable of estimating participants' focus of attention from multiple cues. In the system he employs an omni-directional camera to simultaneously track the faces of participants sitting around a meeting table and uses neural networks to estimate their head poses. In addition, he uses microphones to detect who is speaking. The system predicts participants' focus of attention from acoustic and visual information separately, and then combines the output of the audio- and video-based focus of attention predictors. In addition he reports recent experimental results: In order to determine how well we can predict a subject's focus of attention solely on the basis of his or her head orientation, he has conducted an experiment in which he recorded head and eye orientations of participants in a meeting using special tracking equipment. The results demonstrate that head orientation was a sufficient indicator of the subjects' focus target in 89\% of the time. Furthermore he discusses how the neural networks used to estimate head orientation can be adapted to work in new locations and under new illumination conditions.},
	institution  = {IEEE},
	keywords     = {tracking;image motion analysis;neural nets;speech recognition;lighting;user interfaces;focus of attention tracking;meetings;multiple cues;omni-directional camera;neural networks;head pose estimation;microphones;visual information;head orientation;illumination;acoustic information;attention predictors;video;audio;experimental results;Head;Face detection;Focusing;Cameras;Lighting;Competitive intelligence;Humans;Layout;Interactive systems;Laboratories;litsurvey.bib}
}

@inproceedings{Stiefelhagen2001,
	title        = {Estimating focus of attention based on gaze and sound},
	author       = {Stiefelhagen, Rainer and Yang, Jie and Waibel, Alex},
	year         = 2001,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2001 workshop on Perceptive user interfaces},
	location     = {Orlando, Florida, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {PUI '01},
	pages        = {1--9},
	institution  = {ACM},
	keywords     = {intelligent environments, meeting analysis, focus of attention, gaze tracking;litsurvey.bib}
}

@inproceedings{Stiefelhagen2002,
	title        = {Head orientation and gaze direction in meetings},
	author       = {Stiefelhagen, Rainer and Zhu, Jie},
	year         = 2002,
	month        = {\#apr\#},
	booktitle    = {{CHI} '02 Extended Abstracts on Human Factors in Computing Systems},
	location     = {Minneapolis, Minnesota, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI EA '02},
	pages        = {858--859},
	keywords     = {attention-based interfaces, gaze tracking, head pose;litsurvey.bib}
}

@article{Stockman1988,
	title        = {{Sensing and recognition of rigid objects using structured light}},
	author       = {Stockman, G C and -. Chen, S and Hu, G and Shrikhande, N},
	year         = 1988,
	month        = {\#jun\#},
	journal      = {IEEE Control Syst. Mag.},
	volume       = 8,
	number       = 3,
	pages        = {14--22},
	abstract     = {Word directed toward the development of a vision system for bin picking of rigid 3D objects is reported. Any such system must have components for sensing, feature extraction, modeling, and matching. A structured light system which attempts to deliver a rich 2/sup 1///sub 2/D representation of the scene is described. Surface patches are evident as connected sets of stripes whose 3D coordinates are computed by means of triangulation and constraint propagation. Object edges are detected by the intersection of surface patches or by backprojecting image edges to intersect with the patches. Two matching paradigms are given for drawing correspondence between structures in the scene representation and structures in models. Three major contributions are reported: a method for sensing object surface patches without having to solve uniquely for stripe labels; the use of both an intensity image and a striped image, allowing scenes to be represented by detected edges along with 3D surface patches; and a pose-clustering algorithm, a uniform technique to accumulate matching evidence for recognition while averaging out substantial errors of pose.},
	keywords     = {computer vision;computerised pattern recognition;computer vision;edge detection;object recognition;feature matching;pose errors;rigid objects;structured light;bin picking;feature extraction;triangulation;constraint propagation;surface patches;backprojecting;matching paradigms;intensity image;striped image;pose-clustering algorithm;Layout;Image edge detection;Machine vision;Feature extraction;Object detection;Clustering algorithms;Robot sensing systems;Robot kinematics;Data mining;Computer vision;litsurvey.bib}
}

@inproceedings{Strait2014,
	title        = {Measuring users' responses to humans, robots, and human-like robots with functional near infrared spectroscopy},
	author       = {Strait, M and Scheutz, M},
	year         = 2014,
	month        = {\#aug\#},
	booktitle    = {The 23rd {IEEE} International Symposium on Robot and Human Interactive Communication},
	pages        = {1128--1133},
	abstract     = {The Uncanny Valley Hypothesis (UVH) describes the sudden change in a person's affect from affinity to aversion that is evoked by robots that border a human-like appearance. The portion of the human-likeness spectrum in which such aversion is posited to occur is referred to as the ``uncanny valley''. However, evidence in support of the UVH is primarily based on subjectively assessed evaluations. Thus it remains an open question as to whether there are behavioral or neurophysiological manifestations of uncanny valley effects. To address this gap in literature, we investigated the activation of the anterior prefrontal cortex (PFC) - a region of the brain associated with emotion regulation - in response to a series of robots with varying human-likeness. We hypothesized that highly human-like robots - which have been found to receive negative subjective attributions - will also elicit increased activity in the PFC versus humans or robots with lesser degrees of human-likeness in accordance with the UVH. Our results show a ``valley'' in brain activity in the PFC corresponding to the valley observed via subjective measures alone, thus suggesting one neural manifestation (the PFC) of uncanny valley effects and further supporting the affective response (aversion) posited to occur by the UVH. However, the results also reveal a second ``uncanny valley'' in prefrontal hemodynamics, which suggests that the effects (and the contributing factors) are more complex than previously understood.},
	institution  = {IEEE},
	keywords     = {humanoid robots;infrared spectroscopy;prefrontal hemodynamics;affective response;neural manifestation;brain activity;PFC versus humans;emotion regulation;anterior prefrontal cortex;uncanny valley effects;neurophysiological manifestations;human-likeness spectrum;human-like appearance;UVH;uncanny valley hypothesis;functional near infrared spectroscopy;human-like robots;user responses;Robots;Hemodynamics;Atmospheric measurements;Particle measurements;Spectroscopy;Visualization;Face;litsurvey.bib}
}

@inproceedings{Sugimoto2004,
	title        = {Caretta: a system for supporting face-to-face collaboration by integrating personal and shared spaces},
	author       = {Sugimoto, Masanori and Hosoi, Kazuhiro and Hashizume, Hiromichi},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {41--48},
	institution  = {ACM},
	keywords     = {PDA, face-to-face collaboration, personal and shared spaces, sensing board;litsurvey.bib}
}

@article{Sullivan1998,
	title        = {{Automatic Model Construction, Pose Estimation, and Object Recognition from Photographs Using Triangular Splines}},
	author       = {Sullivan, S and Ponce, J},
	year         = 1998,
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	volume       = 20,
	pages        = {1091--1096},
	keywords     = {litsurvey.bib}
}

@article{Sundaram2000,
	title        = {The role of nonverbal communication in service encounters},
	author       = {Sundaram, D S and Webster, Cynthia},
	year         = 2000,
	month        = {\#jan\#},
	journal      = {J. Prof. Serv. Mark.},
	publisher    = {MCB UP Ltd},
	volume       = 14,
	number       = 5,
	pages        = {378--391},
	abstract     = {Although the verbal components of service encounters have been investigated, the nonverbal aspects of employee ?customer interactions have remained virtually unexplored in the marketing literature. Thus, the purpose of this paper is to explore the importance of service employees' nonverbal communication during service interactions. Specifically, a conceptual model is presented that links nonverbal communication (kinesics, paralanguage, proxemics, and physical appearance), customer affect, and consumers' evaluations of service providers (with respect to credibility, friendliness, competence, empathy, courtesy, and trustworthiness). Further, the importance of nonverbal elements is discussed and managerial implications are given.},
	keywords     = {litsurvey.bib}
}

@article{Surman2015,
	title        = {Head tracked retroreflecting {3D} display},
	author       = {Surman, Phil and Day, Sally and Liu, Xianzi and Benjamin, Joshua and Urey, Hakan and Aksit, Kaan},
	year         = 2015,
	month        = {\#feb\#},
	journal      = {Jnl Soc Info Display},
	volume       = 23,
	number       = 2,
	pages        = {56--68},
	abstract     = {Abstract In this paper, we describe a single-user glasses-free (autostereoscopic) 3D display where images from a pair of picoprojectors are projected on to a retroreflecting screen. Real images of the projector lenses formed at the viewer's eyes produce exit pupils that follow the eye positions by the projectors moving laterally under the control of a head tracker. This provides the viewer with a comfortable degree of head movement. The retroreflecting screen, display hardware, infrared head tracker, and means of stabilizing the image position on the screen are explained. The performance of the display in terms of crosstalk, resolution, image distortion, and other parameters is described. Finally, applications of this display type are suggested.},
	keywords     = {autostereoscopic, retroreflector, picoprojector, exit pupils, head tracking, infrared;litsurvey.bib}
}

@article{Suzuki2012,
	title        = {Substitutional reality system: a novel experimental platform for experiencing alternative reality},
	author       = {Suzuki, Keisuke and Wakisaka, Sohei and Fujii, Naotaka},
	year         = 2012,
	month        = {\#jun\#},
	journal      = {Sci. Rep.},
	publisher    = {Nature Publishing Group},
	volume       = 2,
	pages        = 459,
	abstract     = {We have developed a novel experimental platform, referred to as a substitutional reality (SR) system, for studying the conviction of the perception of live reality and related metacognitive functions. The SR system was designed to manipulate people's reality by allowing them to experience live scenes (in which they were physically present) and recorded scenes (which were recorded and edited in advance) in an alternating manner without noticing a reality gap. All of the na{\"\i}ve participants (n = 21) successfully believed that they had experienced live scenes when recorded scenes had been presented. Additional psychophysical experiments suggest the depth of visual objects does not affect the perceptual discriminability between scenes, and the scene switch during head movement enhance substitutional performance. The SR system, with its reality manipulation, is a novel and affordable method for studying metacognitive functions and psychiatric disorders.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@book{cryptopians,
	title        = {The Cryptopians: Idealism, Greed, Lies, and the Making of the First Big Cryptocurrency Craze},
	author       = {Laura Shin},
	year         = 2022,
	publisher    = {Public Affairs}
}

@inproceedings{Symons2004,
	title        = {What are you looking at? Acuity for triadic eye gaze},
	author       = {Symons, Lawrence A and Lee, Kang and Cedrone, Caroline C and Nishimura, Mayu},
	year         = 2004,
	volume       = 131,
	pages        = {451--469},
	abstract     = {The authors measured observers' ability to determine direction of gaze toward an object in space. In Experiment 1, they determined the difference threshold for determining whether a live ``looker'' was looking to the left or right of a target point. Acuity for eye direction was quite high (approximately 30 s arc). Viewing the movement of the looker's eyes did not improve acuity. When one of the looker's eyes was occluded, the observers' acuity was disrupted and their point of subjective equality was shifted away from the exposed eye. Experiment 2 was a replication of Experiment 1, but digitized gaze displays were used. The results of Experiment 3 showed that the acuity for direction of gaze depended on the position of the looker's target. Overall, the results indicated that humans are highly sensitive to gaze direction and that information from both eyes is used to determine direction of regard.},
	keywords     = {Adult, Eye Movements, Female, Humans, Interpersonal Relations, Visual Acuity, Visual Perception;litsurvey.bib}
}

@article{Systems_undated-ps,
	title        = {Here's Looking at You: Eye Contact and Gaze Perspectivein the Two Dimensional World of {TelePresence}},
	author       = {Systems, Cisco},
	keywords     = {litsurvey.bib}
}

@article{szabo1997formalizing,
	title        = {Formalizing and securing relationships on public networks},
	author       = {Szabo, Nick},
	year         = 1997,
	journal      = {First monday}
}

@article{Szeliski1993,
	title        = {Rapid Octree Construction from Image Sequences},
	author       = {Szeliski, R},
	year         = 1993,
	month        = {\#jul\#},
	journal      = {Comput. Vis. Image Underst.},
	volume       = 58,
	number       = 1,
	pages        = {23--32},
	keywords     = {litsurvey.bib}
}

@inproceedings{Tachi2003,
	title        = {Telexistence and retro-reflective projection technology ({RPT})},
	author       = {Tachi, Susumu},
	year         = 2003,
	booktitle    = {Proceedings of the 5th Virtual Reality International Conference ({VRIC2003}) pp},
	volume       = 69,
	pages        = {1--69},
	keywords     = {litsurvey.bib}
}

@article{Tachi2004,
	title        = {{MUTUAL} {TELEXISTENCE} {SYSTEM} {USING} {RETRO-REFLECTIVE} {PROJECTION} {TECHNOLOGY}},
	author       = {Tachi, Susumu and Kawakami, Naoki and Inami, Masahiko and Zaitsu, Yoshitaka},
	year         = 2004,
	month        = {\#mar\#},
	journal      = {Int. J. Humanoid Rob.},
	publisher    = {World Scientific Publishing Co.},
	volume       = {01},
	number       = {01},
	pages        = {45--64},
	abstract     = {Telexistence is fundamentally a concept named for the technology that enables a human being to have a real-time sensation of being at a place other than where he or she actually is, and to interact with the remote environment, which may be real, virtual, or a combination of both. It also refers to an advanced type of teleoperation system that enables an operator at the controls to perform remote tasks dexterously with the feeling of existing in a surrogate robot. Although conventional telexistence systems provide an operator the real-time sensation of being in a remote environment, persons in the remote environment have only the sensation that a surrogate robot is present, not the operator. Mutual telexistence aims to solve this problem so that the existence of the operator is apparent to persons in the remote environment by providing mutual sensations of presence. This paper proposes a method of mutual telexistence using projection technology with retro-reflective objects, and describes experimental hardware constructed to demonstrate the feasibility of the proposed method.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Tang2010,
	title        = {Three's company: understanding communication channels in three-way distributed collaboration},
	author       = {Tang, Anthony and Pahud, Michel and Inkpen, Kori and Benko, Hrvoje and Tang, John C and Buxton, Bill},
	year         = 2010,
	month        = {\#feb\#},
	booktitle    = {Proceedings of the 2010 {ACM} conference on Computer supported cooperative work},
	location     = {Savannah, Georgia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '10},
	pages        = {271--280},
	conference   = {the 2010 ACM conference},
	institution  = {ACM},
	keywords     = {tabletop, media space, video-mediated communication, shared workspace;litsurvey.bib}
}

@inproceedings{Tang2006,
	title        = {Collaborative coupling over tabletop displays},
	author       = {Tang, Anthony and Tory, Melanie and Po, Barry and Neumann, Petra and Carpendale, Sheelagh},
	year         = 2006,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Montr{\'e}al, Qu{\'e}bec, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '06},
	pages        = {1181--1190},
	institution  = {ACM},
	keywords     = {mixed focus collaboration, coordination, collaborative coupling, collaborative tabletop displays, single display groupware;litsurvey.bib}
}

@inproceedings{Tang2013,
	title        = {{HomeProxy}: exploring a physical proxy for video communication in the home},
	author       = {Tang, John C and Xiao, Robert and Hoff, Aaron and Venolia, Gina and Therien, Patrick and Roseway, Asta},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {1339--1342},
	institution  = {ACM},
	keywords     = {asynchronous video, home, physical proxies, video chat;litsurvey.bib}
}

@article{Tay2008,
	title        = {An updatable holographic three-dimensional display},
	author       = {Tay, Sava{\c s} and Blanche, P-A and Voorakaranam, R and Tun{\c c}, A V and Lin, W and Rokutanda, S and Gu, T and Flores, D and Wang, P and Li, G and St Hilaire, P and Thomas, J and Norwood, R A and Yamamoto, M and Peyghambarian, N},
	year         = 2008,
	month        = {\#feb\#},
	journal      = {Nature},
	publisher    = {Nature Publishing Group},
	volume       = 451,
	number       = 7179,
	pages        = {694--698},
	abstract     = {Holographic three-dimensional (3D) displays provide realistic images without the need for special eyewear, making them valuable tools for applications that require situational awareness, such as medical, industrial and military imaging. Currently commercially available holographic 3D displays use photopolymers that lack image-updating capability, resulting in restricted use and high cost. Photorefractive polymers are dynamic holographic recording materials that allow updating of images and have a wide range of applications, including optical correlation, imaging through scattering media and optical communication. To be suitable for 3D displays, photorefractive polymers need to have nearly 100\% diffraction efficiency, fast writing time, hours of image persistence, rapid erasure, and large area-a combination of properties that has not been shown before. Here, we report an updatable holographic 3D display based on photorefractive polymers with such properties, capable of recording and displaying new images every few minutes. This is the largest photorefractive 3D display to date (4 x 4 inches in size); it can be recorded within a few minutes, viewed for several hours without the need for refreshing, and can be completely erased and updated with new images when desired.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@inproceedings{Teixeira2013,
	title        = {Indoor localization using {SLAM} in parallel with a natural marker detector},
	author       = {Teixeira, Lucas and Raposo, Alberto B and Gattass, Marcelo},
	year         = 2013,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the 28th Annual {ACM} Symposium on Applied Computing},
	location     = {Coimbra, Portugal},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SAC '13},
	pages        = {27--33},
	keywords     = {picking, SLAM, indoor localization, tracking, computer vision;litsurvey.bib}
}

@book{Terveen2003,
	title        = {Conference Proceedings: Conference on Human Factors in Computing Systems : Changing the World, Changing Ourselves},
	author       = {Terveen, Loren},
	year         = 2003,
	publisher    = {Association for Computing Machinery},
	pages        = {521--528},
	keywords     = {attentive user interfaces, conferencing, eye contact, eye tracking, gaze, multiparty video;litsurvey.bib},
	language     = {en}
}

@book{Ting-Toomey2012,
	title        = {Understanding intercultural communication},
	author       = {Ting-Toomey, Stella and Chung, Leeva C},
	year         = 2012,
	publisher    = {Oxford University Press New York, NY},
	keywords     = {litsurvey.bib}
}

@inproceedings{Tory2004,
	title        = {Combining {2D} and {3D} views for orientation and relative position tasks},
	author       = {Tory, Melanie and Moller, Torsten and Atkins, M Stella and Kirkpatrick, Arthur E},
	year         = 2004,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Vienna, Austria},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '04},
	pages        = {73--80},
	institution  = {ACM},
	keywords     = {empirical study, display design, orientation and relative position tasks, 2D and 3D visualization, experiment;litsurvey.bib}
}

@inproceedings{Towles2003,
	title        = {Transport and rendering challenges of multi-stream {3D} tele-immersion data},
	author       = {Towles, Herman and Kum, Sang-Uok and Sparks, Travis and Sinha, Sudipta and Larsen, Scott and Beddes, Nathan},
	year         = 2003,
	booktitle    = {{NSF} Lake Tahoe Workshop on Collaborative Virtual Reality and Visualization},
	address      = {Lake Tahoe},
	pages        = {1--6},
	keywords     = {litsurvey.bib}
}

@unpublished{Trends_undated,
	title        = {Google Trends for Projection Mapping},
	author       = {Trends, Google},
	keywords     = {litsurvey.bib}
}

@article{Troje1998,
	title        = {Illumination-induced apparent shift in orientation of human heads},
	author       = {Troje, N F and Siebeck, U},
	year         = 1998,
	journal      = {Perception},
	publisher    = {Sage Publications},
	volume       = 27,
	number       = 6,
	pages        = {671--680},
	abstract     = {Changing the position of a light source illuminating a human face induces an apparent shift of the perceived orientation of that face. The direction of this apparent shift is opposite to the shift of the light source. We demonstrated the illumination-induced apparent orientation shift (IAOS), quantified it in terms of the physical orientation shift needed to compensate for it, and evaluated the results in the context of possible mechanisms underlying orientation judgment. Results indicate that IAOS depends not only on the angle between the two light source positions, but also on the mean orientation of the face. Availability of cues coded in the visual texture of the face did not affect IAOS. The most effective cue was the location of the visible outline of the face. IAOS seems to be due to a shift of this outline when shadowed areas on the face merge with the black background. We conclude that an important mechanism for orientation judgment is based on a comparison of visible parts left and right of the profile line.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Tsai1987,
	title        = {A versatile camera calibration technique for high-accuracy {3D} machine vision metrology using off-the-shelf {TV} cameras and lenses},
	author       = {Tsai, R},
	year         = 1987,
	month        = {\#aug\#},
	journal      = {IEEE Journal on Robotics and Automation},
	publisher    = {IEEE},
	volume       = 3,
	number       = 4,
	pages        = {323--344},
	abstract     = {A new technique for three-dimensional (3D) camera calibration for machine vision metrology using off-the-shelf TV cameras and lenses is described. The two-stage technique is aimed at efficient computation of camera external position and orientation relative to object reference coordinate system as well as the effective focal length, radial lens distortion, and image scanning parameters. The two-stage technique has advantage in terms of accuracy, speed, and versatility over existing state of the art. A critical review of the state of the art is given in the beginning. A theoretical framework is established, supported by comprehensive proof in five appendixes, and may pave the way for future research on 3D robotics vision. Test results using real data are described. Both accuracy and speed are reported. The experimental results are analyzed and compared with theoretical prediction. Recent effort indicates that with slight modification, the two-stage calibration can be done in real time.},
	keywords     = {Calibration;Machine vision;Measurement;Cameras;Calibration;Machine vision;Metrology;TV;Lenses;Robot vision systems;Robotic assembly;Robot kinematics;Application software;litsurvey.bib}
}

@inproceedings{Tse2007,
	title        = {How pairs interact over a multimodal digital table},
	author       = {Tse, Edward and Shen, Chia and Greenberg, Saul and Forlines, Clifton},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {215--218},
	institution  = {ACM},
	keywords     = {digital tables, speech, gestures, multimodal interaction;litsurvey.bib}
}

@inproceedings{Tsui2012,
	title        = {Towards measuring the quality of interaction: communication through telepresence robots},
	author       = {Tsui, Katherine M and Desai, Munjal and Yanco, Holly A},
	year         = 2012,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the Workshop on Performance Metrics for Intelligent Systems},
	location     = {College Park, Maryland},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {PerMIS '12},
	pages        = {101--108},
	institution  = {ACM},
	keywords     = {human-computer interaction, embodied video-mediated communication, human-robot interaction;litsurvey.bib}
}

@inproceedings{Tsui2011,
	title        = {Exploring use cases for telepresence robots},
	author       = {Tsui, Katherine M and Desai, Munjal and Yanco, Holly A and Uhlik, Chris},
	year         = 2011,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the 6th international conference on Human-robot interaction},
	location     = {Lausanne, Switzerland},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {HRI '11},
	pages        = {11--18},
	institution  = {IEEE},
	keywords     = {video conferencing, teleoperation, remote presence;litsurvey.bib}
}

@inproceedings{Tuddenham2009,
	title        = {Territorial coordination and workspace awareness in remote tabletop collaboration},
	author       = {Tuddenham, Philip and Robinson, Peter},
	year         = 2009,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '09},
	pages        = {2139--2148},
	institution  = {ACM},
	keywords     = {fluidity, coupling, territoriality, remote tabletop interfaces;litsurvey.bib}
}

@inproceedings{Uddin2014,
	title        = {Seven V's of Big Data understanding Big Data to extract value},
	author       = {Uddin, Muhammad Fahim and Gupta, Navarun and others},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 zone 1 conference of the American Society for Engineering Education},
	pages        = {1--5},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Seven V___s of Big Data_Understanding Big Data.pdf:PDF}
}

@article{UNstats_undated,
	title        = {Deputy {UN} chief calls for urgent action to tackle global sanitation crisis},
	author       = {{UNstats}},
	keywords     = {litsurvey.bib}
}

@misc{Usoh2000,
	title        = {{Using Presence Questionnaires in Reality. (Usoh et al, 2000).pdf}},
	author       = {Usoh, Martin and Catena, Ernest and Arman, Sima and Slater, Mel},
	year         = 2000,
	booktitle    = {Presence Teleoperators Virtual Environments},
	publisher    = {MIT Press},
	volume       = 9,
	number       = 5,
	pages        = {497--503},
	abstract     = {A between-group experiment was carried out to assess whether two different presence questionnaires can distinguish between real and virtual experiences. One group of ten subjects searched for a box in a real office environment. A second group of ten subjects carried out the same task in a virtual environment that simulated the same office. Immediately after their experience, subjects were given two different presence questionnaires in randomized order: the Witmer and Singer Presence (WS), and the questionnaire developed by Slater, Usoh, and Steed (SUS). The paper argues that questionnaires should be able to pass a ``reality test,'' whereby under current conditions the presence scores should be higher for real experiences than for virtual ones. Nevertheless, only the SUS had a marginally higher mean score for the real compared to the virtual, and there was no significant difference at all between the WS mean scores. It is concluded that, although such questionnaires may be useful when all subjects experience the same type of environment, their utility is doubtful for the comparison of experiences across environments, such as immersive virtual compared to real, or desktop compared to immersive virtual. ABSTRACT FROM AUTHOR Copyright of Presence: Teleoperators \& Virtual Environments is the property of MIT Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts)},
	keywords     = {litsurvey.bib}
}

@article{Usoh2000,
	title        = {Using Presence Questionnaires in Reality},
	author       = {Usoh, Martin and Catena, Ernest and Arman, Sima and Slater, Mel},
	year         = 2000,
	month        = {\#oct\#},
	journal      = {Presence: Teleoperators and Virtual Environments},
	publisher    = {MIT Press},
	volume       = 9,
	number       = 5,
	pages        = {497--503},
	abstract     = {A between-group experiment was carried out to assess whether two different presence questionnaires can distinguish between real and virtual experiences. One group of ten subjects searched for a box in a real office environment. A second group of ten subjects carried out the same task in a virtual environment that simulated the same office. Immediately after their experience, subjects were given two different presence questionnaires in randomized order: the Witmer and Singer Presence (WS), and the questionnaire developed by Slater, Usoh, and Steed (SUS). The paper argues that questionnaires should be able to pass a ?reality test? whereby under current conditions the presence scores should be higher for real experiences than for virtual ones. Nevertheless, only the SUS had a marginally higher mean score for the real compared to the virtual, and there was no significant difference at all between the WS mean scores. It is concluded that, although such questionnaires may be useful when all subjects experience the same type of environment, their utility is doubtful for the comparison of experiences across environments, such as immersive virtual compared to real, or desktop compared to immersive virtual.},
	keywords     = {litsurvey.bib}
}

@article{Vadera2010,
	title        = {CSNL: A cost-sensitive non-linear decision tree algorithm},
	author       = {Vadera, Sunil},
	year         = 2010,
	journal      = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
	publisher    = {ACM},
	volume       = 4,
	number       = 2,
	pages        = 6,
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/clustering/1754428.1754429.pdf:PDF}
}

@book{Van_Baren2004,
	title        = {Measuring presence: A guide to current measurement approaches},
	author       = {Van Baren, Joy and IJsselsteijn, Wijnand},
	year         = 2004,
	keywords     = {litsurvey.bib}
}

@inproceedings{Van_den_Bergh2009,
	title        = {A novel camera-based system for collaborative interaction with multi-dimensional data models},
	author       = {Van den Bergh, Michael and Halatsch, Jan and Kunze, Antje and Bosch{\'e}, Fr{\'e}d{\'e}ric},
	year         = 2009,
	booktitle    = {{CONVR} Conference Proceedings, University of Sydney},
	pages        = {19--28},
	keywords     = {litsurvey.bib}
}

@misc{cypherPunkMailList,
	title        = {Cypher Punks Mailing List Archives},
	author       = {Various},
	year         = 1990,
	url          = {https://mailing-list-archive.cryptoanarchy.wiki},
	owner        = {its352},
	timestamp    = {2021.12.02}
}

@book{Various2002,
	title        = {Distributed Work},
	author       = {{Various}},
	year         = 2002,
	publisher    = {MIT Press},
	editor       = {Pamela J Hinds, Sara Kiesler},
	keywords     = {litsurvey.bib}
}

@inproceedings{Venolia2010,
	title        = {Embodied social proxy: mediating interpersonal connection in hub-and-satellite teams},
	author       = {Venolia, Gina and Tang, John and Cervantes, Ruy and Bly, Sara and Robertson, George and Lee, Bongshin and Inkpen, Kori},
	year         = 2010,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Atlanta, Georgia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '10},
	pages        = {1049--1058},
	institution  = {ACM},
	keywords     = {distributed collaboration, telepresence, embodied video conferencing, empirical study;litsurvey.bib}
}

@inproceedings{Vertegaal1999,
	title        = {The {GAZE} groupware system: mediating joint attention in multiparty communication and collaboration},
	author       = {Vertegaal, Roel},
	year         = 1999,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} conference on Human Factors in Computing Systems},
	location     = {Pittsburgh, Pennsylvania, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '99},
	pages        = {294--301},
	keywords     = {cscw, multiparty; VRML 2; attention; gaze direction; awareness; multiparty videoconferencing; eyetracking;litsurvey.bib}
}

@inproceedings{Vertegaal1997,
	title        = {Catching the eye: management of joint attention in cooperative work},
	author       = {Vertegaal, Roel},
	year         = 1997,
	keywords     = {litsurvey.bib}
}

@inproceedings{Vertegaal2002,
	title        = {Explaining effects of eye gaze on mediated group conversations: amount or synchronization?},
	author       = {Vertegaal, Roel and Ding, Yaping},
	year         = 2002,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2002 {ACM} conference on Computer supported cooperative work},
	location     = {New Orleans, Louisiana, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '02},
	pages        = {41--48},
	institution  = {IEEE},
	keywords     = {gaze, eye tracking, avatars, attentive interfaces, agents, multiparty mediated communication;litsurvey.bib}
}

@inproceedings{Vertegaal2001,
	title        = {Eye gaze patterns in conversations: there is more to conversational agents than meets the eyes},
	author       = {Vertegaal, Roel and Slagter, Robert and van der Veer, Gerrit and Nijholt, Anton},
	year         = 2001,
	month        = {\#mar\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Seattle, Washington, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '01},
	pages        = {301--308},
	keywords     = {attention-based interfaces, attentive agents, communication, conversational attention, eye tracking, gaze, multiparty; multiparty communication; tracking;litsurvey.bib}
}

@inproceedings{Vertegaal2000,
	title        = {Effects of gaze on multiparty mediated communication},
	author       = {Vertegaal, Roel and Van der Veer, Gerrit and Vons, Harro},
	year         = 2000,
	booktitle    = {Graphics interface},
	publisher    = {Morgan Kaufmann},
	pages        = {95--102},
	keywords     = {litsurvey.bib}
}

@inproceedings{Vetere2005,
	title        = {Mediating intimacy: designing technologies to support strong-tie relationships},
	author       = {Vetere, Frank and Gibbs, Martin R and Kjeldskov, Jesper and Howard, Steve and Mueller, Florian 'floyd' and Pedell, Sonja and Mecoles, Karen and Bunyan, Marcus},
	year         = 2005,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Portland, Oregon, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '05},
	pages        = {471--480},
	institution  = {ACM},
	keywords     = {intimacy, intimate technology, participatory design, tactile interfaces, cultural probes, ethnography;litsurvey.bib}
}

@inproceedings{Vidal2019,
	title        = {Semantic Data Integration Techniques for Transforming Big Biomedical Data into Actionable Knowledge},
	author       = {Vidal, Maria-Esther and Jozashoori, Samaneh},
	year         = 2019,
	booktitle    = {2019 IEEE 32nd International Symposium on Computer-Based Medical Systems (CBMS)},
	pages        = {563--566},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08787394.pdf:PDF}
}

@book{Vigna2016,
	title        = {The age of cryptocurrency: how bitcoin and the blockchain are challenging the global economic order},
	author       = {Vigna, Paul and Casey, Michael J},
	year         = 2016,
	publisher    = {Macmillan},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/The Age of Cryptocurrency _ How - Michael J. Casey.pdf:PDF}
}

@book{Vince1995,
	title        = {{Virtual reality systems}},
	author       = {Vince, John},
	year         = 1995,
	publisher    = {Pearson Education India},
	keywords     = {litsurvey.bib}
}

@inproceedings{Vishwanath2005,
	title        = {Why pictures look right when viewed from the wrong place},
	author       = {Vishwanath, Dhanraj and Girshick, Ahna R and Banks, Martin S},
	year         = 2005,
	publisher    = {Nature Publishing Group},
	volume       = 8,
	pages        = {1401--1410},
	keywords     = {litsurvey.bib}
}

@inproceedings{Voida2012,
	title        = {Cross-cutting faultlines of location and shared identity in the intergroup cooperation of partially distributed groups},
	author       = {Voida, Amy and Bos, Nathan and Olson, Judith and Olson, Gary and Dunning, Lauren},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {3101--3110},
	institution  = {ACM},
	keywords     = {shared identity, faultline, partially distributed work, intergroup cooperation;litsurvey.bib}
}

@misc{w3cSemantic,
	title        = {Semantic Web Standard pages},
	author       = {W3C},
	year         = 2015,
	url          = {https://www.w3.org/standards/semanticweb/@MISC{w3cSemantic, author = {W3C}, title = {Semantic Web Standard pages}, year = {2015}, owner = {its352}, timestamp = {2021.12.02}, url = {https://www.w3.org/standards/semanticweb/} }},
	owner        = {its352},
	timestamp    = {2021.12.02}
}

@inproceedings{Wada2000,
	title        = {Homography based parallel volume intersection: toward real-time volume reconstruction using active cameras},
	author       = {Wada, T and {Xiaojun Wu} and Tokai, S and Matsuyama, T},
	year         = 2000,
	month        = {\#sep\#},
	booktitle    = {Proceedings Fifth {IEEE} International Workshop on Computer Architectures for Machine Perception},
	address      = {Padova},
	pages        = {331--339},
	abstract     = {Silhouette volume intersection is one of the most popular ideas for reconstructing the 3D volume of an object from multi-viewpoint silhouette images. This paper presents a novel parallel volume intersection method based on plane-to-plane homography for real-time 3D volume reconstruction using active cameras. This paper mainly focuses on the acceleration of back-projection from silhouette images to 3D space without using any sophisticated software technique, such as octree volume representation, or look-up table based projection acceleration. Also this paper presents a parallel intersection method of projected silhouette images. From the preliminary experimental results we estimate near frame-rate volume reconstruction for a life-sized mannequin can be achieved at 3 cm spatial resolution on our PC cluster system.},
	keywords     = {image reconstruction;real-time volume reconstruction;active cameras;parallel volume intersection;back-projection;silhouette images;octree volume representation;projection acceleration;projected silhouette images;frame-rate volume reconstruction;Cameras;Image reconstruction;Optical sensors;Spatial resolution;Biomedical optical imaging;Magnetic field measurement;Shape measurement;Acceleration;Humans;Magnetic sensors;litsurvey.bib}
}

@inproceedings{Waizenegger2011,
	title        = {Patch-sweeping with robust prior for high precision depth estimation in real-time systems},
	author       = {Waizenegger, W and Atzpadin, N and Schreer, O and Feldmann, I},
	year         = 2011,
	month        = {\#sep\#},
	booktitle    = {2011 18th {IEEE} International Conference on Image Processing},
	pages        = {881--884},
	abstract     = {This paper presents a novel real-time approach for robust high precision and high quality depth estimation. It extends recent work on real-time Patch-Sweeping by combining the advantages of a robust hybrid stereo-based disparity estimator with the high accuracy of the Patch-Sweeping approach. It over- comes limitations of the existing Patch-Sweep approach, such as limited search range. Further, it implicitly benefits from the high robustness as well as time consistency of the disparity estimator. The presented overall algorithmic system concept introduces a powerful alternative to traditional real-time depth estimation approaches. Additionally, the proposed algorithmic structures allow a high degree of parallelization. Based on this, the computational effort could be efficiently balanced between GPU and CPU processing. The target platform of the proposed algorithmic chain is a real-time immersive 3D video communication system which requires highly accurate 3D estimation results for a high quality virtual eye contact generation.},
	institution  = {IEEE},
	keywords     = {estimation theory;graphics processing units;multiprocessing systems;real-time systems;solid modelling;stereo image processing;video communication;robust high precision;robust high quality depth estimation;real-time patch sweeping approach;robust hybrid stereo-based disparity estimator;search range;time consistency;overall algorithmic system;high parallelization degree;GPU processing;CPU processing;real-time immersive 3D video communication system;high quality virtual eye contact generation;3D estimation;Three dimensional displays;Real time systems;Streaming media;Estimation;Robustness;Cameras;Conferences;Patch sweeping;HRM;Depth estimation;3D Video Communication;Real-time;GPGPU;Cuda;litsurvey.bib}
}

@article{Walther2002,
	title        = {Cues filtered out, cues filtered in},
	author       = {Walther, Joseph B and Parks, Malcolm R},
	year         = 2002,
	journal      = {Handbook of interpersonal communication},
	publisher    = {researchgate.net},
	volume       = 3,
	pages        = {529--563},
	abstract     = {Iii---``August 1998, news of the results of a dy soon to be published in the American Psychologist sent shock waves through the Internet community and, to no small extent, through public discourse about the social impact of the Internet. Robert Kraut and his colleagues (1998) had found that Internet use in a sample of 93 families had resulted in small but significant increases in loneliness, social isolation, and depression over a 2-year period. The researchers asserted that the},
	keywords     = {litsurvey.bib}
}

@incollection{Walther2002,
	title        = {{Cues filtered out, cues filtered in: Computer-mediated communication and relationships}},
	author       = {Walther, J B and Parks, M R and Knapp, I M L and Daly, J A},
	year         = 2002,
	booktitle    = {Handbook of Interpersonal Communication},
	publisher    = {Sage Publications},
	volume       = {3\textbackslashtextsuperscriptrd},
	pages        = {529--563},
	editor       = {Knapp, Mark L and Daly, John A},
	keywords     = {litsurvey.bib}
}

@inproceedings{Wang2014,
	title        = {Parallel frequent pattern mining without candidate generation on GPUs},
	author       = {Wang, Fei and Yuan, Bo},
	year         = 2014,
	booktitle    = {2014 IEEE International Conference on Data Mining Workshop},
	pages        = {1046--1052},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/GPU - accelerated/07022712.pdf:PDF}
}

@article{Wang2018,
	title        = {Big data analytics: Understanding its capabilities and potential benefits for healthcare organizations},
	author       = {Wang, Yichuan and Kung, LeeAnn and Byrd, Terry Anthony},
	year         = 2018,
	journal      = {Technological Forecasting and Social Change},
	publisher    = {Elsevier},
	volume       = 126,
	pages        = {3--13},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/1-s2.0-S0040162516000500-main.pdf:PDF}
}

@inproceedings{Watanabe2017,
	title        = {A Scatterplots Selection Technique for Multi-Dimensional Data Visualization Combining with Parallel Coordinate Plots},
	author       = {Watanabe, Ayaka and Itoh, Takayuki and Chiba, Kazuhisa and Kanazaki, Masahiro},
	year         = 2017,
	booktitle    = {2017 21st International Conference Information Visualisation (IV)},
	pages        = {78--83},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08107951.pdf:PDF}
}

@article{Watson1966,
	title        = {{Quantitative Research in Proxemic Behavior}},
	author       = {Watson, O Michael and Graves, Theodore D},
	year         = 1966,
	month        = {\#aug\#},
	journal      = {Am. Anthropol.},
	volume       = 68,
	number       = 4,
	pages        = {971--985},
	abstract     = {Proxemics is the study of how man structures microspace, how he relates physically to other persons with whom he is interacting, and what is communicated by these physical relationships. Edward Hall, who coined the term ?proxemics? and devised a system of notation for recording proxemic behavior, reports many impressionistic observations on Arab and American proxemic differences. To test these hypotheses systematically, 32 Arab and American college students were observed under controlled conditions and their proxemic behavior recorded. The Arabs and Americans were found to differ significantly in proxemic behavior, the Arabs interacting with each other closer and more directly than Americans, as hypothesized.},
	keywords     = {litsurvey.bib}
}

@incollection{Weissig2012,
	title        = {The Ultimate Immersive Experience: Panoramic {3D} Video Acquisition},
	author       = {Weissig, Christian and Schreer, Oliver and Eisert, Peter and Kauff, Peter},
	year         = 2012,
	booktitle    = {Advances in Multimedia Modeling},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	series       = {Lecture Notes in Computer Science},
	volume       = 7131,
	pages        = {671--681},
	editor       = {Schoeffmann, Klaus and Merialdo, Bernard and Hauptmann, Alexander G and Ngo, Chong-Wah and Andreopoulos, Yiannis and Breiteneder, Christian},
	keywords     = {litsurvey.bib}
}

@phdthesis{Wen2013,
	title        = {Revisiting aggregation techniques for data intensive applications},
	author       = {Wen, Jian},
	year         = 2013,
	school       = {UC Riverside},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/Revisiting Aggregation Techniques for Data Int.pdf:PDF}
}

@article{Werkhoven2001,
	title        = {Seeing is believing: communication performance under isotropic teleconferencing conditions},
	author       = {Werkhoven, Peter J and Schraagen, Jan Maarten and Punte, Patrick A J},
	year         = 2001,
	month        = {\#sep\#},
	journal      = {Displays},
	publisher    = {Elsevier},
	volume       = 22,
	number       = 4,
	pages        = {137--149},
	abstract     = {The visual component of conversational media such as videoconferencing systems communicates important non-verbal information such as facial expressions, gestures, posture and gaze. Unlike the other cues, selective gaze depends critically on the configuration of cameras and monitors. Under isotropic videoconferencing conditions people see each other in spatially consistent directions (shared video space). Isotropy is hypothesized to regulate the interactional process of conversation. Further, it is hypothesized that isotropy increases social nearness which increases persuasive force but decreases the exchange of information in group discussion tasks. We have studied the interactional process and task outcome of two discussion tasks under isotropic and (standard) non-isotropic videoconferencing conditions relative to face-to-face conditions. The communication of unshared information was tested in a `hidden profile' task by Stasser et al.[Journal of Experimental Social Psychology 31 (1995) 244]. Dominance and persuasive force were revealed using a prioritization game of survival items called `Lost at the moon', featuring a dominant confederate. The results support our hypotheses and have revealed that persuasive force (the ability to change another person's opinion) is significantly stronger under isotropic conditions (including face-to-face) than under non-isotropic conditions. In contrast, dominance (the ability to influence group solutions by dominant behavior) is similar for all conditions. Further, participants communicate almost twice as much unshared information under mediated conditions than under the face-to-face condition.},
	keywords     = {Videoconferencing; Shared video space; Communication performance; Persuasive force; Information sharing;litsurvey.bib}
}

@article{Werner2016,
	title        = {A lost century in economics: Three theories of banking and the conclusive evidence},
	author       = {Werner, Richard A},
	year         = 2016,
	journal      = {International Review of Financial Analysis},
	publisher    = {Elsevier},
	volume       = 46,
	pages        = {361--379},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/bitcoin/1-s2.0-S1057521915001477-main.pdf:PDF}
}

@article{Wheeler2018,
	title        = {Virtual interaction and visualisation of 3D medical imaging data with VTK and Unity},
	author       = {Wheeler, Gavin and Deng, Shujie and Toussaint, Nicolas and Pushparajah, Kuberan and Schnabel, Julia A and Simpson, John M and Gomez, Alberto},
	year         = 2018,
	journal      = {Healthcare technology letters},
	publisher    = {IET},
	volume       = 5,
	number       = 5,
	pages        = {148--153},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Mining/volumeMedical/HTL.2018.5064.pdf:PDF}
}

@article{Williams1977,
	title        = {Experimental comparisons of face-to-face and mediated communication: A review},
	author       = {Williams, Ederyn},
	year         = 1977,
	journal      = {Psychol. Bull.},
	publisher    = {American Psychological Association},
	volume       = 84,
	number       = 5,
	pages        = 963,
	keywords     = {litsurvey.bib}
}

@inproceedings{Wilson2012,
	title        = {Steerable augmented reality with the beamatron},
	author       = {Wilson, Andrew and Benko, Hrvoje and Izadi, Shahram and Hilliges, Otmar},
	year         = 2012,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 25th annual {ACM} symposium on User interface software and technology},
	location     = {Cambridge, Massachusetts, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '12},
	pages        = {413--422},
	institution  = {ACM},
	keywords     = {steerable displays, ubiquitous computing, augmented reality, depth cameras;litsurvey.bib}
}

@inproceedings{Wilson2000,
	title        = {Perception of head orientation},
	author       = {Wilson, Hugh R and Wilkinson, Frances and Lin, Li-Ming and Castillo, Maja},
	year         = 2000,
	publisher    = {Elsevier},
	volume       = 40,
	pages        = {459--472},
	keywords     = {litsurvey.bib}
}

@article{Wolff2014,
	title        = {A modular architecture for an interactive real-time simulation and training environment for satellite on-orbit servicing},
	author       = {Wolff, Robin and Preusche, Carsten and Gerndt, Andreas},
	year         = 2014,
	month        = {\#feb\#},
	journal      = {Journal of Simulation},
	publisher    = {Taylor \& Francis},
	volume       = 8,
	number       = 1,
	pages        = {50--63},
	abstract     = {AbstractMaintaining or repairing satellites in orbit is a delicate task that requires expert skills. The planning, training and analysis of on-orbit servicing (OOS) missions performed by astronauts or through remote operation using a robot is often time consuming and costly. Virtual Reality (VR) enables simulation and training in a flexible and safe environment. This paper describes an interactive real-time environment that supports a number of OOS tasks within an immersive VR environment. The system simulates the dynamic and kinematic behaviour of satellite components and provides photo-realistic visualization of satellite parts and the space environment. It integrates user interaction with haptic force feedback through a bi-manual haptic human machine interface, as well as simulates and interfaces to a humanoid robot for tele-operation.In order to provide a realistic experience at interactive frame rates, we propose a distributed system architecture, where the load of computing the physics simulation, haptic feedback and visualization of the complex scene is transferred to dedicated machines. The modular architecture is designed to allow the inclusion of further simulation processes. Several mechanisms for reducing the communication traffic have been implemented. This paper gives an overview of the system architecture, outlines the software implementation and documents an evaluation of the real-time performance of our system in detail. We describe how system performance was measured in terms of simulation timings and distribution load, as well as report on latencies at several stages. Results show that our distributed system is capable of providing visual and haptic feedback at high frame rates required for user interaction with end-to-end latencies of less than 8?ms and 3?ms, respectively.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Wolff2008,
	title        = {Communicating Eye Gaze across a Distance without Rooting Participants to the Spot},
	author       = {Wolff, R and Roberts, D and Murgia, A and Murray, N and Rae, J and Steptoe, W and Steed, A and Sharkey, P},
	year         = 2008,
	month        = {\#oct\#},
	booktitle    = {2008 12th {IEEE/ACM} International Symposium on Distributed Simulation and {Real-Time} Applications},
	publisher    = {Ieee},
	pages        = {111--118},
	abstract     = {Eye gaze is an important conversational resource that until now could only be supported across a distance if people were rooted to the spot. We introduce EyeCVE, the worldpsilas first tele-presence system that allows people in different physical locations to not only see what each other are doing but follow each otherpsilas eyes, even when walking about. Projected into each space are avatar representations of remote participants, that reproduce not only body, head and hand movements, but also those of the eyes. Spatial and temporal alignment of remote spaces allows the focus of gaze as well as activity and gesture to be used as a resource for non-verbal communication. The temporal challenge met was to reproduce eye movements quick enough and often enough to interpret their focus during a multi-way interaction, along with communicating other verbal and non-verbal language. The spatial challenge met was to maintain communicational eye gaze while allowing free movement of participants within a virtually shared common frame of reference. This paper reports on the technical and especially temporal characteristics of the system.},
	keywords     = {biology computing;eye;virtual reality;eye gaze;EyeCVE;tele-presence system;avatar representations;nonverbal communication;physical locations;eye movements;Cameras;Videoconference;Avatars;Video sharing;Virtual environment;Humans;Eyes;Head;Focusing;Displays;litsurvey.bib}
}

@inproceedings{Wollaston1824,
	title        = {On the apparent direction of eyes in a portrait},
	author       = {Wollaston, William Hyde},
	year         = 1824,
	publisher    = {JSTOR},
	pages        = {247--256},
	keywords     = {litsurvey.bib}
}

@article{wonglimpiyarat2016s,
	title        = {S-curve trajectories of electronic money innovations},
	author       = {Wonglimpiyarat, Jarunee},
	year         = 2016,
	journal      = {The Journal of High Technology Management Research},
	publisher    = {Elsevier},
	volume       = 27,
	number       = 1,
	pages        = {1--9}
}

@inproceedings{Wu2003,
	title        = {Real-time active 3d shape reconstruction for 3d video},
	author       = {Wu, T and Matsuyama, T},
	year         = 2003,
	booktitle    = {Image and Signal Processing and Analysis, 2003. {ISPA} 2003. Proceedings of the 3\textbackslashtextsuperscript{rd} International Symposium on},
	volume       = 1,
	pages        = {186--191},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@inproceedings{Xiaojun_Wu2006,
	title        = {{Parallel Pipeline Volume Intersection for {Real-Time} {3D} Shape Reconstruction on a {PC} Cluster}},
	author       = {{Xiaojun Wu} and Takizawa, O and Matsuyama, T},
	year         = 2006,
	month        = {\#jan\#},
	booktitle    = {Fourth {IEEE} International Conference on Computer Vision Systems ({ICVS'06})},
	address      = {New York},
	pages        = {4--4},
	abstract     = {The human activity monitoring is one of the major tasks in the field of computer vision. Recently, not only the 2D images but also 3D shapes of a moving person are desired in kinds of cases, such as motion analysis, security monitoring, 3D video creation and so on. In this paper, we propose a parallel pipeline system on a PC cluster for reconstructing the 3D shape of a moving person in real-time. For the 3D shape reconstruction, we have extended the volume intersection method to the 3-base-plane volume intersection. By thus extension, the computation is accelerated greatly for arbitrary camera layouts. We also parallelized the 3-base-plane method and implemented it on a PC cluster. On each node, the pipeline processing is adopted to improve the throughput. To decrease the CPU idle time caused by I/O processing, image capturing, communications over nodes and so on, we implement the pipeline using multiple threads. So that, all stages can be executed concurrently. However, there exists resource conflicts between stages in a real system. To avoid the conflicts while keeping high percentage of CPU running time, we propose a tree structured thread control model. As a result, We achieve the performance as obtaining the full 3D volumes of a moving person at about 12 frames per second, where the voxel size is 5$\times$5$\times$5 [mm^3]. The effectiveness of the thread tree model in such real-time computation is also proved by the experimental results.},
	keywords     = {Shape;Pipeline processing;Image reconstruction;Yarn;Computerized monitoring;Humans;Computer vision;Motion analysis;Real time systems;Acceleration;litsurvey.bib}
}

@inproceedings{Xu2012,
	title        = {Learning how to feel again: towards affective workplace presence and communication technologies},
	author       = {Xu, Anbang and Biehl, Jacob and Rieffel, Eleanor and Turner, Thea and van Melle, William},
	year         = 2012,
	month        = {\#may\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Austin, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '12},
	pages        = {839--848},
	institution  = {ACM},
	keywords     = {affect awareness, myunity, workplace communication, affect, presence, affect computing;litsurvey.bib}
}

@inproceedings{Yamashita2008,
	title        = {Impact of seating positions on group video communication},
	author       = {Yamashita, Naomi and Hirata, Keiji and Aoyagi, Shigemi and Kuzuoka, Hideaki and Harada, Yasunori},
	year         = 2008,
	month        = {\#nov\#},
	booktitle    = {Proceedings of the 2008 {ACM} conference on Computer supported cooperative work},
	location     = {San Diego, CA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '08},
	pages        = {177--186},
	institution  = {ACM},
	keywords     = {empirical study, group-to-group meeting, computer-supported cooperative work, conversational analysis, seating position, video-mediated communication;litsurvey.bib}
}

@inproceedings{Yang2016,
	title        = {Research on Network Security Visualization under Big Data Environment},
	author       = {Yang, Tingting and Jia, Shuwen},
	year         = 2016,
	booktitle    = {2016 International Computer Symposium (ICS)},
	pages        = {660--662},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/07858557.pdf:PDF}
}

@article{Yang2018,
	title        = {Origin-destination flow maps in immersive environments},
	author       = {Yang, Yalong and Dwyer, Tim and Jenny, Bernhard and Marriott, Kim and Cordeil, Maxime and Chen, Haohui},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 25,
	number       = 1,
	pages        = {693--703},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08440844.pdf:PDF}
}

@inproceedings{Yee2007,
	title        = {A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces},
	author       = {Yee, Nick and Bailenson, Jeremy N and Rickertsen, Kathryn},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1--10},
	institution  = {ACM},
	keywords     = {computer-mediated communication, embodied agents, meta-analysis, quantitative methods, realism;litsurvey.bib}
}

@inproceedings{Yee2007,
	title        = {The unbearable likeness of being digital: the persistence of nonverbal social norms in online virtual environments},
	author       = {Yee, Nick and Bailenson, Jeremy N and Urbanek, Mark and Chang, Francis and Merget, Dan},
	year         = 2007,
	volume       = 10,
	pages        = {115--121},
	abstract     = {Every day, millions of users interact in real-time via avatars in online environments, such as massively-multiplayer online role-playing games (MMORPGs). These online environments could potentially be unique research platforms for the social sciences and clinical therapy, but it is crucial to first establish that social behavior and norms in virtual environments are comparable to those in the physical world. In an observational study of Second Life, a virtual community, we collected data from avatars in order to explore whether social norms of gender, interpersonal distance (IPD), and eye gaze transfer into virtual environments even though the modality of movement is entirely different (i.e., via keyboard and mouse as opposed to eyes and legs). Our results showed that established findings of IPD and eye gaze transfer into virtual environments: (1) male-male dyads have larger IPDs than female-female dyads, (2) male-male dyads maintain less eye contact than female-female dyads, and (3) decreases in IPD are compensated with gaze avoidance as predicted by the Equilibrium Theory. We discuss implications for users of online games as well as for social scientists who seek to conduct research in virtual environments.},
	keywords     = {Adult, Female, Humans, Internet, Internet: statistics \& numerical data, Male, Nonverbal Communication, Social Behavior, Social Distance, User-Computer Interface;litsurvey.bib}
}

@article{Yendo2010,
	title        = {The Seelinder: Cylindrical {3D} display viewable from 360 degrees},
	author       = {Yendo, Tomohiro and Fujii, Toshiaki and Tanimoto, Masayuki and Panahpour Tehrani, Mehrdad},
	year         = 2010,
	month        = {\#jul\#},
	journal      = {J. Vis. Commun. Image Represent.},
	publisher    = {Elsevier},
	volume       = 21,
	number       = 5,
	pages        = {586--594},
	abstract     = {We propose a 3D video display technique that allows multiple viewers to see 3D images from a 360-degree horizontal arc without wearing 3D glasses. This technique uses a cylindrical parallax barrier and a one-dimensional light source array. We have developed an experimental display system using this technique. Since this technique is based on the parallax panoramagram, the parallax number and resolution are limited by the diffraction at the parallax barrier. In order to solve this problem, we improved the technique by revolving the parallax barrier. The improved technique was incorporated into two experimental display systems. The newer one is capable of displaying 3D color video images within a 200-mm diameter and a 256-mm height. Images have a resolution of 1254 circumferential pixels and 256 vertical pixels, and are refreshed at 30Hz. Each pixel has a viewing angle of 60 degrees that is divided into over 70 views so that the angular parallax interval of each pixel is less than 1 degree. These pixels are arranged on a cylindrical surface to allow for the produced 3D images to be observed from all directions. In this case, observers may barely perceive the discrete parallax.},
	keywords     = {Autostereoscopic display; Multi-view; Omnidirectional; Ray-space; Light field; Parallax barrier;litsurvey.bib}
}

@inproceedings{Yoo2018,
	title        = {Adapting Data from Physical Activity Sensors for Visualising Exertion in Virtual Reality Games},
	author       = {Yoo, Soojeong and Parker, Callum and Kay, Judy},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers},
	pages        = {307--310},
	organization = {ACM},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/p307-Yoo.pdf:PDF}
}

@misc{Yougov2020,
	title        = {Yougov poll about returning to normal},
	author       = {{Yougov}},
	year         = 2020,
	howpublished = {\url{https://news.sky.com/story/coronavirus-only-9-of-britons-want-life-to-return-to-normal-once-lockdown-is-over-11974459}},
	keywords     = {litsurvey.bib}
}

@article{Young2006,
	title        = {Remembering the evolutionary Freud},
	author       = {Young, Allan},
	year         = 2006,
	month        = {\#mar\#},
	journal      = {Sci. Context},
	volume       = 19,
	number       = 1,
	pages        = {175--189},
	abstract     = {Throughout his career as a writer, Sigmund Freud maintained an interest in the evolutionary origins of the human mind and its neurotic and psychotic disorders. In common with many writers then and now, he believed that the evolutionary past is conserved in the mind and the brain. Today the ``evolutionary Freud'' is nearly forgotten. Even among Freudians, he is regarded to be a red herring, relevant only to the extent that he diverts attention from the enduring achievements of the authentic Freud. There are three ways to explain these attitudes. First, the evolutionary Freud's key work is the ``Overview of the Transference Neurosis'' (1915). But it was published at an inopportune moment, forty years after the author's death, during the so-called ``Freud wars.'' Second, Freud eventually lost interest in the ``Overview'' and the prospect of a comprehensive evolutionary theory of psychopathology. The publication of The Ego and the Id (1923), introducing Freud's structural theory of the psyche, marked the point of no return. Finally, Freud's evolutionary theory is simply not credible. It is based on just-so stories and a thoroughly discredited evolutionary mechanism, Lamarckian use-inheritance. Explanations one and two are probably correct but also uninteresting. Explanation number three assumes that there is a fundamental difference between Freud's evolutionary narratives (not credible) and the evolutionary accounts of psychopathology that currently circulate in psychiatry and mainstream journals (credible). The assumption is mistaken but worth investigating.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Zagarskikh2015,
	title        = {Efficient Visualization of Urban Simulation Data Using Modern GPUs},
	author       = {Zagarskikh, Aleksandr and Karsakov, Andrey and Bezgodov, Alexey},
	year         = 2015,
	journal      = {Procedia Computer Science},
	publisher    = {Elsevier},
	volume       = 51,
	pages        = {2928--2932},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/82249012.pdf:PDF}
}

@article{Zajonc1980,
	title        = {Feeling and thinking: Preferences need no inferences},
	author       = {Zajonc, Robert B},
	year         = 1980,
	journal      = {Am. Psychol.},
	publisher    = {American Psychological Association},
	volume       = 35,
	number       = 2,
	pages        = 151,
	keywords     = {litsurvey.bib}
}

@inproceedings{Zanbaka2007,
	title        = {Social responses to virtual humans: implications for future interface design},
	author       = {Zanbaka, Catherine Amine and Ulinski, Amy Catherine and Goolkasian, Paula and Hodges, Larry F},
	year         = 2007,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {San Jose, California, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '07},
	pages        = {1561--1570},
	institution  = {ACM},
	keywords     = {virtual humans, experimental studies, interface agents, human-computer interaction, social facilitation and inhibition, social influence, avatars, social psychology;litsurvey.bib}
}

@inproceedings{zeng2019data,
	title        = {Data Visualization for Air Quality Analysis on Bigdata Platform},
	author       = {Zeng, Yu-Ren and Chang, Yue Shan and Fang, You Hao},
	year         = 2019,
	booktitle    = {2019 International Conference on System Science and Engineering (ICSSE)},
	pages        = {313--317},
	organization = {IEEE},
	file         = {:C\:/Users/its352/Google Drive/DataVis/literature_repository/Data Visualisation/08823437.pdf:PDF}
}

@inproceedings{Zhang_Shujun2009,
	title        = {{{DreamWorld}: {{CUDA}-accelerated} real-time {3D} modeling system}},
	author       = {{Zhang Shujun} and {Wang Cong} and {Shao Xuqiang} and {Wu Wei}},
	year         = 2009,
	month        = {\#may\#},
	booktitle    = {2009 {IEEE} International Conference on Virtual Environments, {Human-Computer} Interfaces and Measurements Systems},
	address      = {Hong Kong},
	pages        = {168--173},
	abstract     = {3D modeling plays an important role in virtual reality interaction, immersive tele-presence and other applications. A CUDA-accelerated real-time 3D modeling system is presented in this paper. It captures multi-view images of objects and achieves real-time accurate visual hull reconstruction with texture mapping. The system includes off-line camera calibration and on-line visual hull modeling based on our DreamWorld hardware. The multi-camera based modeling process is composed of distributed image acquisition, silhouette extraction, data transmission, visual hull computation and rendering. Initially, the volumetric visual hull is computed through intersection test of voxels with each silhouette and then, a CUDA-based simplified exact marching cubes algorithm is put forward to get a polyhedral mesh model for texture mapping and rendering. Preliminary experimental results from both synthetic and real data show its accuracy, stability and real-time performance.},
	keywords     = {calibration;cameras;computational geometry;image reconstruction;image texture;real-time systems;rendering (computer graphics);solid modelling;virtual reality;CUDA-accelerated real-time 3D modeling system;DreamWorld hardware;virtual reality interaction;immersive tele-presence;multiview object image;accurate visual hull reconstruction;texture mapping;offline camera calibration;online visual hull modeling;distributed image acquisition;silhouette extraction;data transmission;visual hull computation;rendering;volumetric visual hull;marching cube algorithm;Real time systems;Rendering (computer graphics);Virtual reality;Image reconstruction;Cameras;Calibration;Hardware;Data mining;Data communication;Distributed computing;3D modeling;visual hull;CUDA;marching cubes;litsurvey.bib}
}

@article{Zhang2007,
	title        = {Camera calibration from images of spheres},
	author       = {Zhang, Hui and Wong, Kwan-Yee K and Zhang, Guoqiang},
	year         = 2007,
	month        = {\#mar\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	volume       = 29,
	number       = 3,
	pages        = {499--503},
	abstract     = {This paper introduces a novel approach for solving the problem of camera calibration from spheres. By exploiting the relationship between the dual images of spheres and the dual image of the absolute conic (IAC), it is shown that the common pole and polar with regard to the conic images of two spheres are also the pole and polar with regard to the IAC. This provides two constraints for estimating the IAC and, hence, allows a camera to be calibrated from an image of at least three spheres. Experimental results show the feasibility of the proposed approach.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@article{Zhang2008,
	title        = {{Three-dimensional shape measurement using a structured light system with dual cameras}},
	author       = {Zhang, Song and Yau, Shing-Tung},
	year         = 2008,
	month        = {\#jan\#},
	journal      = {Organ. Ethic.},
	publisher    = {International Society for Optics and Photonics},
	volume       = 47,
	number       = 1,
	pages        = {013604},
	abstract     = {A structured light system for three-dimensional shape measurement with single camera has the shortcoming of camera occlusion. To alleviate this problem, this paper introduces a structured light system with dual cameras for three-dimensional shape measurement. We discuss (1) system description, (2) system calibration, (3) three-dimensional data registration using the iterative closest-point (ICP) algorithm, and (4) three-dimensional data merging using holoimage. The principle of the system is introduced, and experiments are presented to verify its performance.},
	keywords     = {calibration; structured light; dual cameras; holoimage; registration; phase shifting; merging; Cameras; Imaging systems; Calibration; Projection systems; 3D image processing; 3D metrology; Structured light; 3D modeling; Optical engineering; Nose; ; ; ; ; ; ; ; ; ; ; ;litsurvey.bib}
}

@inproceedings{Zhang2010,
	title        = {Modeling dwell-based eye pointing target acquisition},
	author       = {Zhang, Xinyong and Ren, Xiangshi and Zha, Hongbin},
	year         = 2010,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Atlanta, Georgia, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '10},
	pages        = {2083--2092},
	keywords     = {information theory, modeling, eye pointing, fitts' law;litsurvey.bib}
}

@inproceedings{Zhang2013,
	title        = {{SideWays}: a gaze interface for spontaneous interaction with situated displays},
	author       = {Zhang, Yanxia and Bulling, Andreas and Gellersen, Hans},
	year         = 2013,
	month        = {\#apr\#},
	booktitle    = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	location     = {Paris, France},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '13},
	pages        = {851--860},
	institution  = {ACM},
	keywords     = {spontaneous interaction, eye tracking, calibration-free, eye-based interaction, situated display;litsurvey.bib}
}

@article{Zhang2004,
	title        = {{Camera calibration with one-dimensional objects}},
	author       = {Zhang, Zhengyou},
	year         = 2004,
	month        = {\#jul\#},
	journal      = {IEEE Trans. Pattern Anal. Mach. Intell.},
	volume       = 26,
	number       = 7,
	pages        = {892--899},
	abstract     = {Camera calibration has been studied extensively in computer vision and photogrammetry and the proposed techniques in the literature include those using 3D apparatus (two or three planes orthogonal to each other or a plane undergoing a pure translation, etc.), 2D objects (planar patterns undergoing unknown motions), and 0D features (self-calibration using unknown scene points). Yet, this paper proposes a new calibration technique using 1D objects (points aligned on a line), thus filling the missing dimension in calibration. In particular, we show that camera calibration is not possible with free-moving 1D objects, but can be solved if one point is fixed. A closed-form solution is developed if six or more observations of such a 1D object are made. For higher accuracy, a nonlinear technique based on the maximum likelihood criterion is then used to refine the estimate. Singularities have also been studied. Besides the theoretical aspect, the proposed technique is also important in practice especially when calibrating multiple cameras mounted apart from each other, where the calibration objects are required to be visible simultaneously.},
	keywords     = {litsurvey.bib},
	language     = {en}
}

@incollection{Zhao2011,
	title        = {Chapter 31 - {Real-Time} Stereo on {GPGPU} Using Progressive Multiresolution Adaptive Windows},
	author       = {Zhao, Yong and Taubin, Gabriel},
	year         = 2011,
	month        = {\#jan\#},
	booktitle    = {{GPU} Computing Gems Emerald Edition},
	publisher    = {Morgan Kaufmann},
	address      = {Boston},
	volume       = 29,
	pages        = {473--495},
	editor       = {Hwu, Wen-Mei W},
	abstract     = {Publisher Summary This chapter presents a new GPGPU-based real-time dense stereo-matching algorithm. The algorithm is based on a progressive multiresolution pipeline that includes background modeling and dense matching with adaptive windows. For applications in which only moving objects are of interest, this approach effectively reduces the overall computation cost quite significantly and preserves the high definition details. Estimating depth from stereo is a classic computer vision problem, which has received tremendous attention since the early days. Recovering 3D information from a pair of stereo cameras has been a popular topic because the additional 3D information provided by this technology contains significantly more information than 2D information produced by traditional cameras. Some believe that this technology will fundamentally revolutionize the computer vision signal-processing pipeline, as well as how future cameras will be built. The current implementation achieves 36 Hz stereo matching on 1024 $\times$ 768 stereo video with a fine 256-pixel disparity range. The focus of this work is to provide efficient high-resolution stereo algorithms for real-time applications in which only foreground moving objects are of interest, such as motion capture, object tracking, and recognition and identification in a surveillance scenario.},
	keywords     = {litsurvey.bib}
}

@inproceedings{Zillner2014,
	title        = {3D-board: a whole-body remote collaborative whiteboard},
	author       = {Zillner, Jakob and Rhemann, Christoph and Izadi, Shahram and Haller, Michael},
	year         = 2014,
	month        = {\#oct\#},
	booktitle    = {Proceedings of the 27th annual {ACM} symposium on User interface software and technology},
	location     = {Honolulu, Hawaii, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '14},
	pages        = {471--479},
	institution  = {ACM},
	keywords     = {interactive whiteboard, reconstruction, remote collaboration, shared workspace, teleconferencing;litsurvey.bib}
}

@article{zong2020interactive,
	title        = {Interactive three-dimensional visualization of network intrusion detection data for machine learning},
	author       = {Zong, Wei and Chow, Yang-Wai and Susilo, Willy},
	year         = 2020,
	journal      = {Future Generation Computer Systems},
	publisher    = {Elsevier},
	volume       = 102,
	pages        = {292--306},
	file         = {:../../../literature_repository/Data Visualisation/1-s2.0-S0167739X18331091-main.pdf:PDF}
}

@misc{Zoom2020,
	title        = {Zoom daily {200M} users message},
	author       = {{Zoom}},
	year         = 2020,
	howpublished = {\url{https://blog.zoom.us/wordpress/2020/04/01/a-message-to-our-users/}},
	keywords     = {litsurvey.bib}
}

@misc{bitcoinMarketCap,
	title        = {The market capitalisation of the bitcoin network compared to global nation state currencies},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://fiatmarketcap.com/}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@misc{bitcoinScalability,
	title        = {The Bitcoin Scalability Problem Wikipedia page},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://en.wikipedia.org/wiki/Bitcoin_scalability_problem}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@misc{compareConfirmations,
	title        = {Relative Security: Comparing equivalent conformation strength across different distributed ledger technologies},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://howmanyconfs.com/}}
}

@misc{etherWhitepaper,
	title        = {Ethereum whitepaper},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://ethereum.org/en/whitepaper/}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@misc{lightningWhitepaper,
	title        = {The Bitcoin Lightning Network whitepaper pdf},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{http://lightning.network/lightning-network-paper.pdf}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@book{noauthor_undated,
	keywords     = {litsurvey.bib}
}

@misc{RGBFAQ,
	title        = {The RGB FAQ},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://rgbfaq.com/}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@misc{whatIsBlockchain,
	title        = {Investopedia description of blockchain},
	note         = {Accessed: 2021-02-10},
	howpublished = {\url{https://www.investopedia.com/terms/b/blockchain.asp}},
	owner        = {its352},
	timestamp    = {2021.02.10}
}

@misc{noauthor_2015,
	title        = {Ericsson Mobility Report},
	year         = 2015,
	howpublished = {\url{http://www.ericsson.com/res/docs/2015/mobility-report/ericsson-mobility-report-nov-2015.pdf}},
	keywords     = {litsurvey.bib}
}

@article{Allard2007,
	title        = {{Grimage: markerless {3D} interactions}},
	author       = {Allard, J{\'e}r{\'e}mie and Menier, Cl{\'e}ment and Raffin, Bruno and Boyer, Edmond and Faure, Fran{\c c}ois},
	year         = 2007,
	journal      = {Proceedings of the 34\textbackslashtextsuperscriptth annual conference on Computer Graphics and Interactive Techniques (SIGGRAPH '07)},
	keywords     = {litsurvey.bib}
}

@article{maurel2012keynesian,
	title        = {Keynesian and Austrian perspectives on crisis, shock adjustment, exchange rate regime and (long-term) growth},
	author       = {Maurel, Mathilde and Schnabl, Gunther},
	year         = 2012,
	journal      = {Open Economies Review},
	publisher    = {Springer},
	volume       = 23,
	number       = 5,
	pages        = {847--868}
}

@inproceedings{ford2005peer,
	title        = {Peer-to-Peer Communication Across Network Address Translators.},
	author       = {Ford, Bryan and Srisuresh, Pyda and Kegel, Dan},
	year         = 2005,
	booktitle    = {USENIX Annual Technical Conference, General Track},
	pages        = {179--192}
}

@article{karaarslan2018blockchain,
	title        = {Blockchain based DNS and PKI solutions},
	author       = {Karaarslan, Enis and Adiguzel, Eylul},
	year         = 2018,
	journal      = {IEEE Communications Standards Magazine},
	publisher    = {IEEE},
	volume       = 2,
	number       = 3,
	pages        = {52--57}
}

@article{benetton2021cryptomining,
	title        = {When Cryptomining Comes to Town: High Electricity-Use Spillovers to the Local Economy},
	author       = {Benetton, Matteo and Compiani, Giovanni and Morse, Adair},
	year         = 2021,
	journal      = {Available at SSRN 3779720}
}

@inproceedings{haber1990time,
	title        = {How to time-stamp a digital document},
	author       = {Haber, Stuart and Stornetta, W Scott},
	year         = 1990,
	booktitle    = {Conference on the Theory and Application of Cryptography},
	pages        = {437--455},
	organization = {Springer}
}

@article{sant2009performance,
	title        = {Performance in Second Life: some possibilities for learning and teaching},
	author       = {Sant, Toni},
	year         = 2009,
	journal      = {Learning and teaching in the virtual world of Second Life},
	publisher    = {Trondheim, Norway: Tapir Academic Press},
	pages        = {145--166}
}

@inproceedings{kemp2006putting,
	title        = {Putting a Second Life metaverse skin on learning management systems},
	author       = {Kemp, Jeremy and Livingstone, Daniel},
	year         = 2006,
	booktitle    = {Proceedings of the Second Life education workshop at the Second Life community convention},
	volume       = 20,
	organization = {The University of Paisley CA, San Francisco}
}

@article{sermon2008they,
	title        = {They live (in Second Life)},
	author       = {Sermon, Paul and others},
	year         = 2008
}

@article{marlatt2020capitalizing,
	title        = {Capitalizing on the craze of fortnite: Toward a conceptual framework for understanding how gamers construct communities of practice},
	author       = {Marlatt, Rick},
	year         = 2020,
	journal      = {Journal of Education},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 200,
	number       = 1,
	pages        = {3--11}
}

@article{kirriemuir2008spring,
	title        = {A Spring 2008 snapshot of UK higher and further education developments in Second Life},
	author       = {Kirriemuir, John},
	year         = 2008,
	journal      = {Eduserv Virtual World Watch},
	pages        = 58
}

@article{snowcrash1992,
	title        = {Snow Crash},
	author       = {Stephenson, Neal},
	year         = 1992,
	journal      = {Spectra Books}
}

@article{mclellan1993avatars,
	title        = {Avatars, Affordances, and Interfaces: Virtual Reality Tools for Learning.},
	author       = {McLellan, Hilary},
	year         = 1993,
	publisher    = {ERIC}
}

@article{baur2021bitcoin,
	title        = {Bitcoin investments and climate change: a financial and carbon intensity perspective},
	author       = {Baur, Dirk G and Oll, Josua},
	year         = 2021,
	journal      = {Finance Research Letters},
	publisher    = {Elsevier},
	pages        = 102575
}

@techreport{makarov2021blockchain,
	title        = {Blockchain Analysis of the Bitcoin Market},
	author       = {Makarov, Igor and Schoar, Antoinette},
	year         = 2021,
	institution  = {National Bureau of Economic Research}
}

@article{golumbia2020cryptocurrency,
	title        = {Cryptocurrency Is Garbage. So Is Blockchain.},
	author       = {Golumbia, David},
	year         = 2020,
	journal      = {So Is Blockchain.(June 16, 2020)}
}

@article{zabka2022short,
	title        = {Short Paper: A Centrality Analysis of the Lightning Network},
	author       = {Zabka, Philipp and Foerster, Klaus-Tycho and Decker, Christian and Schmid, Stefan},
	year         = 2022
}

@article{blandin20203rd,
	title        = {3rd global cryptoasset benchmarking study},
	author       = {Blandin, Apolline and Pieters, Gina C and Wu, Yue and Dek, Anton and Eisermann, Thomas and Njoki, Damaris and Taylor, Sean},
	year         = 2020,
	journal      = {Available at SSRN 3700822}
}

@inproceedings{delgado2018analysis,
	title        = {Analysis of the bitcoin utxo set},
	author       = {Delgado-Segura, Sergi and P{\'e}rez-Sola, Cristina and Navarro-Arribas, Guillermo and Herrera-Joancomart{\'\i}, Jordi},
	year         = 2018,
	booktitle    = {International Conference on Financial Cryptography and Data Security},
	pages        = {78--91},
	organization = {Springer}
}

@article{buterin2013ethereum,
	title        = {Ethereum white paper},
	author       = {Buterin, Vitalik and others},
	year         = 2013,
	journal      = {GitHub repository},
	volume       = 1,
	pages        = {22--23}
}

@misc{poon2016bitcoin,
	title        = {The bitcoin lightning network: Scalable off-chain instant payments},
	author       = {Poon, Joseph and Dryja, Thaddeus},
	year         = 2016
}

@inproceedings{croman2016scaling,
	title        = {On scaling decentralized blockchains},
	author       = {Croman, Kyle and Decker, Christian and Eyal, Ittay and Gencer, Adem Efe and Juels, Ari and Kosba, Ahmed and Miller, Andrew and Saxena, Prateek and Shi, Elaine and Sirer, Emin G{\"u}n and others},
	year         = 2016,
	booktitle    = {International conference on financial cryptography and data security},
	pages        = {106--125},
	organization = {Springer}
}

@article{rauchs2018distributed,
	title        = {Distributed ledger technology systems: A conceptual framework},
	author       = {Rauchs, Michel and Glidden, Andrew and Gordon, Brian and Pieters, Gina C and Recanatini, Martino and Rostand, Francois and Vagneur, Kathryn and Zhang, Bryan Zheng},
	year         = 2018,
	journal      = {Available at SSRN 3230013}
}

@book{davies2010history,
	title        = {History of money},
	author       = {Davies, Glyn},
	year         = 2010,
	publisher    = {University of Wales Press}
}

@article{stroukal2018can,
	title        = {Can Bitcoin become money? Its money functions and the regression theorem},
	author       = {Stroukal, Dominik and others},
	year         = 2018,
	journal      = {International Journal of Business and Management},
	publisher    = {International Institute of Social and Economic Sciences},
	volume       = 6,
	number       = 1,
	pages        = {36--53}
}

@article{gainsford2017salt,
	title        = {Salt and salary: were Roman soldiers paid in salt?},
	author       = {Gainsford, Peter},
	year         = 2017,
	journal      = {Kiwi Hellenist: Modern Myths about the Ancient World. Retrieved},
	volume       = 11
}

@article{goldberg2005famous,
	title        = {Famous myths of" fiat money"},
	author       = {Goldberg, Dror},
	year         = 2005,
	journal      = {Journal of Money, Credit and Banking},
	publisher    = {JSTOR},
	pages        = {957--967}
}

@article{krawisz2014hyperbitcoinization,
	title        = {Hyperbitcoinization},
	author       = {Krawisz, Daniel},
	year         = 2014,
	journal      = {Online verf{\"u}gbar unter: https://nakamotoin}
}

@article{filardo2012central,
	title        = {Central bank and government debt management: issues for monetary policy},
	author       = {Filardo, Andrew J and Mohanty, Madhusudan S and Moreno, Ramon},
	year         = 2012,
	journal      = {BIS Paper},
	number       = {67d}
}

@article{bordo1983some,
	title        = {Some aspects of the monetary economics of Richard Cantillon},
	author       = {Bordo, Michael David},
	year         = 1983,
	journal      = {Journal of Monetary Economics},
	publisher    = {Elsevier},
	volume       = 12,
	number       = 2,
	pages        = {235--258}
}

@book{cantillon1756essai,
	title        = {Essai sur la nature du commerce en g{\'e}n{\'e}ral},
	author       = {Cantillon, Richard},
	year         = 1756,
	publisher    = {{\'e}diteur non identifi{\'e}}
}

@book{prasad2021future,
	title        = {The Future of Money: How the Digital Revolution is Transforming Currencies and Finance},
	author       = {Prasad, Eswar S},
	year         = 2021,
	publisher    = {Harvard University Press}
}

@article{liu2022empirical,
	title        = {Empirical Analysis of EIP-1559: Transaction Fees, Waiting Time, and Consensus Security},
	author       = {Liu, Yulin and Lu, Yuxuan and Nayak, Kartik and Zhang, Fan and Zhang, Luyao and Zhao, Yinhong},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2201.05574}
}

@article{lockwood2021exploring,
	title        = {Exploring value propositions to drive Self-Sovereign Identity adoption},
	author       = {Lockwood, Mick},
	year         = 2021,
	journal      = {Frontiers in Blockchain},
	publisher    = {Frontiers},
	volume       = 4,
	pages        = 4
}

@article{prakash2020characteristic,
	title        = {Characteristic of enterprise collaboration system and its implementation issues in business management},
	author       = {Prakash, Shiv and Joshi, Sudhanshu and Bhatia, Tanvi and Sharma, Sadhna and Samadhiya, Durgesh and Shah, Rajiv Ratn and Kaiwartya, Omprakash and Prasad, Mukesh},
	year         = 2020,
	journal      = {International Journal of Business Intelligence and Data Mining},
	volume       = 16,
	number       = 1,
	pages        = {49--65}
}

@book{griffith2021electrify,
	title        = {Electrify: An Optimist's Playbook for Our Clean Energy Future},
	author       = {Griffith, Saul},
	year         = 2021,
	publisher    = {MIT Press}
}

@article{tomlinson2003third,
	title        = {What Was the Third World?},
	author       = {Tomlinson, Brian Roger},
	year         = 2003,
	journal      = {Journal of Contemporary History},
	publisher    = {Sage Publications Sage UK: London, England},
	volume       = 38,
	number       = 2,
	pages        = {307--321}
}

@techreport{caballero2008financial,
	title        = {Financial crash, commodity prices and global imbalances},
	author       = {Caballero, Ricardo J and Farhi, Emmanuel and Gourinchas, Pierre-Olivier},
	year         = 2008,
	institution  = {National Bureau of Economic Research}
}

@book{spiro2019hidden,
	title        = {The hidden hand of American hegemony},
	author       = {Spiro, David E},
	year         = 2019,
	publisher    = {Cornell University Press}
}

@article{mathews2018china,
	title        = {China: The emergence of the Petroyuan and the challenge to US dollar hegemony},
	author       = {Mathews, John A and Selden, Mark},
	year         = 2018,
	journal      = {The Asia-Pacific Journal},
	volume       = 16,
	number       = {22/3},
	pages        = {1--12}
}

@article{huang2016understanding,
	title        = {Understanding China's Belt \& Road initiative: motivation, framework and assessment},
	author       = {Huang, Yiping},
	year         = 2016,
	journal      = {China Economic Review},
	publisher    = {Elsevier},
	volume       = 40,
	pages        = {314--321}
}

@inproceedings{carlsten2016instability,
	title        = {On the instability of bitcoin without the block reward},
	author       = {Carlsten, Miles and Kalodner, Harry and Weinberg, S Matthew and Narayanan, Arvind},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {154--167}
}

@inproceedings{Hager_undated,
	title        = {{Long-Distance} Signals Transmission of Facial Affect},
	author       = {Hager, Joseph C and Ekman, Paul},
	pages        = {77--82},
	keywords     = {litsurvey.bib}
}

@other{Chen,
	title        = {A survey on visualization approaches for exploring association relationships in graph data},
	author       = {Yi Chen and Zeli Guan and Rong Zhang and Xiaomin Du and Yunhai Wang},
	doi          = {10.1007/s12650-019-00551-y},
	abstract     = {Journal of Visualization, https://doi.org/10.1007/s12650-019-00551-y},
	file         = {:C\:/Users/its352/Docear/projects/Big data/literature_repository/Data Visuaisation/s12650-019-00551-y.pdf:PDF},
	keywords     = {Association relationship, Graph analysis, Visual analytics, Graph simplification, Interaction techniques},
	publishers   = {Springer Berlin Heidelberg}
}

@article{sayeed2019assessing,
	title        = {Assessing blockchain consensus and security mechanisms against the 51\% attack},
	author       = {Sayeed, Sarwar and Marco-Gisbert, Hector},
	year         = 2019,
	journal      = {Applied Sciences},
	publisher    = {Multidisciplinary Digital Publishing Institute},
	volume       = 9,
	number       = 9,
	pages        = 1788
}

@techreport{stoeferle2018gold,
	title        = {Gold and the Turning of the Monetary Tides},
	author       = {Stoeferle, Ronald-Peter and Valek, Mark J},
	year         = 2018,
	institution  = {Technical report}
}

@article{piffaretti2009reshaping,
	title        = {Reshaping the international monetary architecture: lessons from Keynes' plan},
	author       = {Piffaretti, Nadia},
	year         = 2009,
	journal      = {World Bank Policy Research Working Paper},
	number       = 5034
}

@inproceedings{carney2019growing,
	title        = {The growing challenges for monetary policy in the current international monetary and financial system},
	author       = {Carney, Mark},
	year         = 2019,
	booktitle    = {Remarks at the Jackson Hole Symposium},
	volume       = 23
}

@inproceedings{rogaway2004cryptographic,
	title        = {Cryptographic hash-function basics: Definitions, implications, and separations for preimage resistance, second-preimage resistance, and collision resistance},
	author       = {Rogaway, Phillip and Shrimpton, Thomas},
	year         = 2004,
	booktitle    = {International workshop on fast software encryption},
	pages        = {371--388},
	organization = {Springer}
}

@article{de2022revisiting,
	title        = {Revisiting Bitcoinâ€™s carbon footprint},
	author       = {de Vries, Alex and Gallersd{\"o}rfer, Ulrich and Klaa{\ss}en, Lena and Stoll, Christian},
	year         = 2022,
	journal      = {Joule},
	publisher    = {Elsevier}
}

@article{clements2021built,
	title        = {Built to Fail: The Inherent Fragility of Algorithmic Stablecoins},
	author       = {Clements, Ryan},
	year         = 2021,
	journal      = {Wake Forest L. Rev. Online},
	publisher    = {HeinOnline},
	volume       = 11,
	pages        = 131
}

@article{hendrickson2021value,
	title        = {The Value of Bitcoin in the Year 2141 (and beyond!)},
	author       = {Hendrickson, Joshua R and Luther, William J},
	year         = 2021,
	journal      = {AIER Sound Money Project Working Paper},
	number       = {2021-06}
}

@article{Vertegaal2003,
	title        = {{GAZE-2: conveying eye contact in group video conferencing using eye-controlled camera direction}},
	author       = {Vertegaal, Roel and Weevers, Ivo},
	year         = 2003,
	journal      = {Proceedings of the SIGCHI \ldots},
	number       = 5,
	pages        = {521--528},
	isbn         = 1581136307,
	file         = {:/Users/its352/Dropbox/docear_workspace/literature_repository/papers/p521-vertegaal.pdf:pdf},
	groups       = {its352:1},
	keywords     = {attentive user interfaces, conferencing, eye contact, eye tracking, gaze, multiparty video}
}

@inproceedings{Cooke2002,
	title        = {Multiple Narrow-baseline System For Immersive Teleconferencing},
	author       = {Cooke, Eddie and Kauff, Peter and Schreer, Oliver},
	year         = 2002,
	booktitle    = {{Video/Image} Processing and Multimedia Communications 4},
	pages        = {367--370},
	institution  = {IEEE},
	keywords     = {litsurvey.bib}
}

@article{selvam2021blockchain,
	title        = {The Blockchain That Matters: A Comparative Analysis of Bitcoin's Fundamentally Unique and Irreplicable Properties},
	author       = {Selvam, Vijay},
	year         = 2021,
	journal      = {Available at SSRN 3880186}
}

@book{Argyle1988,
	title        = {Bodily communication},
	author       = {Argyle, Michael},
	year         = 1988,
	publisher    = {Methuen},
	keywords     = {litsurvey.bib}
}

@article{malherbe2019cryptocurrencies,
	title        = {Cryptocurrencies and blockchain: Opportunities and limits of a new monetary regime},
	author       = {Malherbe, Leo and Montalban, Matthieu and B{\'e}du, Nicolas and Granier, Caroline},
	year         = 2019,
	journal      = {International Journal of Political Economy},
	publisher    = {Taylor \& Francis},
	volume       = 48,
	number       = 2,
	pages        = {127--152}
}

@article{nakamoto2018,
	title        = {Duality: an excerpt},
	author       = {Satoshi Nakamoto},
	year         = 2018
}

@article{chohan2021double,
	title        = {The double spending problem and cryptocurrencies},
	author       = {Chohan, Usman W},
	year         = 2021,
	journal      = {Available at SSRN 3090174}
}

@inproceedings{schnorr1989efficient,
	title        = {Efficient identification and signatures for smart cards},
	author       = {Schnorr, Claus-Peter},
	year         = 1989,
	booktitle    = {Conference on the Theory and Application of Cryptology},
	pages        = {239--252},
	organization = {Springer}
}

@article{perez2019double,
	title        = {Double-spending prevention for bitcoin zero-confirmation transactions},
	author       = {P{\'e}rez-Sol{\`a}, Cristina and Delgado-Segura, Sergi and Navarro-Arribas, Guillermo and Herrera-Joancomart{\'\i}, Jordi},
	year         = 2019,
	journal      = {International Journal of Information Security},
	publisher    = {Springer},
	volume       = 18,
	number       = 4,
	pages        = {451--463}
}

@inproceedings{moser2013inquiry,
	title        = {An inquiry into money laundering tools in the Bitcoin ecosystem},
	author       = {M{\"o}ser, Malte and B{\"o}hme, Rainer and Breuker, Dominic},
	year         = 2013,
	booktitle    = {2013 APWG eCrime researchers summit},
	pages        = {1--14},
	organization = {Ieee}
}

@inproceedings{fuchsbauer2019aggregate,
	title        = {Aggregate cash systems: A cryptographic investigation of mimblewimble},
	author       = {Fuchsbauer, Georg and Orr{\`u}, Michele and Seurin, Yannick},
	year         = 2019,
	booktitle    = {Annual International Conference on the Theory and Applications of Cryptographic Techniques},
	pages        = {657--689},
	organization = {Springer}
}

@inproceedings{bonneau2015sok,
	title        = {Sok: Research perspectives and challenges for bitcoin and cryptocurrencies},
	author       = {Bonneau, Joseph and Miller, Andrew and Clark, Jeremy and Narayanan, Arvind and Kroll, Joshua A and Felten, Edward W},
	year         = 2015,
	booktitle    = {2015 IEEE symposium on security and privacy},
	pages        = {104--121},
	organization = {IEEE}
}

@article{cross2021greening,
	title        = {GREENING BITCOIN WITH INCENTIVE OFFSETS},
	author       = {Troy Cross and Andrew M. Bailey},
	year         = 2021
}

@book{doerr2018measure,
	title        = {Measure what matters: How Google, Bono, and the Gates Foundation rock the world with OKRs},
	author       = {Doerr, John},
	year         = 2018,
	publisher    = {Penguin}
}

@article{fox2015neural,
	title        = {Neural correlates of gratitude},
	author       = {Fox, Glenn R and Kaplan, Jonas and Damasio, Hanna and Damasio, Antonio},
	year         = 2015,
	journal      = {Frontiers in psychology},
	publisher    = {Frontiers},
	pages        = 1491
}

@book{swammycrypto,
	title        = {Crypto Uncovered},
	author       = {Swammy, Sarah and Thompson, Richard and Loh, Marvin},
	publisher    = {Springer},
	file         = {:../../../literature_repository/bitcoin/Sarah_Swammy,_Richard_Thompson,.pdf:PDF}
}

@book{blocksizewars,
	title        = {The Blocksize War: The battle for control over Bitcoinâ€™s protocol rules},
	author       = {Jonathan Bier},
	year         = 2021,
	publisher    = {Springer}
}

@book{gladsteincheck2022,
	title        = {Check Your Financial Privilege},
	author       = {Alex Gladstein},
	year         = 2022,
	publisher    = {BTC Media LLC}
}

@book{taleb2012antifragile,
	title        = {Antifragile: how to live in a world we don't understand},
	author       = {Taleb, Nassim Nicholas},
	year         = 2012,
	publisher    = {Allen Lane London},
	volume       = 3
}

@phdthesis{mui2002computational,
	title        = {Computational models of trust and reputation: Agents, evolutionary games, and social networks},
	author       = {Mui, Lik},
	year         = 2002,
	school       = {Massachusetts Institute of Technology}
}

@article{martin2022dark,
	title        = {Dark personalities and Bitcoin{\textregistered}: The influence of the Dark Tetrad on cryptocurrency attitude and buying intention},
	author       = {Martin, Brett AS and Chrysochou, Polymeros and Strong, Carolyn and Wang, Di and Yao, Jun},
	year         = 2022,
	journal      = {Personality and Individual Differences},
	publisher    = {Elsevier},
	volume       = 188,
	pages        = 111453
}

@book{heiphetz2010training,
	title        = {Training and collaboration with virtual worlds: How to create cost-saving, efficient and engaging programs},
	author       = {Heiphetz, Alex and Woodill, Gary},
	year         = 2010,
	publisher    = {McGraw Hill Professional}
}

@book{aldrich2005learning,
	title        = {Learning by doing: A comprehensive guide to simulations, computer games, and pedagogy in e-learning and other educational experiences},
	author       = {Aldrich, Clark},
	year         = 2005,
	publisher    = {John Wiley \& Sons}
}

@article{ercotimpact2021,
	title        = {Impacts of Large, Flexible DataCenter Operations on theFuture of ERCOT},
	author       = {Joshua D. Rhodes, Thomas Deetjen, and Caitlin Smith},
	year         = 2021,
	journal      = {Ideasmiths},
	url          = {https://www.ideasmiths.net/wp-content/uploads/2022/02/LANCIUM_IS_ERCOT_flexDC_FINAL_2021.pdf}
}

@article{grunspan2018double,
	title        = {Double spend races},
	author       = {Grunspan, Cyril and P{\'e}rez-Marco, Ricardo},
	year         = 2018,
	journal      = {International Journal of Theoretical and Applied Finance},
	publisher    = {World Scientific},
	volume       = 21,
	number       = {08},
	pages        = 1850053
}

@article{mackinga2022twap,
	title        = {TWAP Oracle Attacks: Easier Done than Said?},
	author       = {Mackinga, Torgin and Nadahalli, Tejaswi and Wattenhofer, Roger},
	year         = 2022,
	journal      = {Cryptology ePrint Archive}
}

@article{moringiello2021property,
	title        = {The Property Law of Tokens},
	author       = {Moringiello, Juliet M and Odinet, Christopher K},
	year         = 2021,
	journal      = {Florida Law Review (Forthcoming 2022)}
}

@article{fairfield2021tokenized,
	title        = {Tokenized: The law of non-fungible tokens and unique digital property},
	author       = {Fairfield, Joshua},
	year         = 2021,
	journal      = {Indiana Law Journal, Forthcoming}
}

@inproceedings{komlo2020frost,
	title        = {FROST: flexible round-optimized Schnorr threshold signatures},
	author       = {Komlo, Chelsea and Goldberg, Ian},
	year         = 2020,
	booktitle    = {International Conference on Selected Areas in Cryptography},
	pages        = {34--65},
	organization = {Springer}
}

@techreport{budish2018economic,
	title        = {The economic limits of bitcoin and the blockchain},
	author       = {Budish, Eric},
	year         = 2018,
	institution  = {National Bureau of Economic Research}
}

@inproceedings{klages2020stablecoins,
	title        = {Stablecoins 2.0: Economic foundations and risk-based models},
	author       = {Klages-Mundt, Ariah and Harz, Dominik and Gudgeon, Lewis and Liu, Jun-You and Minca, Andreea},
	year         = 2020,
	booktitle    = {Proceedings of the 2nd ACM Conference on Advances in Financial Technologies},
	pages        = {59--79}
}

@book{wang2021central,
	title        = {Central Banking 101},
	author       = {Wang, J.},
	year         = 2021,
	publisher    = {JOSEPH},
	isbn         = 9780999136744,
	url          = {https://books.google.co.uk/books?id=nwoozgEACAAJ}
}

@article{dutton2003authenticity,
	title        = {Authenticity in art},
	author       = {Dutton, Denis},
	year         = 2003,
	journal      = {The Oxford handbook of aesthetics},
	publisher    = {Citeseer},
	pages        = {258--274}
}

@misc{jakobsson1999proofs,
	title        = {Proofs of Work and Bread Pudding Protocols (Extended Abstract). Secure Information Networks (s. 258-272)},
	author       = {Jakobsson, Markus and Juels, Ari},
	year         = 1999,
	publisher    = {Boston: Springer US}
}

@inproceedings{dwork1992pricing,
	title        = {Pricing via processing or combatting junk mail},
	author       = {Dwork, Cynthia and Naor, Moni},
	year         = 1992,
	booktitle    = {Annual international cryptology conference},
	pages        = {139--147},
	organization = {Springer}
}

@article{gadekallu2022blockchain,
	title        = {Blockchain for the Metaverse: A Review},
	author       = {Gadekallu, Thippa Reddy and Huynh-The, Thien and Wang, Weizheng and Yenduri, Gokul and Ranaweera, Pasika and Pham, Quoc-Viet and da Costa, Daniel Benevides and Liyanage, Madhusanka},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.09738}
}

@article{nightingale2022ai,
	title        = {AI-synthesized faces are indistinguishable from real faces and more trustworthy},
	author       = {Nightingale, Sophie J and Farid, Hany},
	year         = 2022,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 119,
	number       = 8,
	pages        = {e2120481119}
}

@article{king1966fisher,
	title        = {Fisher, Franklin M., The Identification Problem in Econometrics},
	author       = {King, Gordon A and others},
	year         = 1966,
	journal      = {American Journal of Agricultural Economics},
	publisher    = {Agricultural and Applied Economics Association},
	volume       = 48,
	number       = {4\_Part\_I},
	pages        = {1039--1040}
}

@article{khazzaka2022bitcoin,
	title        = {Bitcoin: Cryptopayments Energy Efficiency},
	author       = {KHAZZAKA, Michel},
	year         = 2022,
	journal      = {Available at SSRN}
}

@incollection{gibson2019neuromancer,
	title        = {Neuromancer (1984)},
	author       = {Gibson, William},
	year         = 2019,
	booktitle    = {Crime and Media},
	publisher    = {Routledge},
	pages        = {86--94}
}

@article{de1990positive,
	title        = {Positive feedback investment strategies and destabilizing rational speculation},
	author       = {De Long, J Bradford and Shleifer, Andrei and Summers, Lawrence H and Waldmann, Robert J},
	year         = 1990,
	journal      = {the Journal of Finance},
	publisher    = {Wiley Online Library},
	volume       = 45,
	number       = 2,
	pages        = {379--395}
}

@inproceedings{kwon2019impossibility,
	title        = {Impossibility of full decentralization in permissionless blockchains},
	author       = {Kwon, Yujin and Liu, Jian and Kim, Minjeong and Song, Dawn and Kim, Yongdae},
	year         = 2019,
	booktitle    = {Proceedings of the 1st ACM Conference on Advances in Financial Technologies},
	pages        = {110--123}
}

@article{piet2022extracting,
	title        = {Extracting Godl [sic] from the Salt Mines: Ethereum Miners Extracting Value},
	author       = {Piet, Julien and Fairoze, Jaiden and Weaver, Nicholas},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.15930}
}

@inproceedings{apostolaki2017hijacking,
	title        = {Hijacking bitcoin: Routing attacks on cryptocurrencies},
	author       = {Apostolaki, Maria and Zohar, Aviv and Vanbever, Laurent},
	year         = 2017,
	booktitle    = {2017 IEEE symposium on security and privacy (SP)},
	pages        = {375--392},
	organization = {IEEE}
}

@book{bitcoinisvenice,
	title        = {Bitcoin is Venice},
	author       = {Allen Farrington, Sacha Meyers},
	year         = 2022,
	url          = {https://www.uncerto.com/book-pdf}
}

@article{authenticVolume2022,
	title        = {Authentic Volume Avatars from Phone Scans},
	author       = {Chen Cao and Tomas Simon and Jin Kyu Kim and others},
	year         = 2022,
	journal      = {ACM Transactions in Graphics},
	url          = {https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R}
}

@article{poelstra2015stake,
	title        = {On stake and consensus},
	author       = {Poelstra, Andrew},
	year         = 2015,
	journal      = {WP Software},
	volume       = 22,
	pages        = 29
}

@article{divakaruni2022lightning,
	title        = {The Lightning Network: Turning Bitcoin into Money},
	author       = {Divakaruni, Anantha and Zimmerman, Peter},
	year         = 2022,
	publisher    = {FRB of Cleveland Working Paper}
}

@book{Srinivasan2022,
	title        = {The Network State: How To Start A New Country},
	author       = {Balaji Srinivasan},
	year         = 2022,
	publisher    = {Amazon},
	url          = {https://balajis.com/the-network-state-book-a-crosspost/}
}

@book{grewal2020struggling,
	title        = {Struggling Amidst Plenty: A Laypersonâ€™s Guide to Our Awful Monetary System, Why itâ€™s the Root Cause of Inequality, Debt, and â€œToo Big to Fail,â€ \& The Little-Known Way to Fix it},
	author       = {Grewal, Subir},
	year         = 2020,
	publisher    = {Subir Grewal}
}

@book{booth2022bitcoin,
	title        = {Bitcoin: Everything Divided by 21 Million},
	author       = {Svanholm, K. Booth, J. and Shilling, M. and Laamanen, N.},
	year         = 2022,
	publisher    = {Amazon Digital Services LLC - KDP Print US},
	isbn         = 9789916697191,
	url          = {https://books.google.co.uk/books?id=14onzwEACAAJ}
}

@article{park2022metaverse,
	title        = {A Metaverse: Taxonomy, components, applications, and open challenges},
	author       = {Park, Sang-Min and Kim, Young-Gab},
	year         = 2022,
	journal      = {Ieee Access},
	publisher    = {IEEE},
	volume       = 10,
	pages        = {4209--4251}
}

@article{mystakidis2022metaverse,
	title        = {Metaverse},
	author       = {Mystakidis, Stylianos},
	year         = 2022,
	journal      = {Encyclopedia},
	publisher    = {MDPI},
	volume       = 2,
	number       = 1,
	pages        = {486--497}
}

@article{xi2022challenges,
	title        = {The challenges of entering the metaverse: An experiment on the effect of extended reality on workload},
	author       = {Xi, Nannan and Chen, Juan and Gama, Filipe and Riar, Marc and Hamari, Juho},
	year         = 2022,
	journal      = {Information Systems Frontiers},
	publisher    = {Springer},
	pages        = {1--22}
}

@article{kraus2022facebook,
	title        = {Facebook and the creation of the metaverse: radical business model innovation or incremental transformation?},
	author       = {Kraus, Sascha and Kanbach, Dominik K and Krysta, Peter M and Steinhoff, Maurice M and Tomini, Nino},
	year         = 2022,
	journal      = {International Journal of Entrepreneurial Behavior \& Research},
	publisher    = {Emerald Publishing Limited}
}

@article{biener2022quantifying,
	title        = {Quantifying the Effects of Working in VR for One Week},
	author       = {Biener, Verena and Kalamkar, Snehanjali and Nouri, Negar and Ofek, Eyal and Pahud, Michel and Dudley, John J and Hu, Jinghui and Kristensson, Per Ola and Weerasinghe, Maheshya and {\v{C}}opi{\v{c}} Pucihar, Klen and others},
	year         = 2022,
	journal      = {arXiv e-prints},
	pages        = {arXiv--2206}
}

@article{ondrejka2004escaping,
	title        = {Escaping the gilded cage: User created content and building the metaverse},
	author       = {Ondrejka, Cory},
	year         = 2004,
	journal      = {NYL Sch. L. Rev.},
	publisher    = {HeinOnline},
	volume       = 49,
	pages        = 81
}

@article{siyaev2021towards,
	title        = {Towards aircraft maintenance metaverse using speech interactions with virtual objects in mixed reality},
	author       = {Siyaev, Aziz and Jo, Geun-Sik},
	year         = 2021,
	journal      = {Sensors},
	publisher    = {MDPI},
	volume       = 21,
	number       = 6,
	pages        = 2066
}

@article{nevelsteen2018virtual,
	title        = {Virtual world, defined from a technological perspective and applied to video games, mixed reality, and the Metaverse},
	author       = {Nevelsteen, Kim JL},
	year         = 2018,
	journal      = {Computer Animation and Virtual Worlds},
	publisher    = {Wiley Online Library},
	volume       = 29,
	number       = 1,
	pages        = {e1752}
}

@techreport{barrero2021working,
	title        = {Why working from home will stick},
	author       = {Barrero, Jose Maria and Bloom, Nicholas and Davis, Steven J},
	year         = 2021,
	institution  = {National Bureau of Economic Research}
}

@inproceedings{Drobyshev22MP,
	title        = {MegaPortraits: One-shot Megapixel Neural Head Avatars},
	author       = {Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor},
	year         = 2022,
	journal      = {Proceedings of the 30th ACM International Conference on Multimedia}
}

@article{BenSasson2022,
	title        = {Scalable and transparent proofs over all large fields via elliptic curves},
	author       = {Sasson, Eli Ben and Carmon, Dan and Kopparty, Swastik and Levit, David},
	year         = 2022,
	journal      = {TR22 110}
}

@article{chen2020survey,
	title        = {A survey on ethereum systems security: Vulnerabilities, attacks, and defenses},
	author       = {Chen, Huashan and Pendleton, Marcus and Njilla, Laurent and Xu, Shouhuai},
	year         = 2020,
	journal      = {ACM Computing Surveys (CSUR)},
	publisher    = {ACM New York, NY, USA},
	volume       = 53,
	number       = 3,
	pages        = {1--43}
}

@misc{https://doi.org/10.48550/arxiv.2208.01908,
	title        = {Mass Exit Attacks on the Lightning Network},
	author       = {Sguanci, Cosimo and Sidiropoulos, Anastasios},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2208.01908},
	url          = {https://arxiv.org/abs/2208.01908},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Cryptography and Security (cs.CR), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences}
}

@article{anderson2002free,
	title        = {Free speech online and offline},
	author       = {Anderson, Ross},
	year         = 2002,
	journal      = {Computer},
	publisher    = {IEEE},
	volume       = 35,
	number       = 6,
	pages        = {28--30}
}

@book{graeber2012debt,
	title        = {Debt: The first 5000 years},
	author       = {Graeber, David},
	year         = 2012,
	publisher    = {Penguin UK}
}

@book{homer1996history,
	title        = {A history of interest rates},
	author       = {Homer, Sidney and Sylla, Richard Eugene},
	year         = 1996,
	publisher    = {Rutgers University Press}
}

@article{szabo2002shelling,
	title        = {Shelling out: the origins of money},
	author       = {Szabo, Nick},
	year         = 2002,
	journal      = {Satoshi Nakamoto Institute}
}

@article{selgin1996defense,
	title        = {In defense of fiduciary mediaâ€”or, we arenot devo (lutionists), we are Misesians!},
	author       = {Selgin, George and White, Lawrence H},
	year         = 1996,
	journal      = {The Review of Austrian Economics},
	publisher    = {Springer},
	volume       = 9,
	number       = 2,
	pages        = {83--107}
}

@article{mora2018bitcoin,
	title        = {Bitcoin emissions alone could push global warming above 2 C},
	author       = {Mora, Camilo and Rollins, Randi L and Taladay, Katie and Kantar, Michael B and Chock, Mason K and Shimada, Mio and Franklin, Erik C},
	year         = 2018,
	journal      = {Nature Climate Change},
	publisher    = {Nature Publishing Group},
	volume       = 8,
	number       = 11,
	pages        = {931--933}
}

@article{barsky1987fisher,
	title        = {The Fisher hypothesis and the forecastability and persistence of inflation},
	author       = {Barsky, Robert B},
	year         = 1987,
	journal      = {Journal of monetary Economics},
	publisher    = {Elsevier},
	volume       = 19,
	number       = 1,
	pages        = {3--24}
}

@book{hall2009inflation,
	title        = {Inflation: causes and effects},
	author       = {Hall, Robert E},
	year         = 2009,
	publisher    = {University of Chicago Press}
}

@other{ponzi2021alden,
	title        = {Bitcoin: Addressing the Ponzi Scheme Characterization},
	author       = {Alden, Lyn},
	year         = 2021,
	journal      = {blogarticle},
	url          = {https://www.lynalden.com/bitcoin-ponzi-scheme/}
}

@inproceedings{rosenberg2022regulation,
	title        = {Regulation of the Metaverse: A Roadmap},
	author       = {Rosenberg, L},
	year         = 2022,
	booktitle    = {Proceedings of the 6th International Conference on Virtual and Augmented Reality Simulations (ICVARS 2022), Brisbane, Australia},
	volume       = 1
}

@article{ball2020metaverse,
	title        = {The Metaverse: what it is, where to find it, and who will build it},
	author       = {Ball, Matthew},
	year         = 2020,
	journal      = {MatthewBall. Vc, available at: www. matthe wball. vc/all/themetaverse}
}

@article{apostolaki2016hijacking,
	title        = {Hijacking bitcoin: Large-scale network attacks on cryptocurrencies},
	author       = {Apostolaki, Maria and Zohar, Aviv and Vanbever, Laurent},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1605.07524}
}

@inproceedings{johnson2014game,
	title        = {Game-theoretic analysis of DDoS attacks against Bitcoin mining pools},
	author       = {Johnson, Benjamin and Laszka, Aron and Grossklags, Jens and Vasek, Marie and Moore, Tyler},
	year         = 2014,
	booktitle    = {International Conference on Financial Cryptography and Data Security},
	pages        = {72--86},
	organization = {Springer}
}

@article{poole2022dreamfusion,
	title        = {DreamFusion: Text-to-3D using 2D Diffusion},
	author       = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
	year         = 2022,
	journal      = {arXiv}
}

@inproceedings{anonymous2023phenaki,
	title        = {Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions},
	author       = {Anonymous},
	year         = 2023,
	booktitle    = {Submitted to The Eleventh International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=vOEXS39nOF},
	note         = {under review}
}

@article{ruiz2022dreambooth,
	title        = {DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},
	author       = {Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
	year         = 2022,
	booktitle    = {arXiv preprint arxiv:2208.12242}
}

@article{cagan1958demand,
	title        = {The demand for currency relative to the total money supply},
	author       = {Cagan, Phillip},
	year         = 1958,
	journal      = {Journal of political economy},
	publisher    = {The University of Chicago Press},
	volume       = 66,
	number       = 4,
	pages        = {303--328}
}

@article{torok2017cascading,
	title        = {Cascading collapse of online social networks},
	author       = {T{\"o}r{\"o}k, J{\'a}nos and Kert{\'e}sz, J{\'a}nos},
	year         = 2017,
	journal      = {Scientific reports},
	publisher    = {Nature Publishing Group},
	volume       = 7,
	number       = 1,
	pages        = {1--8}
}

@article{nair2022exploring,
	title        = {Exploring the Unprecedented Privacy Risks of the Metaverse},
	author       = {Nair, Vivek and Garrido, Gonzalo Munilla and Song, Dawn},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.13176}
}

@article{ferranti2022hedging,
	title        = {Hedging Sanctions Risk: Cryptocurrency in Central Bank Reserves},
	author       = {Ferranti, Matthew},
	year         = 2022,
	journal      = {arXiv preprint arXiv},
	url          = {https://sites.google.com/view/matthewferranti/research}
}

@article{bahdanau2014neural,
	title        = {Neural machine translation by jointly learning to align and translate},
	author       = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1409.0473}
}

@article{RhodesJetal2021,
	title        = {Impacts of Large, Flexible Data Center Operations on the Future of ERCOT},
	author       = {Rhodes J et al, Lancium},
	year         = 2021,
	journal      = {Lancium},
	url          = {https://lancium.com/wp-content/uploads/2022/06/Lancium_Flexible_Data_Center_Whitepaper_4.2022.pdf}
}

@article{borio2017fx,
	title        = {FX swaps and forwards: missing global debt?},
	author       = {Borio, Claudio EV and McCauley, Robert N and McGuire, Patrick},
	year         = 2017,
	journal      = {BIS Quarterly Review September}
}

@book{ball2022metaverse,
	title        = {The metaverse: and how it will revolutionize everything},
	author       = {Ball, Matthew},
	year         = 2022,
	publisher    = {Liveright Publishing}
}

@article{weyl2022decentralized,
	title        = {Decentralized Society: Finding Web3's Soul},
	author       = {Weyl, E Glen and Ohlhaver, Puja and Buterin, Vitalik},
	year         = 2022,
	journal      = {Available at SSRN 4105763}
}

@book{hudson2021destiny,
	title        = {The destiny of civilization: finance capitalism, industrial capitalism or socialism},
	author       = {Hudson, M},
	year         = 2022,
	journal      = {Verlag, ISLET}
}

@book{va2010neoconservatism,
	title        = {Neoconservatism: The biography of a movement},
	author       = {Va'isse, Justin and Va'sse, Justin},
	year         = 2010,
	publisher    = {Harvard University Press}
}

@inproceedings{radford2021learning,
	title        = {Learning transferable visual models from natural language supervision},
	author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	pages        = {8748--8763},
	organization = {PMLR}
}

@incollection{immerwahr202221,
	title        = {21 The Galactic Vietnam: Technology, Modernization, and Empire in George Lucasâ€™s Star Wars},
	author       = {Immerwahr, Daniel},
	year         = 2022,
	booktitle    = {Ideology in US Foreign Relations},
	publisher    = {Columbia University Press},
	pages        = {435--451}
}

@article{kerskens2022experimental,
	title        = {Experimental indications of non-classical brain functions},
	author       = {Kerskens, Christian Matthias and P{\'e}rez, David L{\'o}pez},
	year         = 2022,
	journal      = {Journal of Physics Communications},
	publisher    = {IOP Publishing},
	volume       = 6,
	number       = 10,
	pages        = 105001
}

@incollection{larson2021myth,
	title        = {The Myth of Artificial Intelligence},
	author       = {Larson, Erik J},
	year         = 2021,
	booktitle    = {The Myth of Artificial Intelligence},
	publisher    = {Harvard University Press}
}

@article{searle1980minds,
	title        = {Minds, brains, and programs},
	author       = {Searle, John R},
	year         = 1980,
	journal      = {Behavioral and brain sciences},
	publisher    = {Cambridge University Press},
	volume       = 3,
	number       = 3,
	pages        = {417--424}
}

@misc{turing1950computing,
	title        = {Computing machinery and intelligence in â€œMindâ€, vol},
	author       = {Turing, Alan},
	year         = 1950,
	publisher    = {LIX}
}

@article{french2012moving,
	title        = {Moving beyond the Turing test},
	author       = {French, Robert M},
	year         = 2012,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 55,
	number       = 12,
	pages        = {74--77}
}

@article{french2000turing,
	title        = {The Turing Test: the first 50 years},
	author       = {French, Robert M},
	year         = 2000,
	journal      = {Trends in cognitive sciences},
	publisher    = {Elsevier},
	volume       = 4,
	number       = 3,
	pages        = {115--122}
}

@incollection{searle2009turing,
	title        = {The Turing test: 55 years later},
	author       = {Searle, John R},
	year         = 2009,
	booktitle    = {Parsing the Turing Test},
	publisher    = {Springer},
	pages        = {139--150}
}

@article{warwick2016can,
	title        = {Can machines think? A report on Turing test experiments at the Royal Society},
	author       = {Warwick, Kevin and Shah, Huma},
	year         = 2016,
	journal      = {Journal of experimental \& Theoretical artificial Intelligence},
	publisher    = {Taylor \& Francis},
	volume       = 28,
	number       = 6,
	pages        = {989--1007}
}

@article{elkins2020can,
	title        = {Can GPT-3 pass a Writerâ€™s turing test?},
	author       = {Elkins, Katherine and Chun, Jon},
	year         = 2020,
	journal      = {Journal of Cultural Analytics},
	publisher    = {Department of Languages, Literatures, and Cultures},
	volume       = 5,
	number       = 2,
	pages        = 17212
}

@article{marcus2020gpt,
	title        = {GPT-3, Bloviator: OpenAIâ€™s language generator has no idea what itâ€™s talking about},
	author       = {Marcus, Gary and Davis, Ernest},
	year         = 2020,
	journal      = {Technology Review}
}

@incollection{sep-turing-test,
	title        = {{The Turing Test}},
	author       = {Oppy, Graham and Dowe, David},
	year         = 2021,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	edition      = {{W}inter 2021},
	editor       = {Edward N. Zalta},
	howpublished = {\url{https://plato.stanford.edu/archives/win2021/entries/turing-test/}}
}

@article{stinner2022proof,
	title        = {Proof-of-work consensus under exogenous distress: Evidence from mining shocks in the Bitcoin ecosystem},
	author       = {Stinner, Jona and Tyrell, Marcel},
	year         = 2022,
	journal      = {Available at SSRN 4032034}
}

@book{fisher2014ghosts,
	title        = {Ghosts of my life: Writings on depression, hauntology and lost futures},
	author       = {Fisher, Mark},
	year         = 2014,
	publisher    = {John Hunt Publishing}
}

@incollection{gayoso2018secure,
	title        = {Secure elliptic curves in cryptography},
	author       = {Gayoso Martinez, Victor and Gonzalez-Manzano, Lorena and Martin Munoz, Agustin},
	year         = 2018,
	booktitle    = {Computer and Network Security Essentials},
	publisher    = {Springer},
	pages        = {283--298}
}

@article{lamb2022second,
	title        = {Second life lessons},
	author       = {Lamb, Hilary},
	year         = 2022,
	journal      = {Engineering \& Technology},
	publisher    = {IET},
	volume       = 17,
	number       = 4,
	pages        = {1--9}
}

@article{cameron2012splendid,
	title        = {Splendid isolation:â€˜Philosopherâ€™s islandsâ€™ and the reimagination of space},
	author       = {Cameron, Angus},
	year         = 2012,
	journal      = {Geoforum},
	publisher    = {Elsevier},
	volume       = 43,
	number       = 4,
	pages        = {741--749}
}

@article{swartz2008guerilla,
	title        = {Guerilla open access manifesto},
	author       = {Swartz, Aaron},
	year         = 2008,
	journal      = {Aaron Swartz [Internet]}
}

@article{hennig2022social,
	title        = {Social interactions in the metaverse: Framework, initial evidence, and research roadmap},
	author       = {Hennig-Thurau, Thorsten and Aliman, Dorothea N and Herting, Alina M and Cziehso, Gerrit P and Linder, Marc and K{\"u}bler, Raoul V},
	year         = 2022,
	journal      = {Journal of the Academy of Marketing Science},
	publisher    = {Springer},
	pages        = {1--25}
}

@article{gozalo2023chatgpt,
	title        = {ChatGPT is not all you need. A State of the Art Review of large Generative AI models},
	author       = {Gozalo-Brizuela, Roberto and Garrido-Merchan, Eduardo C},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2301.04655}
}

@article{Adams2023,
	title        = {On-Chain Foreign Exchange and Cross-Border Payments},
	author       = {Adams, Austin and Lader, Mary-Catherine and Liao, Gordon and Puth, David and Wan, Xin},
	year         = 2023,
	month        = jan,
	journal      = {SSRN:}
}

@inproceedings{sood2019implementation,
	title        = {Implementation of blockchain in cross border money transfer},
	author       = {Sood, Aabhas and Simon, Rajbala},
	year         = 2019,
	booktitle    = {2019 4th international conference on information systems and computer networks (ISCON)},
	pages        = {104--107},
	organization = {IEEE}
}

@incollection{bechtel2022future,
	title        = {The Future of Payments in a DLT-based European Economy: A Roadmap},
	author       = {Bechtel, Alexander and Ferreira, Agata and Gross, Jonas and Sandner, Philipp},
	year         = 2022,
	booktitle    = {The Future of Financial Systems in the Digital Age},
	publisher    = {Springer, Singapore},
	pages        = {89--116}
}

@inproceedings{cuervo2018creating,
	title        = {Creating the perfect illusion: What will it take to create life-like virtual reality headsets?},
	author       = {Cuervo, Eduardo and Chintalapudi, Krishna and Kotaru, Manikanta},
	year         = 2018,
	booktitle    = {Proceedings of the 19th International Workshop on Mobile Computing Systems \& Applications},
	pages        = {7--12}
}

@book{giancarlo2021cryptodad,
	title        = {CryptoDad: The Fight for the Future of Money},
	author       = {Giancarlo, J Christopher},
	year         = 2021,
	publisher    = {John Wiley \& Sons}
}

@book{mattei2022capital,
	title        = {The capital order: How economists invented austerity and paved the way to fascism},
	author       = {Mattei, Clara E},
	year         = 2022,
	publisher    = {University of Chicago Press}
}

@article{hawtrey1925currency,
	title        = {Currency and Public Administration 1},
	author       = {Hawtrey, RG},
	year         = 1925,
	journal      = {Public Administration},
	publisher    = {Wiley Online Library},
	volume       = 3,
	number       = 3,
	pages        = {232--245}
}

@article{dymydiuk2020rubicon,
	title        = {RUBICON and revelation: the curious robustness of the â€˜secretâ€™CIA-BND operation with Crypto AG},
	author       = {Dymydiuk, Jason},
	year         = 2020,
	journal      = {Intelligence and National Security},
	publisher    = {Taylor \& Francis},
	volume       = 35,
	number       = 5,
	pages        = {641--658}
}

@book{balassa2013theory,
	title        = {The theory of economic integration},
	author       = {Balassa, Bela},
	year         = 2013,
	publisher    = {Routledge}
}

@book{iser1993fictive,
	title        = {The fictive and the imaginary: Charting literary anthropology},
	author       = {Iser, Wolfgang},
	year         = 1993,
	publisher    = {Johns Hopkins University Press}
}

@book{taylor2009play,
	title        = {Play between worlds: Exploring online game culture},
	author       = {Taylor, Tina L},
	year         = 2009,
	publisher    = {MIT press}
}

@book{glas2013battlefields,
	title        = {Battlefields of negotiation: Control, agency, and ownership in World of Warcraft},
	author       = {Glas, Ren{\'e}},
	year         = 2013,
	publisher    = {Amsterdam University Press}
}

@book{chen2011leet,
	title        = {Leet noobs},
	author       = {Chen, Mark},
	year         = 2011,
	publisher    = {Peter Lang Publishing, New York}
}

@misc{serapis2008coming,
	title        = {Coming of age in second life: an anthropologist explores the virtually human},
	author       = {Serapis, Zicodas},
	year         = 2008,
	publisher    = {JSTOR}
}

@article{cole2013call,
	title        = {The Call of ThingsA Critique of Object-Oriented Ontologies},
	author       = {Cole, Andrew},
	year         = 2013,
	journal      = {the minnesota review},
	publisher    = {Duke University Press},
	volume       = 2013,
	number       = 80,
	pages        = {106--118}
}

@article{bertomeu2023uncle,
	title        = {Uncle Samâ€™s Stimulus and Crypto Boom},
	author       = {Bertomeu, Jeremy and Martin, Xiumin and Zhang, Sheryl},
	year         = 2023,
	journal      = {Available at SSRN 4320431}
}

@article{Kaloudis2023,
	title        = {How Bitcoin NFTs Might Accidentally Fix Bitcoin's Security Budget},
	author       = {Kaloudis, George},
	year         = 2023,
	url          = {https://www.coindesk.com/consensus-magazine/2023/02/06/how-bitcoin-nfts-might-accidentally-fix-bitcoins-security-budget/}
}

@article{brundage2018malicious,
	title        = {The malicious use of artificial intelligence: Forecasting, prevention, and mitigation},
	author       = {Brundage, Miles and Avin, Shahar and Clark, Jack and Toner, Helen and Eckersley, Peter and Garfinkel, Ben and Dafoe, Allan and Scharre, Paul and Zeitzoff, Thomas and Filar, Bobby and others},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1802.07228}
}

@article{Wouters2022,
	title        = {What Could Bitcoin Mining Look Like at One Zettahash?},
	author       = {Wouters, Sam},
	year         = 2022,
	journal      = {River Research},
	url          = {https://river.com/learn/files/river-bitcoin-mining-zettahash-report.pdf}
}

@article{low2022emperor,
	title        = {The emperorâ€™s new art: Cryptomania, art \& property},
	author       = {Low, Kelvin FK},
	year         = 2022,
	journal      = {Art \& Property (December 6, 2021)},
	volume       = 86
}

@inproceedings{Rosenberg2023,
	title        = {The Metaverse and Conversational AI as a Threat Vector for Targeted Influence},
	author       = {Rosenberg, Louis},
	year         = 2023,
	month        = {03}
}

@book{Lowery2023,
	title        = {Softwar: A Novel Theory on Power Projection and the National Strategic Significance of Bitcoin},
	author       = {Lowery, Jason Paul},
	year         = 2023,
	journal      = {self published},
	issn         = {979-8371524188},
	url          = {https://www.amazon.com/dp/B0BW358F37}
}

@book{warren2023bitcoin,
	title        = {Bitcoin: A Game Theoretic Analysis},
	author       = {Warren, Micah},
	year         = 2023,
	publisher    = {Walter de Gruyter GmbH}
}

@article{Nair2023,
	title        = {Unique Identification of 50,000 Virtual Reality Users from Head Hand Motion Data},
	author       = {Nair, Vivek and Guo, Wenbo and Mattern, Justus and Wang, Rui and O'Brien, James F. and Rosenberg, Louis and Song, Dawn},
	year         = 2023,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2302.08927},
	url          = {https://arxiv.org/abs/2302.08927},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences}
}

@inproceedings{mirzaei2022daric,
	title        = {Daric: A Storage Efficient Payment Channel With Penalization Mechanism},
	author       = {Mirzaei, Arash},
	year         = 2022,
	booktitle    = {2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S)},
	pages        = {51--52},
	organization = {IEEE}
}

@article{Sheng2023,
	title        = {High-throughput Generative Inference of Large Language Models with a Single GPU Ying},
	author       = {Sheng, Ying},
	year         = 2023
}

@article{katterbauer2022impact,
	title        = {The impact of the legalization of Bitcoin in the Central African Republic--a legal analysis},
	author       = {Katterbauer, Klemens and Syed, Hassan and Cleenewerck, Laurent},
	year         = 2022,
	journal      = {Cuadernos de Econom{\'\i}a},
	volume       = 713,
	pages        = 746
}

@misc{penrose1990emperor,
	title        = {The emperorâ€™s new mind: Concerning computers, minds, and the laws of physics},
	author       = {Penrose, Roger and Mermin, N David},
	year         = 1990,
	publisher    = {American Association of Physics Teachers}
}

@misc{Menati2022,
	title        = {Modeling and Analysis of Utilizing Cryptocurrency Mining for Demand Flexibility in Electric Energy Systems: A Synthetic Texas Grid Case Study},
	author       = {Menati, Ali and Lee, Kiyeob and Xie, Le},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2207.02428},
	url          = {https://arxiv.org/abs/2207.02428},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Systems and Control (eess.SY), FOS: Electrical engineering, electronic engineering, information engineering}
}

@article{ibanez2023sok,
	title        = {SoK: Bitcoin, Energy Consumption and Environmental Impact},
	author       = {Iba{\~n}ez, Juan Ignacio and Freier, Alexander},
	year         = 2023,
	journal      = {Energy Consumption and Environmental Impact (February 3, 2023)}
}

@article{jiang2023monetary,
	title        = {Monetary Tightening and US Bank Fragility in 2023: Mark-to-Market Losses and Uninsured Depositor Runs?},
	author       = {Jiang, Erica Xuewei and Matvos, Gregor and Piskorski, Tomasz and Seru, Amit},
	year         = 2023,
	journal      = {Available at SSRN}
}

@misc{bubeck2023sparks,
	title        = {Sparks of Artificial General Intelligence: Early experiments with GPT-4},
	author       = {SÃ©bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
	year         = 2023,
	archiveprefix = {arXiv},
	eprint       = {2303.12712},
	primaryclass = {cs.CL}
}

@book{hulsmann2008ethics,
	title        = {Ethics of money production},
	author       = {H{\"u}lsmann, J{\"o}rg Guido},
	year         = 2008,
	publisher    = {Ludwig von Mises Institute}
}

@misc{yudkowsky2008hanson,
	title        = {The Hanson-Yudkowsky AI-foom debate},
	author       = {Yudkowsky, Eliezer},
	year         = 2008,
	journal      = {2013-04-01)[2019-01-03]. http://intelligence. org/files/AIFoomDebate. pdf}
}

@article{song2018preventing,
	title        = {Preventing a Butlerian Jihad},
	author       = {Song, Schoni},
	year         = 2018,
	journal      = {Journal of International Affairs},
	publisher    = {JSTOR},
	volume       = 72,
	number       = 1,
	pages        = {135--142}
}

@article{perez2022discovering,
	title        = {Discovering Language Model Behaviors with Model-Written Evaluations},
	author       = {Perez, Ethan and Ringer, Sam and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.09251}
}

@article{bayer2023artificial,
	title        = {Artificial Minds},
	author       = {Bayer, Lara},
	year         = 2023
}

@article{bostrom2003ethical,
	title        = {Ethical issues in advanced artificial intelligence},
	author       = {Bostrom, Nick},
	year         = 2003,
	journal      = {Science fiction and philosophy: from time travel to superintelligence},
	volume       = 277,
	pages        = 284
}

@article{hoffmann2022empirical,
	title        = {An empirical analysis of compute-optimal large language model training},
	author       = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and de Las Casas, Diego and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {30016--30030}
}

@article{sadasivan2023can,
	title        = {Can AI-Generated Text be Reliably Detected?},
	author       = {Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.11156}
}

@book{white1914fiat,
	title        = {Fiat Money Inflation in France: How it Came, what it Brought and how it Ended. To which is Added an Extract from Macaulay Showing the Results of Tampering with the Currency of England, Also a Summary by Emile Lavasseur},
	author       = {White, Andrew Dickson},
	year         = 1914,
	publisher    = {Brigdens, Limited}
}

@article{shinn2023reflexion,
	title        = {Reflexion: an autonomous agent with dynamic memory and self-reflection},
	author       = {Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.11366}
}

@article{shen2023hugginggpt,
	title        = {HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace},
	author       = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.17580}
}

@article{horton2019death,
	title        = {The death of a technical skill},
	author       = {Horton, John J and Tambe, Prasanna and Wharton, U Penn},
	year         = 2019,
	journal      = {Unpublished Manuscript}
}

@techreport{trajtenberg2018ai,
	title        = {AI as the next GPT: a Political-Economy Perspective},
	author       = {Trajtenberg, Manuel},
	year         = 2018,
	institution  = {National Bureau of Economic Research}
}

@article{manakul2023selfcheckgpt,
	title        = {SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
	author       = {Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.08896}
}

@article{azamfirei2023large,
	title        = {Large language models and the perils of their hallucinations},
	author       = {Azamfirei, Razvan and Kudchadkar, Sapna R and Fackler, James},
	year         = 2023,
	journal      = {Critical Care},
	publisher    = {BioMed Central},
	volume       = 27,
	number       = 1,
	pages        = {1--2}
}

@article{ouyang2022training,
	title        = {Training language models to follow instructions with human feedback},
	author       = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {27730--27744}
}

@article{dai2022can,
	title        = {Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta Optimizers},
	author       = {Dai, Damai and Sun, Yutao and Dong, Li and Hao, Yaru and Sui, Zhifang and Wei, Furu},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.10559}
}

@article{o2021god,
	title        = {God, human, animal, machine: Technology, metaphor, and the search for meaning},
	author       = {O'Gieblyn, Meghan},
	year         = 2021,
	journal      = {(No Title)}
}

@article{chiu2017economics,
	title        = {The economics of cryptocurrencies--bitcoin and beyond},
	author       = {Chiu, Jonathan and Koeppl, Thorsten V},
	year         = 2017,
	journal      = {Available at SSRN 3048124}
}

@article{hu2021lora,
	title        = {Lora: Low-rank adaptation of large language models},
	author       = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2106.09685}
}

@misc{park2023generative,
	title        = {Generative Agents: Interactive Simulacra of Human Behavior},
	author       = {Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
	year         = 2023,
	archiveprefix = {arXiv},
	eprint       = {2304.03442},
	primaryclass = {cs.HC}
}

@inproceedings{morkel2005overview,
	title        = {An overview of image steganography.},
	author       = {Morkel, Tayana and Eloff, Jan HP and Olivier, Martin S},
	year         = 2005,
	booktitle    = {ISSA},
	volume       = 1,
	number       = 2,
	pages        = {1--11}
}

@misc{voskuil2020cryptoeconomics,
	title        = {Cryptoeconomics. Fundamental Principles of Bitcoin},
	author       = {Voskuil, Eric},
	year         = 2020,
	publisher    = {Online}
}

@Article{haidt2023social,
  author    = {Haidt J.},
  journal   = {ongoing},
  title     = {Social media and mental health: A collaborative review. Unpublished manuscript, New York University.},
  year      = {2023},
  publisher = {Self Published},
  url       = {https://tinyurl.com/SocialMediaMentalHealthReview},
}

@book{booth2020price,
	title        = {The Price of Tomorrow: Why Deflation is the Key to an Abundant Future},
	author       = {Booth, Jeff},
	year         = 2020,
	publisher    = {Stanley Press}
}

@Article{hou2022metaprompting,
  author  = {Hou, Yutai and Dong, Hongyuan and Wang, Xinghao and Li, Bohan and Che, Wanxiang},
  journal = {arXiv preprint arXiv:2209.11486},
  title   = {MetaPrompting: Learning to Learn Better Prompts},
  year    = {2022},
}

@Book{harari2014sapiens,
  author    = {Harari, Yuval Noah},
  publisher = {Random House},
  title     = {Sapiens: A brief history of humankind},
  year      = {2014},
}

@Misc{yang2023harnessing,
  author        = {Jingfeng Yang and Hongye Jin and Ruixiang Tang and Xiaotian Han and Qizhang Feng and Haoming Jiang and Bing Yin and Xia Hu},
  title         = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.13712},
  primaryclass  = {cs.CL},
}

@Misc{schaeffer2023emergent,
  author        = {Rylan Schaeffer and Brando Miranda and Sanmi Koyejo},
  title         = {Are Emergent Abilities of Large Language Models a Mirage?},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.15004},
  primaryclass  = {cs.AI},
}

@Article{rosenbergmanipulation,
  author = {Rosenberg, Louis B},
  title  = {The Manipulation Problem: Conversational AI as a Threat to Epistemic Agency},
}

@Misc{wu2022sustainable,
  author        = {Carole-Jean Wu and Ramya Raghavendra and Udit Gupta and Bilge Acun and Newsha Ardalani and Kiwan Maeng and Gloria Chang and Fiona Aga Behram and James Huang and Charles Bai and Michael Gschwind and Anurag Gupta and Myle Ott and Anastasia Melnikov and Salvatore Candido and David Brooks and Geeta Chauhan and Benjamin Lee and Hsien-Hsin S. Lee and Bugra Akyildiz and Maximilian Balandat and Joe Spisak and Ravi Jain and Mike Rabbat and Kim Hazelwood},
  title         = {Sustainable AI: Environmental Implications, Challenges and Opportunities},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2111.00364},
  primaryclass  = {cs.LG},
}

@Article{DBLP:journals/corr/abs-2112-04895,
  author     = {Itai Gat and Guy Lorberbom and Idan Schwartz and Tamir Hazan},
  journal    = {CoRR},
  title      = {Latent Space Explanation by Intervention},
  year       = {2021},
  volume     = {abs/2112.04895},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2112-04895.bib},
  eprint     = {2112.04895},
  eprinttype = {arXiv},
  timestamp  = {Mon, 13 Dec 2021 17:51:48 +0100},
  url        = {https://arxiv.org/abs/2112.04895},
}

@InProceedings{li2023neuralangelo,
  author    = {Li, Zhaoshuo and M\"uller, Thomas and Evans, Alex and Taylor, Russell H and Unberath, Mathias and Liu, Ming-Yu and Lin, Chen-Hsuan},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {Neuralangelo: High-Fidelity Neural Surface Reconstruction},
  year      = {2023},
}

@InProceedings{luong2022demographic,
  author       = {Luong, Tiffany and Plechata, Ad{\'e}la and M{\"o}bus, Max and Atchapero, Michael and B{\"o}hm, Robert and Makransky, Guido and Holz, Christian},
  booktitle    = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title        = {Demographic and Behavioral Correlates of Cybersickness: A Large Lab-in-the-Field Study of 837 Participants},
  year         = {2022},
  organization = {IEEE},
  pages        = {307--316},
}

@Article{fleuret2023little,
  author  = {Fleuret, Fran{\c{c}}ois},
  journal = {A lovely concise introduction},
  title   = {The Little Book of Deep Learning},
  year    = {2023},
  url     = {https://fleuret.org/public/lbdl.pdf},
}

@Misc{shumailov2023curse,
  author        = {Ilia Shumailov and Zakhar Shumaylov and Yiren Zhao and Yarin Gal and Nicolas Papernot and Ross Anderson},
  title         = {The Curse of Recursion: Training on Generated Data Makes Models Forget},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.17493},
  primaryclass  = {cs.LG},
}

@InProceedings{hansberger2017dispelling,
  author       = {Hansberger, Jeffrey T and Peng, Chao and Mathis, Shannon L and Areyur Shanthakumar, Vaidyanath and Meacham, Sarah C and Cao, Lizhou and Blakely, Victoria R},
  booktitle    = {Virtual, Augmented and Mixed Reality: 9th International Conference, VAMR 2017, Held as Part of HCI International 2017, Vancouver, BC, Canada, July 9-14, 2017, Proceedings 9},
  title        = {Dispelling the gorilla arm syndrome: the viability of prolonged gesture interactions},
  year         = {2017},
  organization = {Springer},
  pages        = {505--520},
}

@InProceedings{boring2009scroll,
  author    = {Boring, Sebastian and Jurmu, Marko and Butz, Andreas},
  booktitle = {Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group: Design: Open 24/7},
  title     = {Scroll, tilt or move it: using mobile phones to continuously control pointers on large public displays},
  year      = {2009},
  pages     = {161--168},
}

@Article{mollick2023assigning,
  author  = {Mollick, Ethan R and Mollick, Lilach},
  journal = {Available at SSRN},
  title   = {Assigning AI: Seven Approaches for Students, with Prompts},
  year    = {2023},
}

@Article{mollick2023using,
  author  = {Mollick, Ethan R and Mollick, Lilach},
  journal = {Including Prompts (March 17, 2023)},
  title   = {Using AI to implement effective teaching strategies in classrooms: Five strategies, including prompts},
  year    = {2023},
}

@Article{mollick2022new,
  author  = {Mollick, Ethan R and Mollick, Lilach},
  journal = {Available at SSRN},
  title   = {New Modes of Learning Enabled by AI Chatbots: Three Methods and Assignments},
  year    = {2022},
}

@Article{dettmers2022case,
  author  = {Dettmers, Tim and Zettlemoyer, Luke},
  journal = {arXiv preprint arXiv:2212.09720},
  title   = {The case for 4-bit precision: k-bit Inference Scaling Laws},
  year    = {2022},
}

@Misc{eloundou2023gpts,
  author        = {Tyna Eloundou and Sam Manning and Pamela Mishkin and Daniel Rock},
  title         = {GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.10130},
  primaryclass  = {econ.GN},
}

@Misc{pan2023unifying,
  author        = {Shirui Pan and Linhao Luo and Yufei Wang and Chen Chen and Jiapu Wang and Xindong Wu},
  title         = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2306.08302},
  primaryclass  = {cs.CL},
}

@Misc{ohare2022money,
  author        = {John Joseph O'Hare and Allen Fairchild and Umran Ali},
  title         = {Money and Trust in Digital Society -- Bitcoin, Nostr, Stablecoins, Digital Objects and Machine Learning in B2B Telepresent Mixed Reality},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2207.09460},
  primaryclass  = {cs.CR},
}

@Book{bandow1994perpetuating,
  author    = {Bandow, Doug and V{\'a}squez, Ian},
  publisher = {Cato Institute Washington\^{} eDC DC},
  title     = {Perpetuating poverty: The World Bank, the IMF, and the developing world},
  year      = {1994},
}

@InProceedings{han2023autoad,
  author    = {Tengda Han and Max Bain and Arsha Nagrani and G\"ul Varol and Weidi Xie and Andrew Zisserman},
  booktitle = {CVPR},
  title     = {{AutoAD}: Movie Description in Context},
  year      = {2023},
}

@Article{penedo2023refinedweb,
  author  = {Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal = {arXiv preprint arXiv:2306.01116},
  title   = {The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only},
  year    = {2023},
}

@Misc{juneja2022human,
  author        = {Prerna Juneja and Tanushree Mitra},
  title         = {Human and technological infrastructures of fact-checking},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2205.10894},
  primaryclass  = {cs.HC},
}

@Article{nissen2022digital,
  author    = {Nissen, Ida Anthonj and Walter, Jessica Gabriele and Charquero-Ballester, Marina and Bechmann, Anja},
  journal   = {Digital Journalism},
  title     = {Digital Infrastructures of COVID-19 Misinformation: A New Conceptual and Analytical Perspective on Fact-Checking},
  year      = {2022},
  number    = {5},
  pages     = {738--760},
  volume    = {10},
  publisher = {Taylor \& Francis},
}

@Misc{yang2023large,
  author        = {Kai-Cheng Yang and Filippo Menczer},
  title         = {Large language models can rate news outlet credibility},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.00228},
  primaryclass  = {cs.CL},
}

@Misc{vargas2023predicting,
  author        = {Francielle Vargas and Kokil Jaidka and Thiago A. S. Pardo and FabrÃ­cio Benevenuto},
  title         = {Predicting Sentence-Level Factuality of News and Bias of Media Outlets},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2301.11850},
  primaryclass  = {cs.CL},
}

@Misc{liu2023retallm,
  author        = {Jiongnan Liu and Jiajie Jin and Zihan Wang and Jiehan Cheng and Zhicheng Dou and Ji-Rong Wen},
  title         = {RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2306.05212},
  primaryclass  = {cs.IR},
}

@Misc{vladika2023scientific,
  author        = {Juraj Vladika and Florian Matthes},
  title         = {Scientific Fact-Checking: A Survey of Resources and Approaches},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.16859},
  primaryclass  = {cs.CL},
}

@Misc{huang2023manitweet,
  author        = {Kung-Hsiang Huang and Hou Pong Chan and Kathleen McKeown and Heng Ji},
  title         = {ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.14225},
  primaryclass  = {cs.CL},
}

@Misc{pikuliak2023multilingual,
  author        = {MatÃºÅ¡ Pikuliak and Ivan Srba and Robert Moro and Timo Hromadka and Timotej Smolen and Martin Melisek and Ivan Vykopal and Jakub Simko and Juraj Podrouzek and Maria Bielikova},
  title         = {Multilingual Previously Fact-Checked Claim Retrieval},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.07991},
  primaryclass  = {cs.CL},
}

@Article{xue2023repeat,
  author  = {Xue, Fuzhao and Fu, Yao and Zhou, Wangchunshu and Zheng, Zangwei and You, Yang},
  journal = {arXiv preprint arXiv:2305.13230},
  title   = {To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis},
  year    = {2023},
}

@Misc{yao2023tree,
  author        = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
  title         = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.10601},
  primaryclass  = {cs.CL},
}

@Article{lyytinen2002ubiquitous,
  author    = {Lyytinen, Kalle and Yoo, Youngjin},
  journal   = {Communications of the ACM},
  title     = {Ubiquitous computing},
  year      = {2002},
  number    = {12},
  pages     = {63--96},
  volume    = {45},
  publisher = {Citeseer},
}

@Misc{liu2023lost,
  author        = {Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
  title         = {Lost in the Middle: How Language Models Use Long Contexts},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2307.03172},
  primaryclass  = {cs.CL},
}

@Misc{chen2023chatgpts,
  author        = {Lingjiao Chen and Matei Zaharia and James Zou},
  title         = {How is ChatGPT's behavior changing over time?},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2307.09009},
  primaryclass  = {cs.CL},
}

@Misc{kaddour2023challenges,
  author        = {Jean Kaddour and Joshua Harris and Maximilian Mozes and Herbie Bradley and Roberta Raileanu and Robert McHardy},
  title         = {Challenges and Applications of Large Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2307.10169},
  primaryclass  = {cs.CL},
}

@Comment{jabref-meta: databaseType:bibtex;}
